import{_ as i}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as l,c as a,e as s}from"./app-5kh03Iqc.js";const e="/pinkpig/assets/round_dial_sft-RfwOzUzQ.png",t="/pinkpig/assets/equal_token-uy6ESpXh.png",n="/pinkpig/assets/loss_func-o0vd0f-o.png",o={},r=s('<h1 id="不传之秘" tabindex="-1"><a class="header-anchor" href="#不传之秘" aria-hidden="true">#</a> 不传之秘</h1><h2 id="哥哥总结的不传之秘" tabindex="-1"><a class="header-anchor" href="#哥哥总结的不传之秘" aria-hidden="true">#</a> 哥哥总结的不传之秘</h2><ul><li>训练性能 <ul><li>SFT 很容易导致在其他领域上的能力急剧下滑与遗忘</li><li>ppo相对容易能力下滑和遗忘</li><li>grpo根本不忘</li></ul></li><li>loss <ul><li>数据量小的时候（小于几十万条），loss 下降平缓只是证明训练过程没 bug，不能证明模型学得好</li><li>loss 中间有突刺或者下降不平缓，很可能模型就傻了</li></ul></li><li>小模型与大模型 <ul><li>小模型（小于7B）不能理解稍微复杂点的语言思考</li><li>很多训练策略与结论在小模型上和大点儿的模型上是两个世界</li><li>小模型最好学短思维链，大模型学长思维链</li></ul></li><li>训练数据要点（一定不能让模型有通过记忆找到很类似的题解答，进行偷懒的机会） <ul><li>去重</li><li>多样性</li><li>先易后难学习（curriculum learning）</li></ul></li><li>简单的方法比复杂的方法往往要好</li><li>模型是知行合一的，对自己生成的评分最高</li></ul><h2 id="多轮对话微调" tabindex="-1"><a class="header-anchor" href="#多轮对话微调" aria-hidden="true">#</a> 多轮对话微调</h2><p>一张图让你明白多轮对话是怎么微调的</p><figure><img src="'+e+'" alt="多轮对话微调" tabindex="0" loading="lazy"><figcaption>多轮对话微调</figcaption></figure><p>下面那串数字是多轮对话的label ids，也叫targets，有一个input_ids和它一一对应</p><figure><img src="'+t+'" alt="input_ids与targets一一对应" tabindex="0" loading="lazy"><figcaption>input_ids与targets一一对应</figcaption></figure><p>input_ids里每个token的id都是真的，targets里有部分是-100，只有assitant回复的部分是真的id</p><p>只有AI的多轮对话算，system和human都是-100，不计算loss</p><p>单轮的targets只有一小块不是-100，多轮（比如3轮）targets里就有3块不是-100</p><p>-100起什么作用呢？最后算交叉熵 loss的时候，-100的位置全部不算loss</p><figure><img src="'+n+'" alt="loss函数" tabindex="0" loading="lazy"><figcaption>loss函数</figcaption></figure><p>只有不为ignore_index(-100)的地方参与了计算，最后loss算平均，分母也是只算不为-100的token个数</p><h2 id="这个人偶尔会说点训模型过程中的不传之密" tabindex="-1"><a class="header-anchor" href="#这个人偶尔会说点训模型过程中的不传之密" aria-hidden="true">#</a> 这个人偶尔会说点训模型过程中的不传之密</h2><p>https://www.zhihu.com/people/ybq-29-32/posts</p><h2 id="领域模型训练" tabindex="-1"><a class="header-anchor" href="#领域模型训练" aria-hidden="true">#</a> 领域模型训练</h2><p>一、领域模型训练的重要性 领域模型，即在某一专业领域性能特别好的模型，其重要性不言而喻。在实际应用中，领域模型需要处理大量专业任务，如法律模型的法规判断、医学模型的病症诊断等。这些任务要求模型具备高度的专业性和准确性，而领域模型正是通过专门训练来满足这些需求的。</p><p>二、领域模型训练的关键环节</p><ol><li><p>Post-pretrain训练 Post-pretrain训练是领域模型训练的重要环节。在通用预训练（pretrain）阶段，模型已经学习到了大量的基础知识和语言能力。然而，为了进一步提升模型在特定领域的性能，需要进行post-pretrain训练。这一阶段的目的是让模型更好地认识领域的专有名词，理解领域的特定语境，从而提升模型的准确性和专业性。</p></li><li><p>数据质量与配比 数据是模型训练的基础，数据的质量和配比直接影响模型的性能。在领域模型训练中，需要确保数据的高质量，并合理配比不同来源的数据。例如，在法律模型训练中，需要包含大量的法律法规、案例判决等数据；在医学模型训练中，则需要包含各种病症、药品、治疗方案等数据。同时，还需要注意数据的多样性，包括中英文、代码等不同类型的数据，以提升模型的泛化能力。</p></li><li><p>Channel loss的监控 在领域模型训练中，channel loss的监控也是非常重要的。Channel loss是指不同数据channel各自的loss，通过监控channel loss，可以了解模型在不同类型数据上的表现情况，从而调整训练策略。例如，如果发现某个channel的loss较高，可以针对该channel增加数据或调整训练参数，以提升模型在该类型数据上的性能。</p></li></ol>',20),p=[r];function d(c,h){return l(),a("div",null,p)}const g=i(o,[["render",d],["__file","不传之秘.html.vue"]]);export{g as default};

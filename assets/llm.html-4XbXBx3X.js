const t=JSON.parse('{"key":"v-61f37bc9","path":"/llm/llm/llm.html","title":"LLM","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"LLM 知识点 Part1 背景与基础知识 Chapter1 引言 LM的发展历程 total detail ####### 统计语言模型（Statistical Language Model, SLM） 使用马尔可夫假设（Markov Assumption）来建立语言序列的预测模型，根据一个固定长度的前缀来预测目标单词（预测下一个词的出现概率） ######## n-gram（n元语言模型） 具有固定上下文长度 𝑛 的统计语言模型","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/llm/llm.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"LLM"}],["meta",{"property":"og:description","content":"LLM 知识点 Part1 背景与基础知识 Chapter1 引言 LM的发展历程 total detail ####### 统计语言模型（Statistical Language Model, SLM） 使用马尔可夫假设（Markov Assumption）来建立语言序列的预测模型，根据一个固定长度的前缀来预测目标单词（预测下一个词的出现概率） ######## n-gram（n元语言模型） 具有固定上下文长度 𝑛 的统计语言模型"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-02-16T13:11:34.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-02-16T13:11:34.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-16T13:11:34.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"知识点","slug":"知识点","link":"#知识点","children":[{"level":3,"title":"Part1 背景与基础知识","slug":"part1-背景与基础知识","link":"#part1-背景与基础知识","children":[]},{"level":3,"title":"Part2 预训练","slug":"part2-预训练","link":"#part2-预训练","children":[]},{"level":3,"title":"Part4 大模型使用","slug":"part4-大模型使用","link":"#part4-大模型使用","children":[]}]},{"level":2,"title":"专业术语","slug":"专业术语","link":"#专业术语","children":[{"level":3,"title":"Prompt（提示）","slug":"prompt-提示","link":"#prompt-提示","children":[]},{"level":3,"title":"编码器和解码器，自然语言理解和自然语言生成","slug":"编码器和解码器-自然语言理解和自然语言生成","link":"#编码器和解码器-自然语言理解和自然语言生成","children":[]},{"level":3,"title":"预训练和微调","slug":"预训练和微调","link":"#预训练和微调","children":[]},{"level":3,"title":"LM出现顺序","slug":"lm出现顺序","link":"#lm出现顺序","children":[]}]}],"git":{"createdTime":1739711494000,"updatedTime":1739711494000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro.local","commits":1}]},"readingTime":{"minutes":57.74,"words":17323},"filePathRelative":"llm/llm/llm.md","localizedDate":"February 16, 2025","excerpt":"<h1> LLM</h1>\\n<h2> 知识点</h2>\\n<h3> Part1 背景与基础知识</h3>\\n<h4> Chapter1 引言</h4>\\n<h5> LM的发展历程</h5>\\n<h6> total</h6>\\n<figure><figcaption></figcaption></figure>\\n<h6> detail</h6>\\n<p>####### 统计语言模型（Statistical Language Model, SLM）\\n使用马尔可夫假设（Markov Assumption）来建立语言序列的预测模型，根据一个固定长度的前缀来预测目标单词（预测下一个词的出现概率）</p>\\n<p>######## n-gram（n元语言模型）\\n具有固定上下文长度 𝑛 的统计语言模型</p>","autoDesc":true}');export{t as data};

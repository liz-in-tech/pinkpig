import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as i,c as n,e as l}from"./app-I9eu-1La.js";const s="/pinkpig/assets/image-EnbZqNkj.png",t="/pinkpig/assets/image-1-PDeYiNxJ.png",e="/pinkpig/assets/image-2-B8cjguw2.png",o="/pinkpig/assets/image-3-smnfjRgN.png",p={},r=l('<h1 id="autodl使用指南" tabindex="-1"><a class="header-anchor" href="#autodl使用指南" aria-hidden="true">#</a> AutoDL使用指南</h1><h2 id="了解gpu" tabindex="-1"><a class="header-anchor" href="#了解gpu" aria-hidden="true">#</a> 了解GPU</h2><p>GPU算力排名</p><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="'+t+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>单精度：L40 &gt; 4090 &gt; 4090D &gt; L20 &gt; 3090Ti &gt; A40 &gt; 3090 &gt; 3080Ti &gt; 3080 &gt; 3070 &gt; A100 &gt; A800 &gt; A4000 &gt; V100 &gt; 2080Ti &gt; 3060</p><p>半精度：A100 &gt; A800 &gt; L40 &gt; 4090 &gt; A40 &gt; 4090D &gt; V100 &gt; L20 &gt; 3090Ti &gt; A4000 &gt; 3090 &gt; 3080Ti &gt; 3080 &gt; 2080Ti &gt; 3070 &gt; 3060</p><p>GPU型号介绍</p><figure><img src="'+e+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>cuda需在11.1及以上</p><p>GPU、CPU、内存的机制为：按租用的GPU数量成比例分配CPU和内存（如果租用两块GPU，那么CPU和内存就x2）</p><p>常买GPU型号</p><ul><li>佛山 Tesla T4 16G：0.78/h <ul><li>CPU8核，内存56G，系统盘30G，数据盘50G SSD</li></ul></li><li>内蒙B区/重庆A区/西北B区/北京B区 4090 24G: 1.88-2.28/h（西北地区有1.88/h的） <ul><li>数据盘 50G</li><li>可能不一样的：CPU核数/内存/CPU型号/驱动/CUDA</li></ul></li></ul><h2 id="autodl使用教程" tabindex="-1"><a class="header-anchor" href="#autodl使用教程" aria-hidden="true">#</a> AutoDL使用教程</h2><ul><li>学生认证可享会员价（只需要学校邮箱验证，每一年认证一次）</li><li>登录方式：微信</li><li>免密登录：使用ssh-keygen命令生成密钥文件 <ul><li>ssh-keygen -t rsa</li><li>直接3个回车即可生成</li><li>可以看到密钥文件路径</li><li>打开公钥文件，复制公钥内容 <ul><li>cat ~/.ssh/id_rsa.pub</li></ul></li><li>在控制台-&gt;设置密钥登录-&gt;添加公钥</li><li>运行中的实例重启一次即可实现免密登录</li></ul></li><li>守护进程 <ul><li>避免SSH会话连接中断导致任务失败</li><li>输入screen，按回车键，执行任务；再打开另一个终端来查看GPU占用</li></ul></li><li></li></ul><h2 id="省钱绝招" tabindex="-1"><a class="header-anchor" href="#省钱绝招" aria-hidden="true">#</a> 省钱绝招</h2><p>https://autodl.com/docs/save_money/</p><ul><li>无卡模式开机 <ul><li>无卡模式开机使用0.5核；2GB内存；无GPU卡的配置，价格统一为￥0.1/小时 <ul><li>如果不是无卡模式开机，至少￥0.88/小时（如2080Ti）</li></ul></li><li>无卡模式会释放GPU，置GPU为空闲状态，正常开机时如果GPU被其他用户租用，可能出现空闲GPU不足的情况。此时可以等待GPU释放或克隆实例</li></ul></li><li>使用shutdown命令实现任务结束后关机</li></ul><h2 id="快捷工具-jupyterlab在线环境" tabindex="-1"><a class="header-anchor" href="#快捷工具-jupyterlab在线环境" aria-hidden="true">#</a> 快捷工具：jupyterLab在线环境</h2><ul><li>文件浏览区可对实例中的目录和文件进行查看、新建、下载等操作</li><li>可打开实例Terminal终端环境</li></ul><h2 id="上传和下载数据" tabindex="-1"><a class="header-anchor" href="#上传和下载数据" aria-hidden="true">#</a> 上传和下载数据</h2><ul><li>FileZilla方式</li><li>scp方式</li></ul><h2 id="数据保留逻辑" tabindex="-1"><a class="header-anchor" href="#数据保留逻辑" aria-hidden="true">#</a> 数据保留逻辑</h2><ul><li>实例在数据在</li><li>实例的开关机不影响数据</li><li>需要注意实例的释放时间，实例释放后，数据也会被清除</li></ul><h2 id="实例中目录用途" tabindex="-1"><a class="header-anchor" href="#实例中目录用途" aria-hidden="true">#</a> 实例中目录用途</h2><ul><li>/rootautodl-pub:公开数据集</li><li>/root/miniconda3</li><li>系统盘：/ <ul><li>一般</li><li>实例关机数据不会丢失，可存放代码等。会随保存镜像一起保存</li><li>在系统盘存放训练文件xx并且在数据盘下存在模型xx后</li></ul></li><li>数据盘：/root/autodl-tmp <ul><li>快</li><li>实例关机数据不会丢失，可存放读写IO要求高的数据。但不会随保存镜像一起保存</li><li>用于存在用户的个人数据，存放比较大的（数据，模型）</li></ul></li></ul><h2 id="环境配置" tabindex="-1"><a class="header-anchor" href="#环境配置" aria-hidden="true">#</a> 环境配置</h2><ul><li>基础镜像 <ul><li>Pytorch 2.5.1</li><li>Python 3.12</li><li>Ubuntu 22.04</li><li>CUDA 12.4 <img src="'+o+`" alt="" loading="lazy"></li></ul></li></ul><h3 id="jupyter初始配置" tabindex="-1"><a class="header-anchor" href="#jupyter初始配置" aria-hidden="true">#</a> jupyter初始配置</h3><ul><li>jupyterLab在线环境打开实例Terminal终端环境</li><li>（必要）更新系统依赖：apt-get update</li><li>（非必要）安装工具包：apt-get install zip # 以安装zip工具为例 <ul><li>跳过提示直接安装，添加“-y”参数 <ul><li>apt-get install -y zip</li></ul></li><li>关键词搜索筛选工具包：apt-cache search zip | grep file</li></ul></li><li>（必要）初始化conda: conda init (执行完成后关闭终端，重新开启一个终端，前面会有一个(base))</li><li>（非必要）查看conda列表 <ul><li>conda list</li><li>conda list | grep cuda</li></ul></li><li>（非必要）查看conda所有的python版本：conda search python</li><li>（必要）查看conda创建的环境 <ul><li>conda env list</li></ul></li><li>（非必要）安装python依赖包 <ul><li>使用conda安装python依赖包（全局的依赖） # 以安装numpy为例 <ul><li>搜索依赖: conda search numpy</li><li>安装工具包：conda install numpy</li><li>指定版本：conda install nummpy=1.22.3</li></ul></li></ul></li><li>（必要）使用conda创建python虚拟环境（环境的挂载目录为/root/miniconda3/envs） <ul><li>创建我的环境 <code>conda create -n &lt;name&gt; python=3.12</code></li><li>激活我的环境 <code>conda activate &lt;name&gt;</code></li><li>退出当前环境 conda deactivate</li><li>删除环境 <code>conda remove -n &lt;name&gt; --all</code></li></ul></li></ul><h3 id="vscode远程开发" tabindex="-1"><a class="header-anchor" href="#vscode远程开发" aria-hidden="true">#</a> vscode远程开发</h3><ul><li>（非必要）学术加速（不开很慢甚至无法下载相关文件） <ul><li>开启学术加速 <ul><li>source /etc/network_turbo</li></ul></li><li>关闭学术加速 unset http_proxy &amp;&amp; unset https_proxy</li></ul></li><li>（必要）vscode插件 <ul><li>Jupyter (以下的会自动安装) <ul><li>Jupyter Cell Tags</li><li>Jupyter Keymap</li><li>Jupyter Notebook Renderes</li><li>Jupyter Slide Show</li></ul></li><li>Python (以下的会自动安装) <ul><li>Pylint</li><li>Python Debugger</li></ul></li><li>Black Formatter</li><li>Git Graph</li><li>GitLens</li></ul></li><li>（必要）Ctrl + Shift + P -&gt; python:select interpreter -&gt; 添加python解释器 <ul><li>测试补全</li><li>查看跳转</li></ul></li><li>（必要）debug: <ul><li>pip install debugpy</li><li>项目根目录下，创建.vscode文件夹，里面的launch.json内容如上</li><li>点击按钮&quot;Python Debugger: Debug using launch.json&quot;</li></ul></li></ul><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;0.2.0&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;configurations&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Python: Debug Current File&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;debugpy&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;request&quot;</span><span class="token operator">:</span> <span class="token string">&quot;launch&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;program&quot;</span><span class="token operator">:</span> <span class="token string">&quot;\${file}&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;console&quot;</span><span class="token operator">:</span> <span class="token string">&quot;integratedTerminal&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;justMyCode&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
            <span class="token property">&quot;cwd&quot;</span><span class="token operator">:</span> <span class="token string">&quot;\${fileDirname}&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;env&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;PATH&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/root/miniconda3/envs/verl/bin:$PATH&quot;</span><span class="token punctuation">,</span> <span class="token comment">// 换成你自己的</span>
                <span class="token property">&quot;CONDA_PREFIX&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/root/miniconda3/envs/verl&quot;</span><span class="token punctuation">,</span> <span class="token comment">// 换成你自己的</span>
                <span class="token property">&quot;CONDA_DEFAULT_ENV&quot;</span><span class="token operator">:</span> <span class="token string">&quot;verl&quot;</span> <span class="token comment">// 换成你自己的</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>（必要）在虚拟环境中使用pip命令安装python依赖包 <ul><li>使用临时源安装 -i</li><li>qwen_debug安装包 <ul><li>pip install modelscope</li><li>pip install transformers peft diffusers</li><li>pip install torch</li><li>pip install transformers</li><li>pip install accelerate</li></ul></li></ul></li></ul><h2 id="命令" tabindex="-1"><a class="header-anchor" href="#命令" aria-hidden="true">#</a> 命令</h2><h3 id="查看gpu的利用率-nvidia-smi-l-1" tabindex="-1"><a class="header-anchor" href="#查看gpu的利用率-nvidia-smi-l-1" aria-hidden="true">#</a> 查看GPU的利用率：nvidia-smi -l 1</h3><ul><li>如果GPU占用率为0说明代码可能没有使用GPU，需检查代码。</li><li>如果GPU占用率忽高忽低、占用率峰值在50%以下，那么可能是数据预处理跟不上GPU的处理速度</li></ul><h3 id="查看cpu的占用率-控制台-容器实例-实例监控按钮" tabindex="-1"><a class="header-anchor" href="#查看cpu的占用率-控制台-容器实例-实例监控按钮" aria-hidden="true">#</a> 查看CPU的占用率：控制台 -&gt; 容器实例 -&gt; 实例监控按钮</h3><ul><li>假设您的实例核心数为5，如果CPU占用率接近500%（即5个核心都正在高负载使用）那么可能是CPU数量不够，CPU出现了瓶颈，此时您可以迁移实例到更高CPU数量的主机上去或者升配。如果CPU占用率远没有达到500%的，说明您的代码没有把CPU的算力压榨出来，一般可以通过修改Torch Dataloader中的worker_num提高CPU负载，经验值num_worker = 略小于核心数量，最好测试不同worker num值对性能的影响。</li></ul><h3 id="查看文件和目录占用容量信息" tabindex="-1"><a class="header-anchor" href="#查看文件和目录占用容量信息" aria-hidden="true">#</a> 查看文件和目录占用容量信息</h3><p>df -h</p><h3 id="查看gpu监控信息" tabindex="-1"><a class="header-anchor" href="#查看gpu监控信息" aria-hidden="true">#</a> 查看GPU监控信息</h3><p>nvidia-smi</p><h3 id="查看框架版本信息" tabindex="-1"><a class="header-anchor" href="#查看框架版本信息" aria-hidden="true">#</a> 查看框架版本信息</h3><p>import torch torch.<strong>version</strong> # 示例：&quot;1.8.1+cu111&quot; torch.version.cuda</p><h3 id="查看配置文件信息" tabindex="-1"><a class="header-anchor" href="#查看配置文件信息" aria-hidden="true">#</a> 查看配置文件信息</h3><p>cat /etc/os-release</p><h3 id="检查当前使用的python和pip路径和版本" tabindex="-1"><a class="header-anchor" href="#检查当前使用的python和pip路径和版本" aria-hidden="true">#</a> 检查当前使用的python和pip路径和版本</h3><p>which python which pip</p><p>python --version</p>`,50),u=[r];function c(d,h){return i(),n("div",null,u)}const k=a(p,[["render",c],["__file","autodl_init.html.vue"]]);export{k as default};

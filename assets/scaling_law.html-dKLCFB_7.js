import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as i,c as e,e as h}from"./app-eS8cJyut.js";const l={},r=h('<h1 id="两种不同的性能提升理论-涌现能力和扩展法则" tabindex="-1"><a class="header-anchor" href="#两种不同的性能提升理论-涌现能力和扩展法则" aria-hidden="true">#</a> 两种不同的性能提升理论：涌现能力和扩展法则</h1><h2 id="_1-scaling-law-扩展法则" tabindex="-1"><a class="header-anchor" href="#_1-scaling-law-扩展法则" aria-hidden="true">#</a> 1. Scaling Law（扩展法则）</h2><h3 id="_1-1-定义" tabindex="-1"><a class="header-anchor" href="#_1-1-定义" aria-hidden="true">#</a> 1.1 定义</h3><p>建立模型性能与模型规模（𝑁）、数据规模（𝐷）和计算算力（𝐶）这三个因素之间的关系</p><p>通过规模扩展（如增加模型参数规模或数据规模）通常会带来下游任务的模型性能提升，这种现象通常被称为&quot;扩展法则&quot;（Scaling Law）</p><p>OpenAI 从参数、数据、算力三个方面深入地研究了规模扩展对于模型性能所带来的影响，建立了定量的函数关系，称之为&quot;扩展法则&quot;（Scaling Law）</p><h3 id="_1-2-2种扩展法则" tabindex="-1"><a class="header-anchor" href="#_1-2-2种扩展法则" aria-hidden="true">#</a> 1.2 2种扩展法则</h3><ol><li>KM扩展法则 <ul><li>OpenAI 团队</li></ul></li><li>Chinchilla 扩展法则 <ul><li>DeepMind 团队</li></ul></li></ol><h3 id="_1-3-讨论" tabindex="-1"><a class="header-anchor" href="#_1-3-讨论" aria-hidden="true">#</a> 1.3 讨论</h3><h4 id="_1-3-1-km与chinchilla的对比" tabindex="-1"><a class="header-anchor" href="#_1-3-1-km与chinchilla的对比" aria-hidden="true">#</a> 1.3.1 KM与Chinchilla的对比</h4><p>尽管 KM 扩展法则和 Chinchilla 扩展法则具有相似的公式形式，但是在模型规模和数据规模的扩展上存在一定的差异。随着算力预算的增加，KM 扩展法则倾向于将更大的预算分配给模型规模的增加，而不是分配给数据规模的增加；而 Chinchilla 扩展法则主张两种规模参数应该以等比例关系增加。</p><h4 id="_1-3-2-predictable-scaling-可预测的扩展" tabindex="-1"><a class="header-anchor" href="#_1-3-2-predictable-scaling-可预测的扩展" aria-hidden="true">#</a> 1.3.2 Predictable Scaling（可预测的扩展）</h4><h5 id="_1-3-2-1-定义" tabindex="-1"><a class="header-anchor" href="#_1-3-2-1-定义" aria-hidden="true">#</a> 1.3.2.1 定义</h5><p>在实践中，扩展法则可以用于指导大语言模型的训练，通过较小算力资源可靠地估计较大算力资源投入后的模型性能，这被称为可预测的扩展</p><h5 id="_1-3-2-2-可预测性体现在2个方面" tabindex="-1"><a class="header-anchor" href="#_1-3-2-2-可预测性体现在2个方面" aria-hidden="true">#</a> 1.3.2.2 可预测性体现在2个方面</h5><ol><li>使用小模型的性能去预估大模型的性能</li><li>使用大模型的早期训练性能去估计训练完成后的性能</li></ol><h5 id="_1-3-2-3-作用" tabindex="-1"><a class="header-anchor" href="#_1-3-2-3-作用" aria-hidden="true">#</a> 1.3.2.3 作用</h5><ul><li>减少实验成本</li><li>可以用于监控大语言模型的训练状态，如在早期识别异常性能</li></ul><h5 id="_1-3-2-4-任务层面的可预测性" tabindex="-1"><a class="header-anchor" href="#_1-3-2-4-任务层面的可预测性" aria-hidden="true">#</a> 1.3.2.4 任务层面的可预测性</h5><p>整体上来说，语言建模损失较小的模型往往在下游任务中表现更好。然而，语言建模损失的减少并不总是意味着模型在下游任务上的性能改善。</p><h5 id="_1-3-2-5-逆向扩展-inverse-scaling-现象" tabindex="-1"><a class="header-anchor" href="#_1-3-2-5-逆向扩展-inverse-scaling-现象" aria-hidden="true">#</a> 1.3.2.5 &quot;逆向扩展&quot;（Inverse Scaling）现象</h5><p>随着语言建模损失的降低，任务性能却出人意料地变差</p><p>根据 GPT-4 的报告，通过扩展法则可以准确预测某些任务能力（例如编码能力），但是对于有些任务的性能预测是非常困难的。此外，有些重要能力（例如上下文学习能力）根据扩展法则是不可预测的，只有当模型大小超过一定规模时才会出现,如下文所讨论的涌现能力。</p><h2 id="_2-emergent-abilities-涌现能力" tabindex="-1"><a class="header-anchor" href="#_2-emergent-abilities-涌现能力" aria-hidden="true">#</a> 2. Emergent Abilities（涌现能力）</h2><h3 id="_2-1-定义" tabindex="-1"><a class="header-anchor" href="#_2-1-定义" aria-hidden="true">#</a> 2.1 定义</h3><p>大模型具有但小模型不具有的能力（在小型模型中不存在但在大模型中出现的能力）</p><p>&quot;顿悟&quot;（Grokking）</p><p>为了区别这一能力上的差异，学术界将这些大型预训练语言模型命名为&quot;大语言模型&quot;（Large Language Model, LLM）</p><p>值得注意的是，大语言模型不一定比小型预训练语言模型具有更强的任务效果，而且某些大语言模型中也可能不具有某种涌现能力。</p><h3 id="_2-2-3种典型涌现能力" tabindex="-1"><a class="header-anchor" href="#_2-2-3种典型涌现能力" aria-hidden="true">#</a> 2.2 3种典型涌现能力</h3><ol><li><p>上下文学习（In-context Learning, ICL）</p><ul><li>在 GPT-3 的论文中被正式提出</li><li>具体方式为，在Prompt中为语言模型提供自然语言指令和多个任务示例（Demonstration），无需显式的训练或梯度更新，仅输入文本的单词序列就能为测试样本生成预期的输出。</li></ul></li><li><p>指令遵循（Instruction Following）</p><ul><li>指令遵循能力是指大语言模型能够按照自然语言指令来执行对应的任务</li><li>为了获得这一能力，通常需要使用自然语言描述的多任务示例数据集进行微调，称为指令微调（Instruction Tuning）或监督微调（Supervised Fine-tuning）</li><li>相比于上下文学习能力，指令遵循能力整体上更容易获得，但是最终的任务执行效果还取决于模型性能和任务难度</li></ul></li><li><p>逐步推理（Step-by-step Reasoning）</p><ul><li>具体来说，大语言模型可以在提示中引入任务相关的中间推理步骤来加强复杂任务的求解，从而获得更为可靠的答案</li><li>利用思维链（Chain-of-Thought, CoT）提示策略来加强推理性能，思维链提示特别适合帮助大语言模型解决复杂数学问题</li></ul></li></ol><h3 id="_2-3-讨论" tabindex="-1"><a class="header-anchor" href="#_2-3-讨论" aria-hidden="true">#</a> 2.3 讨论</h3><p>通常来说，很难统一界定大语言模型出现这些上述能力的临界规模（即具备某种能力的最小规模），因为能力涌现会受到多种因素或者任务设置的影响。</p><p>最近的研究表明，经过了高质量的预训练与指令微调后，即使较小的语言模型（如 LLaMA-2 (7B)）也能够一定程度上展现出上述提到的三种能力，并且对于参数规模的要求随着预训练数据规模的扩展以及数据质量的提升在不断下降。</p><h3 id="_3-涌现能力与扩展法则的关系" tabindex="-1"><a class="header-anchor" href="#_3-涌现能力与扩展法则的关系" aria-hidden="true">#</a> 3. 涌现能力与扩展法则的关系</h3><p>扩展法则使用语言建模损失来衡量语言模型的整体性能，整体上展现出了较为平滑的性能提升趋势，具有较好的可预测性，但是指数形式暗示着可能存在的边际效益递减现象</p><p>涌现能力通常使用任务性能来衡量模型性能，整体上展现出随规模扩展的骤然跃升趋势，不具有可预测性， 但是一旦出现涌现能力则意味着模型性能将会产生大幅跃升</p><p>由于这两种观点反映了不同的模型性能提升趋势（持续改进 v.s. 性能跃升），可能在一些情况下会导致不一致的发现与结论。</p>',38),n=[r];function d(t,c){return i(),e("div",null,n)}const p=a(l,[["render",d],["__file","scaling_law.html.vue"]]);export{p as default};

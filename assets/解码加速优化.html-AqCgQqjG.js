import{_ as i}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as e,e as n}from"./app-eS8cJyut.js";const t="/pinkpig/assets/llm_020-lIidEWOm.png",r="/pinkpig/assets/llm_021-oykqkVuu.png",l="/pinkpig/assets/llm_022-j7ItV1OS.png",s="/pinkpig/assets/llm_023-DEXP28GG.png",d="/pinkpig/assets/llm_024-CqUHcjqH.png",c="/pinkpig/assets/llm_025-Nw7eMfOx.png",o="/pinkpig/assets/llm_026-9EH6lU5W.png",p="/pinkpig/assets/llm_027-09hzHI6c.png",g="/pinkpig/assets/llm_028-n6VwXbkc.png",h={},_=n('<h1 id="解码加速算法" tabindex="-1"><a class="header-anchor" href="#解码加速算法" aria-hidden="true">#</a> 解码加速算法</h1><h2 id="_1-解码效率的定量评估指标" tabindex="-1"><a class="header-anchor" href="#_1-解码效率的定量评估指标" aria-hidden="true">#</a> 1. 解码效率的定量评估指标</h2><ul><li>GPU性能评估 <ul><li>GPU算力 : 算力是指 GPU 每秒能够进行的浮点运算次数，单位是 FLOP/s</li><li>GPU带宽 : 带宽是该显卡每秒能够进行的显存读写量，单位是 byte/s</li><li>GPU计算强度上限 : 算力和带宽的比值被称为该 GPU 的计算强度上限 𝐼𝑚𝑎𝑥，单位为 FLOP/byte</li></ul></li><li>模型性能评估 <ul><li>模型的运算量 : 运算量是指运行该模型需要的总浮点计算数，单位为 FLOP</li><li>模型的访存量 : 访存量是运行该模型的过程中所需的显存读写量，单位为 byte</li><li>模型的计算强度 : 运算量和访存量的比值被称为该模型的计算强度 𝐼，单位为 FLOP/byte</li></ul></li><li>带宽瓶颈和计算瓶颈 <ul><li>带宽瓶颈 / 显存瓶颈 <ul><li>当模型的计算强度 𝐼 小于GPU 的计算强度上限 𝐼𝑚𝑎𝑥 时，这说明 GPU 的理论最高显存读写速度低于实际运算所需速度，因此模型实际的运行效率将主要受到显存读写速度的影响，这种情况称为带宽瓶颈；</li></ul></li><li>反之，当 𝐼 大于 𝐼𝑚𝑎𝑥 时，说明 GPU 的理论最高浮点运算速度低于实际运算所需速度，因此模型的运行效率将主要受到算力的影响，这种情况称为计算瓶颈。</li></ul></li></ul><h2 id="_2-自回归生成算法" tabindex="-1"><a class="header-anchor" href="#_2-自回归生成算法" aria-hidden="true">#</a> 2. 自回归生成算法</h2><p>由于自回归算法的序列化生成特点，使得解码算法存在效率较低的问题。</p><figure><img src="'+t+'" alt="自回归生成算法" tabindex="0" loading="lazy"><figcaption>自回归生成算法</figcaption></figure><h2 id="_3-全量解码阶段与增量解码阶段" tabindex="-1"><a class="header-anchor" href="#_3-全量解码阶段与增量解码阶段" aria-hidden="true">#</a> 3. 全量解码阶段与增量解码阶段</h2><h3 id="_3-1-全量解码阶段-第一次-计算瓶颈" tabindex="-1"><a class="header-anchor" href="#_3-1-全量解码阶段-第一次-计算瓶颈" aria-hidden="true">#</a> 3.1. 全量解码阶段（第一次）- 计算瓶颈</h3><p>对于输入序列，一次性地计算其状态并缓存键值矩阵 （算法 3 第 1 至 3 行）</p><p>以 LLaMA 模型为例，全量解码的运算量、访存量和计算强度：</p><figure><img src="'+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>全量解码阶段是受限于 GPU 浮点数计算能力（即计算瓶颈）</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_3-2-增量解码阶段-之后多次-带宽瓶颈-显存瓶颈" tabindex="-1"><a class="header-anchor" href="#_3-2-增量解码阶段-之后多次-带宽瓶颈-显存瓶颈" aria-hidden="true">#</a> 3.2. 增量解码阶段（之后多次）- 带宽瓶颈/显存瓶颈</h3><p>只计算上一步新生成词元的状态，并不断地以自回归方式生成新词元并对应更新键值缓存，直到生成结束（算法 3 第 4-9 行）</p><p><strong>解码阶段的低效问题主要出现在增量解码阶段，存在显存瓶颈</strong></p><p>以 LLaMA 模型为例，增量解码的运算量、访存量和计算强度</p><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>增量解码阶段是受限于 GPU 显存读写速度的（即显存瓶颈），这种问题通常被称为内存墙（Memory Wall）问题</p><figure><img src="'+d+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_4-增量解码阶段-显存瓶颈-的改进方法" tabindex="-1"><a class="header-anchor" href="#_4-增量解码阶段-显存瓶颈-的改进方法" aria-hidden="true">#</a> 4. 增量解码阶段（显存瓶颈）的改进方法</h2><h3 id="_4-1-系统优化-直接解决系统级别的内存墙问题" tabindex="-1"><a class="header-anchor" href="#_4-1-系统优化-直接解决系统级别的内存墙问题" aria-hidden="true">#</a> 4.1. 系统优化（直接解决系统级别的内存墙问题）</h3><p>针对“内存墙”问题，一个直观的解决方案是减少相关操作的访存量，从而达到提升计算强度的目的。</p><p>优化方法</p><ul><li>FlashAttention</li><li>PagedAttention</li><li>批次管理优化</li></ul><h3 id="_4-2-解码策略优化-针对自回归解码策略的改进方法" tabindex="-1"><a class="header-anchor" href="#_4-2-解码策略优化-针对自回归解码策略的改进方法" aria-hidden="true">#</a> 4.2. 解码策略优化（针对自回归解码策略的改进方法）</h3><h4 id="_4-2-1-推测解码-speculative-decoding" tabindex="-1"><a class="header-anchor" href="#_4-2-1-推测解码-speculative-decoding" aria-hidden="true">#</a> 4.2.1. 推测解码（Speculative Decoding）</h4><p>推测解码不会降低大模型解码的质量， 实验测试表明能够带来约两倍左右的解码加速，是目前使用较多的解码策略优化方案。</p><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_4-2-2-非自回归解码-non-autoregressive-decoding" tabindex="-1"><a class="header-anchor" href="#_4-2-2-非自回归解码-non-autoregressive-decoding" aria-hidden="true">#</a> 4.2.2. 非自回归解码（Non-autoregressive Decoding）</h4><figure><img src="'+o+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_4-2-3-早退机制-early-exiting" tabindex="-1"><a class="header-anchor" href="#_4-2-3-早退机制-early-exiting" aria-hidden="true">#</a> 4.2.3. 早退机制（Early Exiting）</h4><p>可能不需要经过所有层的计算，模型就可以较为可靠地预测下一个词的生成。基于这种想法，研究人员提出了基于早退机制的生成方式。</p><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_4-2-4-级联解码-cascade-inference" tabindex="-1"><a class="header-anchor" href="#_4-2-4-级联解码-cascade-inference" aria-hidden="true">#</a> 4.2.4. 级联解码（Cascade Inference）</h4><p>多个模型按效率从高到低排序，将请求依次给排好序的模型，引入一个专门训练的二分类模型来判断生成结果是否符合任务要求，如果结果可靠则结束</p><figure><img src="'+g+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',37),f=[_];function u(m,x){return a(),e("div",null,f)}const P=i(h,[["render",u],["__file","解码加速优化.html.vue"]]);export{P as default};

const l=JSON.parse('{"key":"v-2f361fae","path":"/llm/01_llm_basic/03_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html","title":"神经网络","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"神经网络 1. 欠拟合与过拟合 欠拟合（Underfitting）：模型在训练数据上表现不佳，无法很好捕捉到数据的特征和模式的现象 模型过于简单 高偏差（high bias） 过拟合（Overfitting）：模型在训练数据上表现很好，但在未见过的测试数据上表现较差的现象（泛化能力差， 记忆了训练数据） 模型过于复杂 通常发生在模型过于复杂或者训练数据较少的情况下 解决方式 数据增强（Data Augmentation）：可以对数据进行扩增，如旋转、缩放、翻转等，从而增加训练数据的多样性，减少模型对于训练数据的过拟合 提前停止（Early Stopping）：在训练过程中监控模型在验证数据上的性能，当性能开始下降时，提前停止训练，避免过拟合 正则化（Regularization）：可以通过在模型的损失函数中引入正则化项来限制模型的参数值，从而减少模型的复杂度，防止过拟合","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/01_llm_basic/03_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"神经网络"}],["meta",{"property":"og:description","content":"神经网络 1. 欠拟合与过拟合 欠拟合（Underfitting）：模型在训练数据上表现不佳，无法很好捕捉到数据的特征和模式的现象 模型过于简单 高偏差（high bias） 过拟合（Overfitting）：模型在训练数据上表现很好，但在未见过的测试数据上表现较差的现象（泛化能力差， 记忆了训练数据） 模型过于复杂 通常发生在模型过于复杂或者训练数据较少的情况下 解决方式 数据增强（Data Augmentation）：可以对数据进行扩增，如旋转、缩放、翻转等，从而增加训练数据的多样性，减少模型对于训练数据的过拟合 提前停止（Early Stopping）：在训练过程中监控模型在验证数据上的性能，当性能开始下降时，提前停止训练，避免过拟合 正则化（Regularization）：可以通过在模型的损失函数中引入正则化项来限制模型的参数值，从而减少模型的复杂度，防止过拟合"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-05-21T08:52:56.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-05-21T08:52:56.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"神经网络\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-05-21T08:52:56.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. 欠拟合与过拟合","slug":"_1-欠拟合与过拟合","link":"#_1-欠拟合与过拟合","children":[]},{"level":2,"title":"2. 直观表现","slug":"_2-直观表现","link":"#_2-直观表现","children":[]},{"level":2,"title":"3. 分层结构","slug":"_3-分层结构","link":"#_3-分层结构","children":[{"level":3,"title":"3.1. 层的分类","slug":"_3-1-层的分类","link":"#_3-1-层的分类","children":[]}]},{"level":2,"title":"4. MLP,Multiple-Layer Perceiver(多层感知器)","slug":"_4-mlp-multiple-layer-perceiver-多层感知器","link":"#_4-mlp-multiple-layer-perceiver-多层感知器","children":[]},{"level":2,"title":"5. 神经网络本质：整个神经网络，就是一个有成千上万个可调节参数的超级大函数","slug":"_5-神经网络本质-整个神经网络-就是一个有成千上万个可调节参数的超级大函数","link":"#_5-神经网络本质-整个神经网络-就是一个有成千上万个可调节参数的超级大函数","children":[{"level":3,"title":"5.1. 模型的整体表示","slug":"_5-1-模型的整体表示","link":"#_5-1-模型的整体表示","children":[]},{"level":3,"title":"5.2. 模型参数 = 权重参数 + 偏置参数","slug":"_5-2-模型参数-权重参数-偏置参数","link":"#_5-2-模型参数-权重参数-偏置参数","children":[]},{"level":3,"title":"5.3. 超参数(Hyperparameters)","slug":"_5-3-超参数-hyperparameters","link":"#_5-3-超参数-hyperparameters","children":[]}]},{"level":2,"title":"6. 神经网络的训练","slug":"_6-神经网络的训练","link":"#_6-神经网络的训练","children":[{"level":3,"title":"6.0. LLM 的训练目标","slug":"_6-0-llm-的训练目标","link":"#_6-0-llm-的训练目标","children":[]},{"level":3,"title":"6.1. 前向传播(Forward Propagation)","slug":"_6-1-前向传播-forward-propagation","link":"#_6-1-前向传播-forward-propagation","children":[]},{"level":3,"title":"6.2. 反向传播(Back Propagation)","slug":"_6-2-反向传播-back-propagation","link":"#_6-2-反向传播-back-propagation","children":[]}]},{"level":2,"title":"7. 示例","slug":"_7-示例","link":"#_7-示例","children":[{"level":3,"title":"7.1. 任务","slug":"_7-1-任务","link":"#_7-1-任务","children":[]},{"level":3,"title":"7.2. 特征提取","slug":"_7-2-特征提取","link":"#_7-2-特征提取","children":[]},{"level":3,"title":"7.3. 神经网络","slug":"_7-3-神经网络","link":"#_7-3-神经网络","children":[]},{"level":3,"title":"7.4. 识别的结果","slug":"_7-4-识别的结果","link":"#_7-4-识别的结果","children":[]}]}],"git":{"createdTime":1743233581000,"updatedTime":1747817576000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-6.local","commits":2},{"name":"liz","email":"liz@MacBook-Pro-2.local","commits":1}]},"readingTime":{"minutes":22.42,"words":6726},"filePathRelative":"llm/01_llm_basic/03_神经网络.md","localizedDate":"March 29, 2025","excerpt":"<h1> 神经网络</h1>\\n<h2> 1. 欠拟合与过拟合</h2>\\n<ul>\\n<li>欠拟合（Underfitting）：模型在训练数据上表现不佳，无法很好捕捉到数据的特征和模式的现象\\n<ul>\\n<li>模型过于简单</li>\\n<li>高偏差（high bias）</li>\\n</ul>\\n</li>\\n<li>过拟合（Overfitting）：模型在训练数据上表现很好，但在未见过的测试数据上表现较差的现象（泛化能力差， 记忆了训练数据）\\n<ul>\\n<li>模型过于复杂</li>\\n<li>通常发生在<strong>模型过于复杂</strong>或者<strong>训练数据较少</strong>的情况下</li>\\n<li>解决方式\\n<ul>\\n<li>数据增强（Data Augmentation）：可以对数据进行扩增，如旋转、缩放、翻转等，从而增加训练数据的多样性，减少模型对于训练数据的过拟合</li>\\n<li>提前停止（Early Stopping）：在训练过程中监控模型在验证数据上的性能，当性能开始下降时，提前停止训练，避免过拟合</li>\\n<li>正则化（Regularization）：可以通过在模型的损失函数中引入正则化项来限制模型的参数值，从而减少模型的复杂度，防止过拟合</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{l as data};

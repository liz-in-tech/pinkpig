const e=JSON.parse('{"key":"v-4c0aaac0","path":"/llm/06_llm_experience/gpu_usage.html","title":"GPU Usage","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"GPU Usage 1. 大模型常见规格 一般模型的规格会体现在模型的名称上，例如 LLaMA2-13b，13b 就是其模型参数量的大小，意思是130亿的参数量。 如何查看 huggingface上找到相应组织后，看模型的Collection 各模型汇总 Llama Llama 3.3：70B Llama 3.2：1B，3B，11B（vision），90B（vision） Llama 3.1：8B，70B，405B Llama 3：8B，70B Qwen Qwen 2.5：0.5B、1.5B、3B、7B、14B、32B、72B QwQ：32B Deepseek DeepSeek LLM：7B，67B DeepSeek V3：671B DeepSeek R1：671B，蒸馏版：（1.5B，7B，8B，14B，32B，70B） Gemini Gemma 3：1B，4B，12B，27B","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/06_llm_experience/gpu_usage.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"GPU Usage"}],["meta",{"property":"og:description","content":"GPU Usage 1. 大模型常见规格 一般模型的规格会体现在模型的名称上，例如 LLaMA2-13b，13b 就是其模型参数量的大小，意思是130亿的参数量。 如何查看 huggingface上找到相应组织后，看模型的Collection 各模型汇总 Llama Llama 3.3：70B Llama 3.2：1B，3B，11B（vision），90B（vision） Llama 3.1：8B，70B，405B Llama 3：8B，70B Qwen Qwen 2.5：0.5B、1.5B、3B、7B、14B、32B、72B QwQ：32B Deepseek DeepSeek LLM：7B，67B DeepSeek V3：671B DeepSeek R1：671B，蒸馏版：（1.5B，7B，8B，14B，32B，70B） Gemini Gemma 3：1B，4B，12B，27B"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-03-30T17:11:04.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-03-30T17:11:04.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPU Usage\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-30T17:11:04.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. 大模型常见规格","slug":"_1-大模型常见规格","link":"#_1-大模型常见规格","children":[]},{"level":2,"title":"2. NVIDIA GPU 参数速查表","slug":"_2-nvidia-gpu-参数速查表","link":"#_2-nvidia-gpu-参数速查表","children":[]},{"level":2,"title":"3. GPU介绍","slug":"_3-gpu介绍","link":"#_3-gpu介绍","children":[]},{"level":2,"title":"4. 现有GPU资源","slug":"_4-现有gpu资源","link":"#_4-现有gpu资源","children":[]},{"level":2,"title":"5. 选择 GPU 用于 AI 机器学习和 LLM 的关键因素","slug":"_5-选择-gpu-用于-ai-机器学习和-llm-的关键因素","link":"#_5-选择-gpu-用于-ai-机器学习和-llm-的关键因素","children":[]},{"level":2,"title":"6. 模型文件有多大","slug":"_6-模型文件有多大","link":"#_6-模型文件有多大","children":[]},{"level":2,"title":"7. nB 模型推理需要多少显存","slug":"_7-nb-模型推理需要多少显存","link":"#_7-nb-模型推理需要多少显存","children":[]},{"level":2,"title":"8. nB 模型训练需要多少显存","slug":"_8-nb-模型训练需要多少显存","link":"#_8-nb-模型训练需要多少显存","children":[{"level":3,"title":"8.1. GPU 显存计算  version2","slug":"_8-1-gpu-显存计算-version2","link":"#_8-1-gpu-显存计算-version2","children":[]},{"level":3,"title":"8.2. gege version3","slug":"_8-2-gege-version3","link":"#_8-2-gege-version3","children":[]}]},{"level":2,"title":"9. 能否用4 * v100 32G训练vicuna 65b？","slug":"_9-能否用4-v100-32g训练vicuna-65b","link":"#_9-能否用4-v100-32g训练vicuna-65b","children":[]}],"git":{"createdTime":1743354664000,"updatedTime":1743354664000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-2.local","commits":1}]},"readingTime":{"minutes":8.31,"words":2492},"filePathRelative":"llm/06_llm_experience/gpu_usage.md","localizedDate":"March 30, 2025","excerpt":"<h1> GPU Usage</h1>\\n<h2> 1. 大模型常见规格</h2>\\n<p>一般模型的规格会体现在模型的名称上，例如 LLaMA2-13b，13b 就是其模型<strong>参数量</strong>的大小，意思是130亿的参数量。</p>\\n<p>如何查看</p>\\n<ul>\\n<li>huggingface上找到相应组织后，看模型的Collection</li>\\n</ul>\\n<p>各模型汇总</p>\\n<ul>\\n<li>Llama\\n<ul>\\n<li>Llama 3.3：70B</li>\\n<li>Llama 3.2：1B，3B，11B（vision），90B（vision）</li>\\n<li>Llama 3.1：8B，70B，405B</li>\\n<li>Llama 3：8B，70B</li>\\n</ul>\\n</li>\\n<li>Qwen\\n<ul>\\n<li>Qwen 2.5：0.5B、1.5B、3B、7B、14B、32B、72B</li>\\n<li>QwQ：32B</li>\\n</ul>\\n</li>\\n<li>Deepseek\\n<ul>\\n<li>DeepSeek LLM：7B，67B</li>\\n<li>DeepSeek V3：671B</li>\\n<li>DeepSeek R1：671B，蒸馏版：（1.5B，7B，8B，14B，32B，70B）</li>\\n</ul>\\n</li>\\n<li>Gemini\\n<ul>\\n<li>Gemma 3：1B，4B，12B，27B</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{e as data};

const e=JSON.parse('{"key":"v-2aed483d","path":"/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html","title":"分布式训练框架","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"分布式训练框架 训练框架对比 小 (&lt;10B参数): torchrun/accelerate都行 中（10B-100B参数）: deepspeed 大（&gt;100参数）: 得上megatron 0. Pytorch三种数据并行方案 DP（torch.nn.DataParallel） 目前，基本上 DP 已经被弃用 DP只用于单机情况（单进程多线程模式），不支持多级多卡 使用普通的All-Reduce机制 DDP（torch.nn.DistributedDataParallel） 相较于DP，DDP传输的数据量更少，训练更高效 DDP适用于单机和多机情况，真正实现分布式训练 DDP数据传输过程： 前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。 DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致 不足：要求整个模型加载到一个GPU上 FSDP（torch.distributed.fsdp.FullyShardedDataParallel） PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感 是一种新型数据并行训练方法 将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"分布式训练框架"}],["meta",{"property":"og:description","content":"分布式训练框架 训练框架对比 小 (&lt;10B参数): torchrun/accelerate都行 中（10B-100B参数）: deepspeed 大（&gt;100参数）: 得上megatron 0. Pytorch三种数据并行方案 DP（torch.nn.DataParallel） 目前，基本上 DP 已经被弃用 DP只用于单机情况（单进程多线程模式），不支持多级多卡 使用普通的All-Reduce机制 DDP（torch.nn.DistributedDataParallel） 相较于DP，DDP传输的数据量更少，训练更高效 DDP适用于单机和多机情况，真正实现分布式训练 DDP数据传输过程： 前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。 DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致 不足：要求整个模型加载到一个GPU上 FSDP（torch.distributed.fsdp.FullyShardedDataParallel） PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感 是一种新型数据并行训练方法 将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-23T13:53:11.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-04-23T13:53:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"分布式训练框架\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-04-23T13:53:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"0. Pytorch三种数据并行方案","slug":"_0-pytorch三种数据并行方案","link":"#_0-pytorch三种数据并行方案","children":[{"level":3,"title":"DP和DDP的区别","slug":"dp和ddp的区别","link":"#dp和ddp的区别","children":[]},{"level":3,"title":"DDP 和 FSDP的区别","slug":"ddp-和-fsdp的区别","link":"#ddp-和-fsdp的区别","children":[]}]},{"level":2,"title":"1. DeepSpeed","slug":"_1-deepspeed","link":"#_1-deepspeed","children":[{"level":3,"title":"为什么需要Deepspeed","slug":"为什么需要deepspeed","link":"#为什么需要deepspeed","children":[]},{"level":3,"title":"DeepSpeed 优化点","slug":"deepspeed-优化点","link":"#deepspeed-优化点","children":[]},{"level":3,"title":"DeepSpeed 通信策略","slug":"deepspeed-通信策略","link":"#deepspeed-通信策略","children":[]},{"level":3,"title":"混合精度训练","slug":"混合精度训练","link":"#混合精度训练","children":[]},{"level":3,"title":"DeepSpeed的核心技术：Zero（Zero Redundancy Optimizer，3D优化与卸载）","slug":"deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载","link":"#deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载","children":[]}]},{"level":2,"title":"2. Megatron-LM","slug":"_2-megatron-lm","link":"#_2-megatron-lm","children":[]},{"level":2,"title":"分布式训练并行策略选择","slug":"分布式训练并行策略选择","link":"#分布式训练并行策略选择","children":[{"level":3,"title":"8.1 单机单卡场景","slug":"_8-1-单机单卡场景","link":"#_8-1-单机单卡场景","children":[]},{"level":3,"title":"8.2 单机多卡场景","slug":"_8-2-单机多卡场景","link":"#_8-2-单机多卡场景","children":[]},{"level":3,"title":"8.3 多机多卡场景","slug":"_8-3-多机多卡场景","link":"#_8-3-多机多卡场景","children":[]}]}],"git":{"createdTime":1745416391000,"updatedTime":1745416391000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-6.local","commits":1}]},"readingTime":{"minutes":18.52,"words":5557},"filePathRelative":"llm/03_llm_training/09_分布式训练框架.md","localizedDate":"April 23, 2025","excerpt":"<h1> 分布式训练框架</h1>\\n<p>训练框架对比</p>\\n<ul>\\n<li>小 (&lt;10B参数): torchrun/accelerate都行</li>\\n<li>中（10B-100B参数）: deepspeed</li>\\n<li>大（&gt;100参数）: 得上megatron</li>\\n</ul>\\n<h2> 0. Pytorch三种数据并行方案</h2>\\n<ul>\\n<li>DP（torch.nn.DataParallel）\\n<ul>\\n<li>目前，基本上 DP 已经被弃用</li>\\n<li>DP只用于单机情况（单进程多线程模式），不支持多级多卡</li>\\n<li>使用普通的All-Reduce机制</li>\\n</ul>\\n</li>\\n<li>DDP（torch.nn.DistributedDataParallel）\\n<ul>\\n<li>相较于DP，DDP传输的数据量更少，训练更高效</li>\\n<li>DDP适用于单机和多机情况，真正实现分布式训练</li>\\n<li>DDP数据传输过程：\\n<ul>\\n<li>前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。</li>\\n<li>DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致</li>\\n</ul>\\n</li>\\n<li>不足：要求整个模型加载到一个GPU上</li>\\n</ul>\\n</li>\\n<li>FSDP（torch.distributed.fsdp.FullyShardedDataParallel）\\n<ul>\\n<li>PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感</li>\\n<li>是一种新型数据并行训练方法</li>\\n<li>将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{e as data};

import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as i,c as n,a as s,b as a,e as l}from"./app-dh4YKh5Y.js";const t="/pinkpig/assets/image-34-cKsnkMGe.png",r="/pinkpig/assets/image-35-TEU1zO5m.png",m="/pinkpig/assets/image-36-v8tiPeNx.png",o="/pinkpig/assets/image-37-1gkyK4Ur.png",p="/pinkpig/assets/image-38-iB_PIUzc.png",c="/pinkpig/assets/image-39-lCoFy-b4.png",g={},d=s("h1",{id:"微调",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#微调","aria-hidden":"true"},"#"),a(" 微调")],-1),h=s("p",null,"SFT在LLM中应用的重要原因",-1),u=s("ul",null,[s("li",null,"特定性能提升"),s("li",null,"领域适应性"),s("li",null,"数据稀缺性")],-1),_=s("p",null,"SFT数据重要性",-1),x=s("ul",null,[s("li",null,"数据质量 > 数据规模"),s("li",null,[a("挑选质量较高的数据，可以有效提高模型的性能 "),s("ul",null,[s("li",null,"数据质量可以通过ppl、reward model，文本质量分类模型等方式进行初步评估。经过人工进行后续筛选。")])]),s("li",null,"多样性的数据可以提高模型性能"),s("li",null,[a("数据结构 "),s("ul",null,[s("li",null,"问题和响应"),s("li",{"prompt:请帮我计算1+1等于几。,response:“2":""})])]),s("li",null,[a("是否使用含思维链（Reasoning_Content）数据 "),s("ul",null,[s("li",null,[a("使用深度推理模型，包括思维链数据 "),s("ul",null,[s("li",null,"使用DeepSeek-R1推理时，会生成思维链数据"),s("li",null,"如果用含思维链数据（Reasoning_Content）训练 建议使用DeepSeek-R1及DeepSeek-R1-Distill系列的深度推理模型"),s("li",{"prompt:请帮我计算1+1等于几。,reasoning_content:1加1在基本的十进制算术中等于2。,response:2":""})])])])])],-1),f=l('<p>SFT训练方式</p><ul><li>全量更新 <ul><li>全量更新在训练过程中对大模型的全部参数进行更新</li></ul></li><li>LoRA <ul><li>在固定预训练大模型本身的参数的基础上，在保留自注意力模块中原始权重矩阵的基础上，对权重矩阵进行低秩分解，训练过程中只更新低秩部分的参数</li></ul></li></ul><h2 id="peft" tabindex="-1"><a class="header-anchor" href="#peft" aria-hidden="true">#</a> PEFT</h2><p>PEFT 只微调少量或者额外的参数，降低计算、存储成本</p><p>PEFT 有什么优点？</p><ul><li>减少计算和存储成本：PEFT只涉及微调少量额外的模型参数，而冻结预训练llm的大部分参数，从而显着降低计算和存储成本</li><li>克服灾难性遗忘：在LLM的全面微调期间，灾难性遗忘可能发生在模型忘记它在预训练期间学到的知识的地方。PEFT通过只更新几个参数来克服这个问题。</li><li>低数据环境下更好的性能：PEFT方法在低数据环境下的表现优于完全微调，并且可以更好地推广到域外场景。</li><li>可移植性：与全面微调的大检查点相比，PEFT方法使用户能够获得价值几mb的小检查点。这使得来自PEFT方法的训练权重易于部署和用于多个任务，而无需替换整个模型。</li><li>与完全微调相当的性能：PEFT仅使用少量可训练参数即可实现与完全微调相当的性能。</li></ul><h2 id="lora" tabindex="-1"><a class="header-anchor" href="#lora" aria-hidden="true">#</a> LoRA</h2><p>神经网络包含很多全连接层，其借助于矩阵乘法得以实现，然而，很多全连接层的权重矩阵都是满秩的。</p><p>LoRA（论文：<strong>LoRA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</strong>），该方法的核心思想就是<strong>通过低秩分解来模拟参数的改变量，从而以极小的参数量来实现大模型的间接训练。</strong></p><p>在涉及到矩阵相乘的模块，在原始的PLM旁边增加一个新的通路，通过前后两个矩阵A,B相乘，第一个矩阵A负责降维，第二个矩阵B负责升维，中间层维度为r。</p><figure><img src="'+t+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>可训练层维度和预训练模型层维度一致为<code>d</code>，先将维度<code>d</code>通过全连接层降维至<code>r</code>，再从<code>r</code>通过全连接层映射回<code>d</code>维度，其中，<code>r&lt;&lt;d</code>，r是矩阵的秩，这样矩阵计算就从<code>d x d</code>变为<code>d x r + r x d</code>，参数量减少很多。</p><figure><img src="'+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在下游任务训练时，固定模型的其他参数，只优化新增的两个矩阵的权重参数，将PLM（pre-trained language models，预训练语言模型）跟新增的通路两部分的结果加起来作为最终的结果（两边通路的输入跟输出维度是一致的），即<code>h=Wx+BAx</code>。第一个矩阵的A的权重参数会通过高斯函数初始化，而第二个矩阵的B的权重参数则会初始化为零矩阵，这样能保证训练开始时新增的通路BA=0从而对模型结果没有影响。</p>',14),y=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"h"),s("mo",null,"="),s("msub",null,[s("mi",null,"W"),s("mn",null,"0")]),s("mi",null,"x"),s("mo",null,"+"),s("mi",{mathvariant:"normal"},"Δ"),s("mi",null,"W"),s("mi",null,"x"),s("mo",null,"="),s("msub",null,[s("mi",null,"W"),s("mn",null,"0")]),s("mi",null,"x"),s("mo",null,"+"),s("mi",null,"B"),s("mi",null,"A"),s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"}," h=W_{0} x+\\Delta W x=W_{0} x+B A x ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"h"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord"},"Δ"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"x")])])])])],-1),b=l('<p>在推理时，将左右两部分的结果加到一起即可，<code>h=Wx+BAx=(W+BA)x</code>，所以只要将训练完成的矩阵乘积<code>BA</code>跟原本的权重矩阵<code>W</code>加到一起作为新权重参数替换原本PLM的W即可，对于推理来说，不会增加额外的计算资源。</p><ul><li>实验还发现，保证权重矩阵的种类的数量比起增加隐藏层维度r更为重要，增加r并不一定能覆盖更加有意义的子空间。</li><li>通过实验也发现，在众多数据集上LoRA在只训练极少量参数的前提下，最终在性能上能和全量微调匹配，甚至在某些任务上优于全量微调。</li></ul><figure><img src="'+m+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="'+o+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="qlora" tabindex="-1"><a class="header-anchor" href="#qlora" aria-hidden="true">#</a> QLoRA</h2><p>QLORA 有一种低精度存储数据类型（4 bit），还有一种计算数据类型（BFloat16）。</p><p>实际上，这意味着无论何时使用 QLoRA 权重张量，我们都会将张量反量化为 BFloat16，然后执行 16 位矩阵乘法。</p><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',9),A=[d,h,u,_,x,f,y,b];function k(v,L){return i(),n("div",null,A)}const T=e(g,[["render",k],["__file","04_微调.html.vue"]]);export{T as default};

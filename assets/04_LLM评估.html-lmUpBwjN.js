const l=JSON.parse('{"key":"v-35edf79c","path":"/llm/04_llm_reasoning/04_LLM%E8%AF%84%E4%BC%B0.html","title":"LLM 评估 与 常见问题","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"LLM 评估 与 常见问题 模型评估 Automated benchmarks 自动评测/自动规则打分 使用精选数据集和指标（如 MMLU）评估特定任务上的模型。它非常适合具体任务，但抽象和创造能力较差。它也容易受到数据污染 使用预置的相似度或准确率打分规则对比模型生成结果与真实标注的差异，从而计算模型指标 Model-based evaluation 模型评测/自动裁判员打分 使用判断和奖励模型来评估模型输出。它与人类偏好高度相关，但受到对其自身输出的偏见和不一致的评分的影响 使用能力更强的大模型作为裁判员，对被评估模型的生成结果进行自动化打分，适用于开放性或复杂问答场景。 提供以下自动裁判员指标：事实性错误、情感倾向性和语义连贯性。 允许您自定义打分Prompt，设置自定义评估指标 Human evaluation 人工评测 它涉及人工提示模型并对响应进行评分。方法包括从氛围检查到具有特定指导方针的系统注释和大规模社区投票（竞技场）。它更适合主观任务，但事实准确性较不可靠 人工评估可综合人类专家的主观见解、经验等从不同评价维度对模型回复进行打分，用于评估模型回复的效果 GSB对比评估（两两对比或多个模型对比） 人工打分规则配置（配置多个维度，人工从多个方面多个维度进行打分） Feedback signal : 分析错误模式以识别特定弱点，例如遵循复杂指令的局限性、缺乏特定知识或易受对抗性提示的影响。这可以通过更好的数据生成和训练参数来改进","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/04_llm_reasoning/04_LLM%E8%AF%84%E4%BC%B0.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"LLM 评估 与 常见问题"}],["meta",{"property":"og:description","content":"LLM 评估 与 常见问题 模型评估 Automated benchmarks 自动评测/自动规则打分 使用精选数据集和指标（如 MMLU）评估特定任务上的模型。它非常适合具体任务，但抽象和创造能力较差。它也容易受到数据污染 使用预置的相似度或准确率打分规则对比模型生成结果与真实标注的差异，从而计算模型指标 Model-based evaluation 模型评测/自动裁判员打分 使用判断和奖励模型来评估模型输出。它与人类偏好高度相关，但受到对其自身输出的偏见和不一致的评分的影响 使用能力更强的大模型作为裁判员，对被评估模型的生成结果进行自动化打分，适用于开放性或复杂问答场景。 提供以下自动裁判员指标：事实性错误、情感倾向性和语义连贯性。 允许您自定义打分Prompt，设置自定义评估指标 Human evaluation 人工评测 它涉及人工提示模型并对响应进行评分。方法包括从氛围检查到具有特定指导方针的系统注释和大规模社区投票（竞技场）。它更适合主观任务，但事实准确性较不可靠 人工评估可综合人类专家的主观见解、经验等从不同评价维度对模型回复进行打分，用于评估模型回复的效果 GSB对比评估（两两对比或多个模型对比） 人工打分规则配置（配置多个维度，人工从多个方面多个维度进行打分） Feedback signal : 分析错误模式以识别特定弱点，例如遵循复杂指令的局限性、缺乏特定知识或易受对抗性提示的影响。这可以通过更好的数据生成和训练参数来改进"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-23T13:53:11.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-04-23T13:53:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM 评估 与 常见问题\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-04-23T13:53:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"模型评估","slug":"模型评估","link":"#模型评估","children":[{"level":3,"title":"评估数据集 就是 测试集","slug":"评估数据集-就是-测试集","link":"#评估数据集-就是-测试集","children":[]},{"level":3,"title":"人工评测 ———— GSB对比评估","slug":"人工评测-————-gsb对比评估","link":"#人工评测-————-gsb对比评估","children":[]},{"level":3,"title":"基线评测","slug":"基线评测","link":"#基线评测","children":[]}]},{"level":2,"title":"常见问题一：LLM 幻觉","slug":"常见问题一-llm-幻觉","link":"#常见问题一-llm-幻觉","children":[]},{"level":2,"title":"常见问题二：LLM 重复 / LLM 复读机问题","slug":"常见问题二-llm-重复-llm-复读机问题","link":"#常见问题二-llm-重复-llm-复读机问题","children":[{"level":3,"title":"出现重复的原因","slug":"出现重复的原因","link":"#出现重复的原因","children":[]},{"level":3,"title":"如何缓解问题","slug":"如何缓解问题","link":"#如何缓解问题","children":[]}]},{"level":2,"title":"常见问题三：为什么SFT之后感觉LLM傻了?","slug":"常见问题三-为什么sft之后感觉llm傻了","link":"#常见问题三-为什么sft之后感觉llm傻了","children":[]},{"level":2,"title":"常见问题四：灾难性遗忘","slug":"常见问题四-灾难性遗忘","link":"#常见问题四-灾难性遗忘","children":[]},{"level":2,"title":"常见问题四：领域模型词表扩增是不是有必要的？","slug":"常见问题四-领域模型词表扩增是不是有必要的","link":"#常见问题四-领域模型词表扩增是不是有必要的","children":[]}],"git":{"createdTime":1743233581000,"updatedTime":1745416391000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-2.local","commits":1},{"name":"liz","email":"liz@MacBook-Pro-6.local","commits":1}]},"readingTime":{"minutes":13.19,"words":3957},"filePathRelative":"llm/04_llm_reasoning/04_LLM评估.md","localizedDate":"March 29, 2025","excerpt":"<h1> LLM 评估 与 常见问题</h1>\\n<h2> 模型评估</h2>\\n<ul>\\n<li>Automated benchmarks 自动评测/自动规则打分\\n<ul>\\n<li>使用精选数据集和指标（如 MMLU）评估特定任务上的模型。它非常适合具体任务，但抽象和创造能力较差。它也容易受到数据污染</li>\\n<li>使用预置的相似度或准确率打分规则对比模型生成结果与真实标注的差异，从而计算模型指标</li>\\n</ul>\\n</li>\\n<li>Model-based evaluation 模型评测/自动裁判员打分\\n<ul>\\n<li>使用判断和奖励模型来评估模型输出。它与人类偏好高度相关，但受到对其自身输出的偏见和不一致的评分的影响</li>\\n<li>使用能力更强的大模型作为裁判员，对被评估模型的生成结果进行自动化打分，适用于开放性或复杂问答场景。</li>\\n<li>提供以下自动裁判员指标：事实性错误、情感倾向性和语义连贯性。</li>\\n<li>允许您自定义打分Prompt，设置自定义评估指标</li>\\n</ul>\\n</li>\\n<li>Human evaluation 人工评测\\n<ul>\\n<li>它涉及人工提示模型并对响应进行评分。方法包括从氛围检查到具有特定指导方针的系统注释和大规模社区投票（竞技场）。它更适合主观任务，但事实准确性较不可靠</li>\\n<li>人工评估可综合人类专家的主观见解、经验等从不同评价维度对模型回复进行打分，用于评估模型回复的效果</li>\\n<li>GSB对比评估（两两对比或多个模型对比）</li>\\n<li>人工打分规则配置（配置多个维度，人工从多个方面多个维度进行打分）</li>\\n</ul>\\n</li>\\n<li>Feedback signal : 分析错误模式以识别特定弱点，例如遵循复杂指令的局限性、缺乏特定知识或易受对抗性提示的影响。这可以通过更好的数据生成和训练参数来改进</li>\\n</ul>","autoDesc":true}');export{l as data};

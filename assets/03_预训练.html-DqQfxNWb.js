const e=JSON.parse('{"key":"v-5a9eb9d8","path":"/llm/03_llm_training/03_%E9%A2%84%E8%AE%AD%E7%BB%83.html","title":"预训练","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"预训练 PTM,Pre-trained Model(预训练模型) 1. 预训练、微调和强化学习 预训练学知识，指令微调学格式，强化学习对齐人类偏好 预训练阶段旨在通过大规模无标注文本建立模型的基础能力 微调阶段使用有标注数据对于模型进行特定任务的适配 目标 预训练：通用知识和理解能力 微调：特定任务；听懂指令 对齐：符合人类偏好 数据 预训练：无标签文本数据进行训练，例如维基百科、网页文本等 微调：带有标签的任务相关数据进行训练。这些数据通常是人工标注的，包含了输入文本和对应的标签或目标 训练方式 预训练：无监督 微调：有监督","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/03_llm_training/03_%E9%A2%84%E8%AE%AD%E7%BB%83.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"预训练"}],["meta",{"property":"og:description","content":"预训练 PTM,Pre-trained Model(预训练模型) 1. 预训练、微调和强化学习 预训练学知识，指令微调学格式，强化学习对齐人类偏好 预训练阶段旨在通过大规模无标注文本建立模型的基础能力 微调阶段使用有标注数据对于模型进行特定任务的适配 目标 预训练：通用知识和理解能力 微调：特定任务；听懂指令 对齐：符合人类偏好 数据 预训练：无标签文本数据进行训练，例如维基百科、网页文本等 微调：带有标签的任务相关数据进行训练。这些数据通常是人工标注的，包含了输入文本和对应的标签或目标 训练方式 预训练：无监督 微调：有监督"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-23T13:53:11.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-04-23T13:53:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"预训练\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-04-23T13:53:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. 预训练、微调和强化学习","slug":"_1-预训练、微调和强化学习","link":"#_1-预训练、微调和强化学习","children":[]},{"level":2,"title":"2. 预训练思想：共性学习","slug":"_2-预训练思想-共性学习","link":"#_2-预训练思想-共性学习","children":[]},{"level":2,"title":"3. 预训练模型用于下游任务的两种策略","slug":"_3-预训练模型用于下游任务的两种策略","link":"#_3-预训练模型用于下游任务的两种策略","children":[{"level":3,"title":"3.1. Fixed Feature Extractor(固定特征提取器)","slug":"_3-1-fixed-feature-extractor-固定特征提取器","link":"#_3-1-fixed-feature-extractor-固定特征提取器","children":[]},{"level":3,"title":"3.2. Fine-Tuning(微调)","slug":"_3-2-fine-tuning-微调","link":"#_3-2-fine-tuning-微调","children":[]}]},{"level":2,"title":"4. NLP预训练发展史","slug":"_4-nlp预训练发展史","link":"#_4-nlp预训练发展史","children":[]},{"level":2,"title":"5. 继续预训练 / 增量预训练","slug":"_5-继续预训练-增量预训练","link":"#_5-继续预训练-增量预训练","children":[{"level":3,"title":"5.1. 为什么要增量预训练？","slug":"_5-1-为什么要增量预训练","link":"#_5-1-为什么要增量预训练","children":[]},{"level":3,"title":"5.2. 进行增量预训练需要做哪些准备工作？","slug":"_5-2-进行增量预训练需要做哪些准备工作","link":"#_5-2-进行增量预训练需要做哪些准备工作","children":[]},{"level":3,"title":"5.3. 增量预训练所用训练框架？","slug":"_5-3-增量预训练所用训练框架","link":"#_5-3-增量预训练所用训练框架","children":[]},{"level":3,"title":"5.4. 增量预训练数据选取思路有哪些？","slug":"_5-4-增量预训练数据选取思路有哪些","link":"#_5-4-增量预训练数据选取思路有哪些","children":[]},{"level":3,"title":"5.5. 增量预训练训练流程是怎么样？","slug":"_5-5-增量预训练训练流程是怎么样","link":"#_5-5-增量预训练训练流程是怎么样","children":[]},{"level":3,"title":"5.6. 领域模型Continue PreTrain 数据选取？","slug":"_5-6-领域模型continue-pretrain-数据选取","link":"#_5-6-领域模型continue-pretrain-数据选取","children":[]}]}],"git":{"createdTime":1743175521000,"updatedTime":1745416391000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-6.local","commits":1},{"name":"liz","email":"liz@MacBook-Pro.local","commits":1}]},"readingTime":{"minutes":6.29,"words":1886},"filePathRelative":"llm/03_llm_training/03_预训练.md","localizedDate":"March 28, 2025","excerpt":"<h1> 预训练</h1>\\n<ul>\\n<li>PTM,Pre-trained Model(预训练模型)</li>\\n</ul>\\n<h2> 1. 预训练、微调和强化学习</h2>\\n<p><strong>预训练学知识，指令微调学格式，强化学习对齐人类偏好</strong></p>\\n<p>预训练阶段旨在通过大规模无标注文本建立模型的基础能力</p>\\n<p>微调阶段使用有标注数据对于模型进行特定任务的适配</p>\\n<p>目标</p>\\n<ul>\\n<li>预训练：通用知识和理解能力</li>\\n<li>微调：特定任务；听懂指令</li>\\n<li>对齐：符合人类偏好\\n数据</li>\\n<li>预训练：无标签文本数据进行训练，例如维基百科、网页文本等</li>\\n<li>微调：带有标签的任务相关数据进行训练。这些数据通常是人工标注的，包含了输入文本和对应的标签或目标\\n训练方式</li>\\n<li>预训练：无监督</li>\\n<li>微调：有监督</li>\\n</ul>","autoDesc":true}');export{e as data};

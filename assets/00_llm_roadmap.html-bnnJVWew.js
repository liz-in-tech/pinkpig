const l=JSON.parse('{"key":"v-8ec2695a","path":"/llm/00_llm_roadmap.html","title":"LLM Roadmap","lang":"en-US","frontmatter":{"icon":"lightbulb","description":"LLM Roadmap 1. LLM 基础（Done，不要从头学了，只需在实践中查漏补缺） Mathematics for ML 线性代数 向量、矩阵、行列式、特征值和特征向量、向量空间和线性变换 概率论 微积分 导数、积分、极限和级数、多元微积分和梯度 Python for ML Python Basics 基本语法、数据类型、错误处理和面向对象编程 Data Science Libraries NumPy 用于数值运算 Pandas 用于数据操作和分析 Matplotlib 和 Seaborn 用于数据可视化 Data Preprocessing 涉及特征缩放和规范化、处理缺失数据、异常值检测、分类数据编码以及将数据分成训练、验证和测试集 ML Libraries 熟练掌握 Scikit-learn（一个提供多种监督和非监督学习算法的库）至关重要。了解如何实现线性回归、逻辑回归、决策树、随机森林、k-最近邻 (K-NN) 和 K-均值聚类等算法非常重要。PCA 和 t-SNE 等降维技术也有助于可视化高维数据。 Neural Networks Fundamentals 理解神经网络的结构，例如层、权重、偏差和激活函数（sigmoid、tanh、ReLU 等）。 梯度爆炸和梯度消失 Overfitting 过拟合 Training and Optimization 熟悉反向传播和不同类型的损失函数，了解各种优化算法，如梯度下降、随机梯度下降 和 Adam。 NLP 分词（文本token化）：Text Preprocessing / Tokenizer 学习各种文本预处理步骤，如标记化（将文本分成单词或句子）、词干提取（将单词简化为其词根形式）、词形还原（类似于词干提取但考虑上下文）、停用词删除等 特征提取：Feature Extraction Techniques 熟悉将文本数据转换为机器学习算法可以理解的格式的技术。主要方法包括词袋 (BoW)、词频-逆文档频率 (TF-IDF) 和 n-gram。 嵌入（token向量化）：Word Embeddings / Word2Vec 词嵌入是一种词语表示方法，可以让具有相似含义的词语具有相似的表示。主要方法包括 Word2Vec、GloVe 和 FastText。 NLP三大特征抽取器 Transformer RNN 了解 RNN 的工作原理，RNN 是一种用于处理序列数据的神经网络。探索 LSTM 和 GRU，这两种 RNN 变体都能够学习长期依赖关系。 CNN NLP预训练发展史：图像预训练 → word embedding → word2vec → elmo → transformer → gpt → bert → GPT 234","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/00_llm_roadmap.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"LLM Roadmap"}],["meta",{"property":"og:description","content":"LLM Roadmap 1. LLM 基础（Done，不要从头学了，只需在实践中查漏补缺） Mathematics for ML 线性代数 向量、矩阵、行列式、特征值和特征向量、向量空间和线性变换 概率论 微积分 导数、积分、极限和级数、多元微积分和梯度 Python for ML Python Basics 基本语法、数据类型、错误处理和面向对象编程 Data Science Libraries NumPy 用于数值运算 Pandas 用于数据操作和分析 Matplotlib 和 Seaborn 用于数据可视化 Data Preprocessing 涉及特征缩放和规范化、处理缺失数据、异常值检测、分类数据编码以及将数据分成训练、验证和测试集 ML Libraries 熟练掌握 Scikit-learn（一个提供多种监督和非监督学习算法的库）至关重要。了解如何实现线性回归、逻辑回归、决策树、随机森林、k-最近邻 (K-NN) 和 K-均值聚类等算法非常重要。PCA 和 t-SNE 等降维技术也有助于可视化高维数据。 Neural Networks Fundamentals 理解神经网络的结构，例如层、权重、偏差和激活函数（sigmoid、tanh、ReLU 等）。 梯度爆炸和梯度消失 Overfitting 过拟合 Training and Optimization 熟悉反向传播和不同类型的损失函数，了解各种优化算法，如梯度下降、随机梯度下降 和 Adam。 NLP 分词（文本token化）：Text Preprocessing / Tokenizer 学习各种文本预处理步骤，如标记化（将文本分成单词或句子）、词干提取（将单词简化为其词根形式）、词形还原（类似于词干提取但考虑上下文）、停用词删除等 特征提取：Feature Extraction Techniques 熟悉将文本数据转换为机器学习算法可以理解的格式的技术。主要方法包括词袋 (BoW)、词频-逆文档频率 (TF-IDF) 和 n-gram。 嵌入（token向量化）：Word Embeddings / Word2Vec 词嵌入是一种词语表示方法，可以让具有相似含义的词语具有相似的表示。主要方法包括 Word2Vec、GloVe 和 FastText。 NLP三大特征抽取器 Transformer RNN 了解 RNN 的工作原理，RNN 是一种用于处理序列数据的神经网络。探索 LSTM 和 GRU，这两种 RNN 变体都能够学习长期依赖关系。 CNN NLP预训练发展史：图像预训练 → word embedding → word2vec → elmo → transformer → gpt → bert → GPT 234"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-03-29T07:33:01.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-03-29T07:33:01.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM Roadmap\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-29T07:33:01.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. LLM 基础（Done，不要从头学了，只需在实践中查漏补缺）","slug":"_1-llm-基础-done-不要从头学了-只需在实践中查漏补缺","link":"#_1-llm-基础-done-不要从头学了-只需在实践中查漏补缺","children":[]},{"level":2,"title":"2. LLM 架构（Done，不要从头学了，只需在实践中查漏补缺）","slug":"_2-llm-架构-done-不要从头学了-只需在实践中查漏补缺","link":"#_2-llm-架构-done-不要从头学了-只需在实践中查漏补缺","children":[]},{"level":2,"title":"3. LLM 训练（专注于LLM的训练和推理，有待加强，训练部分最重要的是分布式训练和强化学习）","slug":"_3-llm-训练-专注于llm的训练和推理-有待加强-训练部分最重要的是分布式训练和强化学习","link":"#_3-llm-训练-专注于llm的训练和推理-有待加强-训练部分最重要的是分布式训练和强化学习","children":[{"level":3,"title":"3.1. LLM 数据工程","slug":"_3-1-llm-数据工程","link":"#_3-1-llm-数据工程","children":[]},{"level":3,"title":"3.2. 分布式训练","slug":"_3-2-分布式训练","link":"#_3-2-分布式训练","children":[]},{"level":3,"title":"3.3. 有监督微调","slug":"_3-3-有监督微调","link":"#_3-3-有监督微调","children":[]},{"level":3,"title":"3.4. 强化学习 & 人类偏好对齐","slug":"_3-4-强化学习-人类偏好对齐","link":"#_3-4-强化学习-人类偏好对齐","children":[]},{"level":3,"title":"3.5. 训练参数","slug":"_3-5-训练参数","link":"#_3-5-训练参数","children":[]},{"level":3,"title":"3.6. 训练监控","slug":"_3-6-训练监控","link":"#_3-6-训练监控","children":[]}]},{"level":2,"title":"4. LLM 推理（专注于LLM的训练和推理，有待加强，推理部分重点是加速优化）","slug":"_4-llm-推理-专注于llm的训练和推理-有待加强-推理部分重点是加速优化","link":"#_4-llm-推理-专注于llm的训练和推理-有待加强-推理部分重点是加速优化","children":[{"level":3,"title":"4.1. 训练和推理的加速优化","slug":"_4-1-训练和推理的加速优化","link":"#_4-1-训练和推理的加速优化","children":[]},{"level":3,"title":"4.2. LLM 压缩","slug":"_4-2-llm-压缩","link":"#_4-2-llm-压缩","children":[]},{"level":3,"title":"4.3. LLM 部署","slug":"_4-3-llm-部署","link":"#_4-3-llm-部署","children":[]},{"level":3,"title":"4.4. LLM 评估","slug":"_4-4-llm-评估","link":"#_4-4-llm-评估","children":[]}]},{"level":2,"title":"5. LLM应用开发（Done，不要从头学了，只需在实践中查漏补缺）","slug":"_5-llm应用开发-done-不要从头学了-只需在实践中查漏补缺","link":"#_5-llm应用开发-done-不要从头学了-只需在实践中查漏补缺","children":[{"level":3,"title":"5.1. LLM APIs","slug":"_5-1-llm-apis","link":"#_5-1-llm-apis","children":[]},{"level":3,"title":"5.2. 开源 LLMs","slug":"_5-2-开源-llms","link":"#_5-2-开源-llms","children":[]},{"level":3,"title":"5.3. Prompt Engineering","slug":"_5-3-prompt-engineering","link":"#_5-3-prompt-engineering","children":[]},{"level":3,"title":"5.4. Agent & RAG","slug":"_5-4-agent-rag","link":"#_5-4-agent-rag","children":[]}]}],"git":{"createdTime":1743175521000,"updatedTime":1743233581000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-2.local","commits":1},{"name":"liz","email":"liz@MacBook-Pro.local","commits":1}]},"readingTime":{"minutes":6.59,"words":1977},"filePathRelative":"llm/00_llm_roadmap.md","localizedDate":"March 28, 2025","excerpt":"<h1> LLM Roadmap</h1>\\n<h2> 1. LLM 基础（Done，不要从头学了，只需在实践中查漏补缺）</h2>\\n<ul>\\n<li>Mathematics for ML\\n<ul>\\n<li>线性代数\\n<ul>\\n<li>向量、矩阵、行列式、特征值和特征向量、向量空间和线性变换</li>\\n</ul>\\n</li>\\n<li>概率论</li>\\n<li>微积分\\n<ul>\\n<li>导数、积分、极限和级数、多元微积分和梯度</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n<li>Python for ML\\n<ul>\\n<li>Python Basics\\n<ul>\\n<li>基本语法、数据类型、错误处理和面向对象编程</li>\\n</ul>\\n</li>\\n<li>Data Science Libraries\\n<ul>\\n<li>NumPy 用于数值运算</li>\\n<li>Pandas 用于数据操作和分析</li>\\n<li>Matplotlib 和 Seaborn 用于数据可视化</li>\\n</ul>\\n</li>\\n<li>Data Preprocessing\\n<ul>\\n<li>涉及特征缩放和规范化、处理缺失数据、异常值检测、分类数据编码以及将数据分成训练、验证和测试集</li>\\n</ul>\\n</li>\\n<li>ML Libraries\\n<ul>\\n<li>熟练掌握 Scikit-learn（一个提供多种监督和非监督学习算法的库）至关重要。了解如何实现线性回归、逻辑回归、决策树、随机森林、k-最近邻 (K-NN) 和 K-均值聚类等算法非常重要。PCA 和 t-SNE 等降维技术也有助于可视化高维数据。</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n<li>Neural Networks\\n<ul>\\n<li>Fundamentals\\n<ul>\\n<li>理解神经网络的结构，例如层、权重、偏差和激活函数（sigmoid、tanh、ReLU 等）。</li>\\n</ul>\\n</li>\\n<li>梯度爆炸和梯度消失</li>\\n<li>Overfitting 过拟合</li>\\n<li>Training and Optimization\\n<ul>\\n<li>熟悉反向传播和不同类型的损失函数，了解各种优化算法，如梯度下降、随机梯度下降 和 Adam。</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n<li>NLP\\n<ul>\\n<li>分词（文本token化）：Text Preprocessing / Tokenizer\\n<ul>\\n<li>学习各种文本预处理步骤，如标记化（将文本分成单词或句子）、词干提取（将单词简化为其词根形式）、词形还原（类似于词干提取但考虑上下文）、停用词删除等</li>\\n</ul>\\n</li>\\n<li>特征提取：Feature Extraction Techniques\\n<ul>\\n<li>熟悉将文本数据转换为机器学习算法可以理解的格式的技术。主要方法包括词袋 (BoW)、词频-逆文档频率 (TF-IDF) 和 n-gram。</li>\\n</ul>\\n</li>\\n<li>嵌入（token向量化）：Word Embeddings / Word2Vec\\n<ul>\\n<li>词嵌入是一种词语表示方法，可以让具有相似含义的词语具有相似的表示。主要方法包括 Word2Vec、GloVe 和 FastText。</li>\\n</ul>\\n</li>\\n<li>NLP三大特征抽取器\\n<ul>\\n<li>Transformer</li>\\n<li>RNN\\n<ul>\\n<li>了解 RNN 的工作原理，RNN 是一种用于处理序列数据的神经网络。探索 LSTM 和 GRU，这两种 RNN 变体都能够学习长期依赖关系。</li>\\n</ul>\\n</li>\\n<li>CNN</li>\\n</ul>\\n</li>\\n<li>NLP预训练发展史：图像预训练 → word embedding → word2vec → elmo → transformer → gpt → bert → GPT 234</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{l as data};

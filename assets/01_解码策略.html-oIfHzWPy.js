import{_ as i}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as e,e as n}from"./app-dh4YKh5Y.js";const t="/pinkpig/assets/llm_011-gbtzkgou.png",p="/pinkpig/assets/llm_019-1ioqISvB.png",r="/pinkpig/assets/llm_012-XFei3JOn.png",l="/pinkpig/assets/llm_013-_nIZFaGU.png",s="/pinkpig/assets/nlp_043-9x1VX4eO.png",o="/pinkpig/assets/llm_014-nNnzqH8B.png",d="/pinkpig/assets/llm_015-5TJljZXA.png",g="/pinkpig/assets/llm_016-NhIn4utT.png",h="/pinkpig/assets/llm_017-WaNxA2E2.png",c="/pinkpig/assets/llm_018-qRi5Lixr.png",_={},m=n('<h1 id="解码策略" tabindex="-1"><a class="header-anchor" href="#解码策略" aria-hidden="true">#</a> 解码策略</h1><h2 id="_1-解码的定义" tabindex="-1"><a class="header-anchor" href="#_1-解码的定义" aria-hidden="true">#</a> 1. 解码的定义</h2><p>在自回归架构中，模型针对输入内容逐个单词生成输出内容，这个过程一般被称为解码。</p><figure><img src="'+t+'" alt="自回归解码流程" tabindex="0" loading="lazy"><figcaption>自回归解码流程</figcaption></figure><p>在这个过程中，解码策略主要关注如何基于概率分布选择合适的下一个词</p><p>大语言模型的生成方式本质是一个概率采样过程，需要合适的解码策略来生成合适的输出内容。</p><h2 id="_2-代表性llm的解码设置" tabindex="-1"><a class="header-anchor" href="#_2-代表性llm的解码设置" aria-hidden="true">#</a> 2. 代表性LLM的解码设置</h2><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_3-常见解码策略" tabindex="-1"><a class="header-anchor" href="#_3-常见解码策略" aria-hidden="true">#</a> 3. 常见解码策略</h2><h3 id="_3-1-贪心搜索-greedy-search" tabindex="-1"><a class="header-anchor" href="#_3-1-贪心搜索-greedy-search" aria-hidden="true">#</a> 3.1. 贪心搜索（Greedy Search）</h3><p>选概率最高的token（确定性）</p><figure><img src="'+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>效果在不同类型的任务中具有一定的差异。</p><ul><li>在机器翻译和文本摘要等任务中，任务输出高度依赖于输入内容，贪心搜索通常能够获得不错的结果，</li><li>但是在开放式生成任务（如故事生成和对话系统）中，贪心搜索有时会因为过于关注局部最优，而生成不自然、重复的句子</li></ul><h4 id="_3-1-1-贪心搜索的改进策略" tabindex="-1"><a class="header-anchor" href="#_3-1-1-贪心搜索的改进策略" aria-hidden="true">#</a> 3.1.1. 贪心搜索的改进策略</h4><h5 id="_3-1-1-1-束搜索-beam-search" tabindex="-1"><a class="header-anchor" href="#_3-1-1-1-束搜索-beam-search" aria-hidden="true">#</a> 3.1.1.1. 束搜索（Beam Search）</h5><p>一般不采用贪心搜索，而采用此</p><p>保留前n个最高概率的token, 并最终选取整体概率最高的作为输出内容，这里的n被称为束大小（Beam Size）。</p><p>当 𝑛 = 1，束搜索就退化为贪心搜索</p><p>如n=2时，每步选择概率最高的2个token，生成结束后选择整体生成概率最高的候选句子作为最后的输出。</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在实践中，束的数量通常设定在 3 到 6 的范围内，设置过大的束会显著增加运算开销，并可能会导致性能下降</p><p>每一步都多选几个可能的序列作为候选，最后综合考虑，选出最优组合</p><p>Beam search作为一种剪枝策略，并不能保证得到全局最优解，但它能以较大的概率得到全局最优解，同时相比于穷举搜索极大的提高了搜索效率。</p><p>当beam search结束时，需要从n条完全路径中选一个打分最高的路径作为最终结果。</p><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h5 id="_3-1-1-2-长度惩罚-长度归一化-length-penalty" tabindex="-1"><a class="header-anchor" href="#_3-1-1-2-长度惩罚-长度归一化-length-penalty" aria-hidden="true">#</a> 3.1.1.2. 长度惩罚/长度归一化（Length Penalty）</h5><p>由于束搜索中需要比较不同长度候选句子的概率，如果没有长度惩罚，传统的束搜索会倾向于生成较短的句子，因为每生成一个单词，都会乘以一个小于 1的概率，使得句子的生成概率逐渐变小。</p><p>因此，可以在生成概率的计算中引入长度惩罚，通过将句子概率除以其长度的指数幂 𝛼，对于句子概率进行归一化处理，从而鼓励模型生成更长的句子。</p><p>在实践中，𝛼 通常设置为 0.6 到 0.7 之间的数值。</p><h5 id="_3-1-1-3-重复惩罚" tabindex="-1"><a class="header-anchor" href="#_3-1-1-3-重复惩罚" aria-hidden="true">#</a> 3.1.1.3. 重复惩罚</h5><p>为了缓解贪心搜索重复生成的问题，这些重复惩罚方法不止适用于贪心搜索，对于随机采样也均适用。</p><p>类型</p><ul><li>n-gram Penalty（n-元惩罚） <ul><li>强制避免生成重复的连续 𝑛 个词元，实践中 𝑛 通常设置为 3 到 5 之间的整数</li><li>“一刀切”地完全避免某些短语的生成</li></ul></li><li>Presence Penalty（出现惩罚） <ul><li>是否出现</li><li>出现惩罚在生成过程中会将已经生成词元的 logits 减去惩罚项 𝛼 来降低该词元之后生成的概率</li><li>在实践中，𝛼 的取值范围通常在 0.1 到 1 之间。</li><li>相对“温和”，而不是“一刀切”地完全避免某些短语的生成</li></ul></li><li>Frequency Penalty（频率惩罚） <ul><li>出现了几次</li><li>频率惩罚会记录每个词元生成的数目，然后减去出现次数乘以惩罚项 𝛼，因此如果一个词元生成得越多，惩罚也就越大</li><li>在实践中，𝛼 的取值范围通常在 0.1 到 1 之间。</li><li>相对“温和”，而不是“一刀切”地完全避免某些短语的生成</li></ul></li></ul><h3 id="_3-2-概率采样-随机采样-probability-sampling" tabindex="-1"><a class="header-anchor" href="#_3-2-概率采样-随机采样-probability-sampling" aria-hidden="true">#</a> 3.2. 概率采样/随机采样（Probability Sampling）</h3><p>概率分布采样（随机性和多样性）</p><p>基于采样的策略为选择除最高概率的其他词留有一定的可能性，从而增加了生成文本的多样性和随机性。</p><h4 id="_3-2-1-概率采样的改进策略" tabindex="-1"><a class="header-anchor" href="#_3-2-1-概率采样的改进策略" aria-hidden="true">#</a> 3.2.1. 概率采样的改进策略</h4><h5 id="_3-2-1-1-temperature-采样-temperature-sampling" tabindex="-1"><a class="header-anchor" href="#_3-2-1-1-temperature-采样-temperature-sampling" aria-hidden="true">#</a> 3.2.1.1. Temperature 采样（Temperature Sampling）</h5><p>调节softmax函数中的温度系数</p><figure><img src="'+o+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>其中，l表示每个候选词元的logit, t是温度系数</p><p>温度系数的大小对采样结果的影响：降低温度系数t会使得概率分布更加集中，从而增加了高概率词元的采样可能性，同时降低了低概率词元的采样可能</p><ul><li>而当 𝑡 趋近于 0 时，实际上等同于贪心搜索，即总是选择概率最高的词</li><li>当温度系数 𝑡 设置为 1 时，该公式退化为标准的随机采样方法</li><li>当 𝑡 趋近于无穷大时，温度采样会退化为均匀采样</li></ul><figure><img src="'+d+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h5 id="_3-2-1-2-top-k-采样-top-k-sampling" tabindex="-1"><a class="header-anchor" href="#_3-2-1-2-top-k-采样-top-k-sampling" aria-hidden="true">#</a> 3.2.1.2. Top-k 采样（Top-k Sampling）</h5><p>直接剔除概率较低的词元，限制模型从概率最高的前 𝑘 个token中进行采样</p><p>k=3，即从前3个概率最高的token中进行采样</p><figure><img src="'+g+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h5 id="_3-2-1-3-top-p-采样-核采样-top-p-sampling-nucleus-sampling" tabindex="-1"><a class="header-anchor" href="#_3-2-1-3-top-p-采样-核采样-top-p-sampling-nucleus-sampling" aria-hidden="true">#</a> 3.2.1.3. Top-p 采样 / 核采样（Top-p Sampling / Nucleus Sampling）</h5><p>累积概率小于或等于阈值p的前几个token中进行采样</p><p>具体实现：按照概率将token从高到低排序，不断将token添加到可选集合中，直到可选集合累积概率首次超过阈值p</p><p>p=0.8，即从累积概率小于等于0.8的前几个高概率的token中进行采样</p><figure><img src="'+h+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h5 id="_3-2-1-4-对比解码-contrastive-decoding" tabindex="-1"><a class="header-anchor" href="#_3-2-1-4-对比解码-contrastive-decoding" aria-hidden="true">#</a> 3.2.1.4. 对比解码（Contrastive Decoding）</h5><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',56),u=[m];function f(b,x){return a(),e("div",null,u)}const z=i(_,[["render",f],["__file","01_解码策略.html.vue"]]);export{z as default};

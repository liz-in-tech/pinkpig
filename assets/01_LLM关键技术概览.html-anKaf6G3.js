const e=JSON.parse('{"key":"v-510936bc","path":"/llm/03_llm_training/01_LLM%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88.html","title":"LLM 关键技术概览","lang":"en-US","frontmatter":{"description":"LLM 关键技术概览 1. 规模扩展 LLM的一个关键成功因素 扩展方向 参数扩展 数据（高质量数据）扩展 关键 : 实现规模扩展的关键在于模型架构的可扩展性。Transformer 模型的可扩展性非常强，对于硬件并行优化的支持也比较友好，特别适合大语言模型的研发，很多工作也在进一步针对其进行优化与改进。 2. 数据工程 在通用的预训练范式下，模型能力本质上是来源于所见过的训练数据，因此数据工程就变得极为重要，不是简单的扩大数据规模就能够实现的。","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/03_llm_training/01_LLM%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"LLM 关键技术概览"}],["meta",{"property":"og:description","content":"LLM 关键技术概览 1. 规模扩展 LLM的一个关键成功因素 扩展方向 参数扩展 数据（高质量数据）扩展 关键 : 实现规模扩展的关键在于模型架构的可扩展性。Transformer 模型的可扩展性非常强，对于硬件并行优化的支持也比较友好，特别适合大语言模型的研发，很多工作也在进一步针对其进行优化与改进。 2. 数据工程 在通用的预训练范式下，模型能力本质上是来源于所见过的训练数据，因此数据工程就变得极为重要，不是简单的扩大数据规模就能够实现的。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-03-28T15:25:21.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-03-28T15:25:21.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM 关键技术概览\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-28T15:25:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. 规模扩展","slug":"_1-规模扩展","link":"#_1-规模扩展","children":[]},{"level":2,"title":"2. 数据工程","slug":"_2-数据工程","link":"#_2-数据工程","children":[]},{"level":2,"title":"3. 高效预训练","slug":"_3-高效预训练","link":"#_3-高效预训练","children":[]},{"level":2,"title":"4. 能力激发","slug":"_4-能力激发","link":"#_4-能力激发","children":[]},{"level":2,"title":"5. 人类对齐","slug":"_5-人类对齐","link":"#_5-人类对齐","children":[]},{"level":2,"title":"6. 工具使用","slug":"_6-工具使用","link":"#_6-工具使用","children":[]}],"git":{"createdTime":1743175521000,"updatedTime":1743175521000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro.local","commits":1}]},"readingTime":{"minutes":3.28,"words":983},"filePathRelative":"llm/03_llm_training/01_LLM关键技术概览.md","localizedDate":"March 28, 2025","excerpt":"<h1> LLM 关键技术概览</h1>\\n<h2> 1. 规模扩展</h2>\\n<p>LLM的一个关键成功因素</p>\\n<ul>\\n<li>扩展方向\\n<ul>\\n<li>参数扩展</li>\\n<li>数据（高质量数据）扩展</li>\\n</ul>\\n</li>\\n</ul>\\n<p>关键 : 实现规模扩展的关键在于模型架构的可扩展性。Transformer 模型的可扩展性非常强，对于硬件并行优化的支持也比较友好，特别适合大语言模型的研发，很多工作也在进一步针对其进行优化与改进。</p>\\n<h2> 2. 数据工程</h2>\\n<p>在通用的预训练范式下，模型能力本质上是来源于所见过的训练数据，因此数据工程就变得极为重要，不是简单的扩大数据规模就能够实现的。</p>","autoDesc":true}');export{e as data};

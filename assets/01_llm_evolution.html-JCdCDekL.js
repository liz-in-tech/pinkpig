import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as l,e as i}from"./app-5kh03Iqc.js";const r="/pinkpig/assets/llm_001-PHe61ZsR.png",n={},d=i('<h1 id="llm发展历程" tabindex="-1"><a class="header-anchor" href="#llm发展历程" aria-hidden="true">#</a> LLM发展历程</h1><figure><img src="'+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_1-n-gram" tabindex="-1"><a class="header-anchor" href="#_1-n-gram" aria-hidden="true">#</a> 1. n-gram</h2><ul><li>具有固定上下文长度 𝑛 的统计语言模型</li><li>根据一个固定长度的前缀来预测目标单词（预测下一个词的出现概率）</li></ul><h2 id="_2-word-embedding-词嵌入-分布式词向量-稠密向量的非零表征-隐含语义的特征表示" tabindex="-1"><a class="header-anchor" href="#_2-word-embedding-词嵌入-分布式词向量-稠密向量的非零表征-隐含语义的特征表示" aria-hidden="true">#</a> 2. Word Embedding（“词嵌入”，分布式词向量，稠密向量的非零表征，隐含语义的特征表示）</h2><ul><li>what <ul><li>词转为对应的向量，用于在后续任务中提取语义特征</li><li>词向量表即词和向量一一对应的字典</li></ul></li></ul><h2 id="_3-预训练语言模型-pre-trained-language-model-plm" tabindex="-1"><a class="header-anchor" href="#_3-预训练语言模型-pre-trained-language-model-plm" aria-hidden="true">#</a> 3. 预训练语言模型（Pre-trained Language Model, PLM）</h2><ul><li>与早期的词嵌入模型相比，预训练语言模型在<strong>训练架构</strong>与<strong>训练数据</strong>两个方面进行了改进与创新</li><li>以 ELMo、BERT (Google)、GPT-1 (OpenAI) 为代表的预训练语言模型确立了“预训练-微调”这一任务求解范式。</li></ul><h2 id="_4-大语言模型-large-language-model-llm" tabindex="-1"><a class="header-anchor" href="#_4-大语言模型-large-language-model-llm" aria-hidden="true">#</a> 4. 大语言模型（Large Language Model, LLM）</h2><ul><li>大语言模型泛指具有<strong>超大规模参数</strong>或者经过<strong>超大规模数据</strong>训练所得到的语言模型 <ul><li>通常参数规模有10-1000B（百亿、千亿甚至万亿）</li><li>通常数据规模有1B (数十亿)</li></ul></li></ul>',10),o=[d];function t(s,g){return a(),l("div",null,o)}const _=e(n,[["render",t],["__file","01_llm_evolution.html.vue"]]);export{_ as default};

import{_ as i}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as l,f as t,a as e,b as o,e as r}from"./app-eTVGMpLM.js";const n="/pinkpig/assets/ai_development-CdUXyB5q.png",s={},d=e("h1",{id:"ai发展历程",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#ai发展历程","aria-hidden":"true"},"#"),o(" AI发展历程")],-1),c=r('<h2 id="_1-ai历史上的四次大发展" tabindex="-1"><a class="header-anchor" href="#_1-ai历史上的四次大发展" aria-hidden="true">#</a> 1. AI历史上的四次大发展</h2><figure><img src="'+n+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><h2 id="_2-里程碑事件" tabindex="-1"><a class="header-anchor" href="#_2-里程碑事件" aria-hidden="true">#</a> 2. 里程碑事件</h2><ul><li>1942年，艾萨克·阿西莫夫（IsaacAsimov）提出「机器人三大定律」</li><li>1943年，「神经网络」的提出</li><li>1950年，艾伦·图灵（Alan Turing）提出「图灵测试」</li><li>1956年，达特茅斯会议，正式提出「人工智能」概念</li><li>1960年代，人工智能进入了第一个高潮期，以逻辑理论为主要研究方向。当时研究人员尝试用形式逻辑来表达计算机的推理过程。</li><li>1969年，反向传播算法（BP）的提出</li><li>1970年代，人工智能的研究进入低谷期，这是因为早期的研究希望通过逻辑推理将人类的智能模拟出来，但是这种方法有着典型的符号主义问题，即无法处理模糊的语言和不确定性的情况。</li><li>1980年代，人工智能的研究开始从符号主义走向连接主义，也就是从逻辑推理转向神经网络。神经网络允许计算机通过学习来逐步改进自己的性能。</li><li>1990年代开始，人工智能进入了第二个高潮期。专家系统、机器学习、自然语言处理等技术不断得到改进和完善，计算机开始具备了更强的智能。</li><li>1997年，IBM的深蓝（Deep Blue）战胜国际象棋世界冠军加里·卡斯帕罗夫（Garry Kasparov）</li><li>2009年，李飞飞（Fei-Fei Li）创建了ImageNet数据集，是人工智能史上最大的数据集，包含 1500 万张图像，涉及 22000 个类别，为深度学习在计算机视觉领域的应用奠定了基础。</li><li>2011年，IBM的沃森（Watson）在著名的智力竞赛节目“Jeopardy”中击败了对手布拉德·拉特和肯·詹宁斯，成功赢取了100万美元的大奖</li><li>2011年，谷歌工程师杰夫·迪恩（Jeff Dean）和斯坦福大学计算机科学教授吴恩达（Andrew Ng），从YouTube视频中提取了1000万个未标记的图像，训练了一个由16，000个电脑处理器组成的庞大神经网络。除此之外，并没有给出任何识别信息，然而人工智能准确的通过深度学习算法识别出了猫科动物的照片。在计算机视觉任务中使用了神经网络和无监督学习，这个事件也标志着「谷歌大脑项目」（Google Brain Project）的开始</li><li>2012年，多伦多大学教授杰弗里·辛顿（Geoffrey Hinton）和他的两个学生建立了名为 AlexNet 的计算机视觉神经网络模型，在著名的 ImageNet 的图像识别大赛中，AlexNet 一举夺冠。这次夺冠影响极其深远，使深度神经网络得以复兴，也为辛顿赢得了「深度学习教父」的绰号。</li><li>2016年，DeepMind的AlphaGo战胜围棋世界冠军李世石（Lee Sedol），通过这次事件，真正的掀起了人工智能AI热潮</li><li>2017年，Google在论文《Attention is All You Need》中提出了Transformer架构，该架构摒弃了传统的循环神经网络（RNN）用于序列建模，转而采用自注意力机制，极大地提升了自然语言处理任务如机器翻译的性能。</li><li>2018年，Google推出预训练模型BERT，首次实现了大规模双向Transformer结构的预训练，并在多种NLP下游任务上取得了当时最先进的效果，开启了NLP领域的预训练模型时代。</li><li>2019年，OpenAI发布了GPT-3模型，它是当时参数量最大的预训练语言模型之一，展现出强大的文本生成和理解能力，进一步推动了大模型在NLP领域的应用。</li><li>2022年，OpenAI推出ChatGPT，虽然ChatGPT是在2022年末推出的，但其影响力一直延续到2024年甚至更远，成为人机交互和对话系统的重大突破，预示着未来智能助手和AI客服的新标准。</li></ul>',4);function h(_,f){return a(),l("div",null,[d,t(" more "),c])}const u=i(s,[["render",h],["__file","AI_evolution.html.vue"]]);export{u as default};

const N=JSON.parse('{"key":"v-5a2c0f2a","path":"/llm/01_llm_basic/06_nlp.html","title":"NLP","lang":"en-US","frontmatter":{"description":"NLP NLP三大特征抽取器比较(CNN/RNN/Transformer) 结论：RNN已经基本完成它的历史使命，将来会逐步退出历史舞台；CNN如果改造得当，将来还是有希望有自己在NLP领域的一席之地；而Transformer明显会很快成为NLP里担当大任的最主流的特征抽取器。 NLP任务的特点：输入是个一维线性序列；输入不定长；单词或句子的位置关系很重要；句子中长距离特征对于语义理解也很重要。 三大抽取器比较 语义特征提取能力：TF &gt; RNN/CNN Transformer在这方面的能力非常显著地超过RNN和CNN，RNN和CNN两者能力差不太多。 长距离特征捕获能力：TF/RNN &gt; CNN 原生CNN特征抽取器在这方面极为显著地弱于RNN和Transformer 任务综合特征抽取能力（机器翻译）：TF &gt; RNN/CNN Transformer综合能力要明显强于RNN和CNN，而RNN和CNN看上去表现基本相当，貌似CNN表现略好一些。 并行计算能力及运行效率：TF/CNN &gt; RNN RNN在并行计算方面有严重缺陷，这是它本身的序列依赖特性导致的；对于CNN和Transformer来说，因为它们不存在网络中间状态不同时间步输入的依赖关系，所以可以非常方便及自由地做并行计算改造。Transformer和CNN差不多，都远远远远强于RNN。","head":[["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/pinkpig/llm/01_llm_basic/06_nlp.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"NLP"}],["meta",{"property":"og:description","content":"NLP NLP三大特征抽取器比较(CNN/RNN/Transformer) 结论：RNN已经基本完成它的历史使命，将来会逐步退出历史舞台；CNN如果改造得当，将来还是有希望有自己在NLP领域的一席之地；而Transformer明显会很快成为NLP里担当大任的最主流的特征抽取器。 NLP任务的特点：输入是个一维线性序列；输入不定长；单词或句子的位置关系很重要；句子中长距离特征对于语义理解也很重要。 三大抽取器比较 语义特征提取能力：TF &gt; RNN/CNN Transformer在这方面的能力非常显著地超过RNN和CNN，RNN和CNN两者能力差不太多。 长距离特征捕获能力：TF/RNN &gt; CNN 原生CNN特征抽取器在这方面极为显著地弱于RNN和Transformer 任务综合特征抽取能力（机器翻译）：TF &gt; RNN/CNN Transformer综合能力要明显强于RNN和CNN，而RNN和CNN看上去表现基本相当，貌似CNN表现略好一些。 并行计算能力及运行效率：TF/CNN &gt; RNN RNN在并行计算方面有严重缺陷，这是它本身的序列依赖特性导致的；对于CNN和Transformer来说，因为它们不存在网络中间状态不同时间步输入的依赖关系，所以可以非常方便及自由地做并行计算改造。Transformer和CNN差不多，都远远远远强于RNN。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-23T13:53:11.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:modified_time","content":"2025-04-23T13:53:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"NLP\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-04-23T13:53:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"NLP三大特征抽取器比较(CNN/RNN/Transformer)","slug":"nlp三大特征抽取器比较-cnn-rnn-transformer","link":"#nlp三大特征抽取器比较-cnn-rnn-transformer","children":[]}],"git":{"createdTime":1745416391000,"updatedTime":1745416391000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-6.local","commits":1}]},"readingTime":{"minutes":1.46,"words":439},"filePathRelative":"llm/01_llm_basic/06_nlp.md","localizedDate":"April 23, 2025","excerpt":"<h1> NLP</h1>\\n<h2> NLP三大特征抽取器比较(CNN/RNN/Transformer)</h2>\\n<p>结论：RNN已经基本完成它的历史使命，将来会逐步退出历史舞台；CNN如果改造得当，将来还是有希望有自己在NLP领域的一席之地；而Transformer明显会很快成为NLP里担当大任的最主流的特征抽取器。</p>\\n<p>NLP任务的特点：输入是个一维线性序列；输入不定长；单词或句子的位置关系很重要；句子中长距离特征对于语义理解也很重要。</p>\\n<p>三大抽取器比较</p>\\n<ul>\\n<li>语义特征提取能力：TF &gt; RNN/CNN\\n<ul>\\n<li>Transformer在这方面的能力非常显著地超过RNN和CNN，RNN和CNN两者能力差不太多。</li>\\n</ul>\\n</li>\\n<li>长距离特征捕获能力：TF/RNN &gt; CNN\\n<ul>\\n<li>原生CNN特征抽取器在这方面极为显著地弱于RNN和Transformer</li>\\n</ul>\\n</li>\\n<li>任务综合特征抽取能力（机器翻译）：TF &gt; RNN/CNN\\n<ul>\\n<li>Transformer综合能力要明显强于RNN和CNN，而RNN和CNN看上去表现基本相当，貌似CNN表现略好一些。</li>\\n</ul>\\n</li>\\n<li>并行计算能力及运行效率：TF/CNN &gt; RNN\\n<ul>\\n<li>RNN在并行计算方面有严重缺陷，这是它本身的序列依赖特性导致的；对于CNN和Transformer来说，因为它们不存在网络中间状态不同时间步输入的依赖关系，所以可以非常方便及自由地做并行计算改造。Transformer和CNN差不多，都远远远远强于RNN。</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{N as data};

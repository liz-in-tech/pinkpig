---
icon: lightbulb
---
# 分布式训练框架
## 1. DeepSpeed
DeepSpeed 是微软开发的一个加速深度学习模型训练的高性能库（与 PyTorch兼容），被广泛用于大语言模型的分布式训练，例如 MT-NLG 和 BLOOM等。

DeepSpeed 为分布式训练提供了各种优化技术支持，如内存优化（ZeRO 技术、梯度检查点）、数据并行、混合精度训练等，使得整个训练过程变得更加高效、稳定。为了更加适配大模型时代的用户需求，DeepSpeed 针对模型生成和强化学习分别开发了特制的优化框架：DeepSpeed-MII 和 DeepSpeed-Chat。

## 2. Megatron-LM
Megatron-LM是由 NVIDIA 开发的一款专门为训练大语言模型而设计的深度学习代码库。这个代码库旨在解决大型模型训练过程中所遇到的一系列技术挑战，包括显存限制、计算效率以及不同的并行策略带来的通信问题。这些优化技术可以在很大程度上提高训练效率和速度，实现跨 GPU 的高效分布式训练。

引入了一系列分布式训练的优化技巧，支持多种并行化策略

数据并行，通过在每个工作节点复制模型，并将输入数据切分多份分配给多个节点，定期同步所有梯度来提升 GPU 的使用效率

模型并行，包括张量并行和流水线并行，通过在多个工作节点上分配模型和计算来克服单个 GPU 容量限制的问题

Megatron-LM 还支持混合精度训练和 FlashAttention 功能

---
icon: lightbulb
---
# 低资源部署策略/模型压缩技术 (修改模型权重本身来减少每个 GPU 上的内存使用)
## 1. 模型量化 / Quantization / 混合精度
降低模型的精度可以带来多种好处。如果模型占用的内存空间较少，则可以在相同数量的硬件上安运行更大的模型。量化还意味着可以在相同的带宽上传输更多参数，这有助于加速带宽有限的模型。

## 2. 模型剪枝 / 稀疏 Sparsity / 正则化
与模型量化不同，模型蒸馏和模型剪枝则通过精简模型的结构，进而减少参数的数量。

## 3. 模型蒸馏 / Distillation
与模型量化不同，模型蒸馏和模型剪枝则通过精简模型的结构，进而减少参数的数量。

缩小模型大小的另一种方法是通过称为蒸馏的过程将其知识转移到较小的模型。此过程涉及训练较小的模型（称为学生）来模仿较大模型（教师）的行为
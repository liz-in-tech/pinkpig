<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://liz-in-tech.github.io/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="分布式训练框架"><meta property="og:description" content="分布式训练框架 训练框架对比 小 (&lt;10B参数): torchrun/accelerate都行 中（10B-100B参数）: deepspeed 大（&gt;100参数）: 得上megatron 0. Pytorch三种数据并行方案 DP（torch.nn.DataParallel） 目前，基本上 DP 已经被弃用 DP只用于单机情况（单进程多线程模式），不支持多级多卡 使用普通的All-Reduce机制 DDP（torch.nn.DistributedDataParallel） 相较于DP，DDP传输的数据量更少，训练更高效 DDP适用于单机和多机情况，真正实现分布式训练 DDP数据传输过程： 前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。 DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致 不足：要求整个模型加载到一个GPU上 FSDP（torch.distributed.fsdp.FullyShardedDataParallel） PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感 是一种新型数据并行训练方法 将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-04-23T13:53:11.000Z"><meta property="article:author" content="Liz"><meta property="article:modified_time" content="2025-04-23T13:53:11.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"分布式训练框架","image":[""],"dateModified":"2025-04-23T13:53:11.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/pinkpig/blogger.png"><title>分布式训练框架 | Liz</title><meta name="description" content="分布式训练框架 训练框架对比 小 (&lt;10B参数): torchrun/accelerate都行 中（10B-100B参数）: deepspeed 大（&gt;100参数）: 得上megatron 0. Pytorch三种数据并行方案 DP（torch.nn.DataParallel） 目前，基本上 DP 已经被弃用 DP只用于单机情况（单进程多线程模式），不支持多级多卡 使用普通的All-Reduce机制 DDP（torch.nn.DistributedDataParallel） 相较于DP，DDP传输的数据量更少，训练更高效 DDP适用于单机和多机情况，真正实现分布式训练 DDP数据传输过程： 前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。 DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致 不足：要求整个模型加载到一个GPU上 FSDP（torch.distributed.fsdp.FullyShardedDataParallel） PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感 是一种新型数据并行训练方法 将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU">
    <link rel="preload" href="/pinkpig/assets/style-B4ayxgRu.css" as="style"><link rel="stylesheet" href="/pinkpig/assets/style-B4ayxgRu.css">
    <link rel="modulepreload" href="/pinkpig/assets/app-ieMuNFND.js"><link rel="modulepreload" href="/pinkpig/assets/09_分布式训练框架.html-f_4CE-ce.js"><link rel="modulepreload" href="/pinkpig/assets/09_分布式训练框架.html-GG66xNfZ.js"><link rel="modulepreload" href="/pinkpig/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/pinkpig/assets/index.html-ibkdGA84.js" as="script"><link rel="prefetch" href="/pinkpig/assets/intro.html-VEF0ZusF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AntDesign.html-5NgDnkhT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSS.html-DWW8u9ge.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Expo.html-lJQuUz4Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Frontend.html-a7NJdFWI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/HTML.html-9wodgV5c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/JavaScript.html-lvtDI2LR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Practice.html-lui81Yar.js" as="script"><link rel="prefetch" href="/pinkpig/assets/React.html-b8iVrI2O.js" as="script"><link rel="prefetch" href="/pinkpig/assets/npm.html-cf-i0MG_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSAPP.html-DfrX1UAP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Netty.html-p8gk6fJ_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/RPC.html-7C88YC2N.js" as="script"><link rel="prefetch" href="/pinkpig/assets/competition.html-9FBFPDQz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/操作系统.html-1QgCNUH3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/浏览器技能.html-uFcrAJVS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/网络.html-36AG3eKy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/计算机技能.html-H-ZX4k04.js" as="script"><link rel="prefetch" href="/pinkpig/assets/commen_mistakes.html-mGgYvOuL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/grammar.html-H-3z-vXH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english3.html--aWr1mmm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english_detail.html-MQS8h2D6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/pronunciation.html-d7en6ro-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/sentence_pattern_and_expression.html-bv8MyCdJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_llm_roadmap.html-bnnJVWew.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Git使用手册.html-2FKeMxuw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Markdown.html-8ZdG81kj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoshop.html-1AQeTxWq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/interview_code.html-oTzIHCpd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/quick_recovery.html-57YZ5vgN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/solve_trick.html-R1zd6M1x.js" as="script"><link rel="prefetch" href="/pinkpig/assets/多层迷宫.html-5S0uvLI1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/算法提升.html-3eGbfge7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/经典题汇总（每个细分类限定10题以内）.html-q2-dePgM.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java8学习笔记.html-gBdmNduj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/基础.html-1_ocEQ4I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/集合.html-B3Wp3Upx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/juc.html-5GKFP4UE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/jvm.html-6rKN8Wso.js" as="script"><link rel="prefetch" href="/pinkpig/assets/spring.html-s5U1LwF9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Keymap.html--yTwT5Pe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Problem_and_plugin.html-fhQh8RqL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Maven--java包管理工具.html-scnAhanr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/careers.html-yiJQBxx-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/common.html-8eP_H2he.js" as="script"><link rel="prefetch" href="/pinkpig/assets/communication.html-Ws1GaxQj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computers.html-E9ZVn5M0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/describing_something.html-qB30C2Nz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/dreams.html-KfGof6S4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/graduating.html-P8cgR_ex.js" as="script"><link rel="prefetch" href="/pinkpig/assets/greetings.html-5eDIKNUU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/hobbies.html-j7YJS0Uj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/immigration.html-N3b_zhs7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/introducing_someone.html-8g3aWQlk.js" as="script"><link rel="prefetch" href="/pinkpig/assets/phone.html-83IoFm_-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/routine.html-HbuB0pac.js" as="script"><link rel="prefetch" href="/pinkpig/assets/time_and_weather.html-iKp7YvRN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/traits.html-2kgfa3hS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_llm_evolution.html-yia_gfta.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_emergent_abilities_and_scaling_law.html-DVn6qo4L.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络.html-2Oss4WeY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_rnn.html-H_M06n55.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_attention.html-MApSKzbp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_nlp.html-K0tT5FAc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_编码器与解码器.html-sqKHqcqy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_gpt.html-Za3C2MCe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_llama.html-31qpWODi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_qwen.html-j6_AwMpp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_deepseek.html-B3W1djTi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_LLM关键技术概览.html-anKaf6G3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM构建过程.html-mPzu15NJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_预训练.html-DqQfxNWb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_微调.html-tnqPShz0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_对齐.html-nkDjN9A8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM数据工程.html-fOikUcO4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_tokenizer.html-ybjzGM0K.js" as="script"><link rel="prefetch" href="/pinkpig/assets/08_word_embedding.html-NkIVwupR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/10_ray.html-snaCKVPs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_解码策略.html--PzsIBtw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM推理.html-UiLUY0jo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_推理框架.html-Qt3AIVVU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_LLM评估.html-lmUpBwjN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_优化技术.html-qepFvgp1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM压缩.html-u6JYyz3R.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_resources.html-ER0hIuhg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/cursor.html-SPLucZvd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/frequent_use_command.html-kuEEE1V7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/google_colab.html-NsrJLy3H.js" as="script"><link rel="prefetch" href="/pinkpig/assets/ipdb.html-lNneRT7f.js" as="script"><link rel="prefetch" href="/pinkpig/assets/llm显存占用计算以及GPU的选择.html-tYtb1LPm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt_experience.html-RjAspTy1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/不传之秘.html-yim4NsOO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/GraphQL.html-zq9chJmn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MicroService.html-gqQ9Z22K.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MybatisPlus.html-sXrDLPET.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rocketmq.html-Hl75cf25.js" as="script"><link rel="prefetch" href="/pinkpig/assets/SQL.html-h6ZRnzFD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/mysql.html-w2oyLSBD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/redis.html-RgiRoRd9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Docker.html-v652K6De.js" as="script"><link rel="prefetch" href="/pinkpig/assets/K8S.html-hVxZM-yZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/docker_from_xmind.html-etYvtf7i.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux.html-GKFxuA1k.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux_command.html-iB7MbZV8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/wsl.html-oi6sho5k.js" as="script"><link rel="prefetch" href="/pinkpig/assets/english_words.html-QD9WjIVg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/experience.html-NGzTOw4o.js" as="script"><link rel="prefetch" href="/pinkpig/assets/paper_find.html--xIE94bO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_python_environment.html-Ogc-g3Pl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_python_data_type.html-SsgcwWnj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_python_operator.html-WW78TP0B.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_python_method.html-gy5ccBYv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_python_builtin_module.html-W4QAcEOF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_python_popular_package.html-4W72Pdg1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_python_web.html-2wx4z3ck.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_deep_learning_frameworks.html-6aphJD4D.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_ai_concept.html-FUCs1g0L.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_neural_net_train.html-YPETtbT8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_pytorch_operation.html-yukjJeR7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_pytorch_practice_nn.html-6bU2zAkC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_linear_nn.html-V-M3_Tfb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_heterogeneous_graph.html-eXFNwBOH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_evolution.html-dPUJTcbb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/0.时空复杂度.html-Ed0mUuFP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.分治思想_递归实现.html-ZR8C9fAr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.二进制_位运算.html-IPYNI70m.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.排序.html-ezbMcwpP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.二分查找.html-6XjBZtvX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.动态规划_贪心.html-JlAVeSTu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.字符串.html-H_Kw0VHp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.数学.html-JB3Fd046.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.算法技巧.html-0zv2JKDG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.数组.html-2pX8ASkd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.链表.html-MDTUDdof.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.栈.html-VhlnLXDW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.队列.html-5RW94C74.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.堆（优先队列）.html-9UtOuX_z.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.树.html-eY_fw8EL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.图.html-C6zmof_l.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.哈希表（散列表）.html-rEshAQ6r.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java语言基础.html-zkZgse3g.js" as="script"><link rel="prefetch" href="/pinkpig/assets/python算法刷题语法快速恢复.html-MwR2aQKw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent.html-YzftFD9b.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent_research.html-pZN9c_1T.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computer_use_same.html-KOaRH6Ml.js" as="script"><link rel="prefetch" href="/pinkpig/assets/langchain.html-i58jGmH0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/memory.html-ly8uWP03.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt.html-lL6RQ9Ux.js" as="script"><link rel="prefetch" href="/pinkpig/assets/018_autorag.html-3i5c7At_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rag_opensource.html-G7UpFpJ-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/404.html-ELYBSFNe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ndBqxueE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ZtH9hb0Y.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FhfXXQqd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Y18Gk6ug.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PYFEr-gw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-n6sTAWGG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-SpiN3Ual.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-lySh48SJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-QLcoUYFo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OkAhqWR6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-WjAYn9Z-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2CIdeSnB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ayy3EF9I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zpwaHXIV.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-nGOSO6_S.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-iyn2Phdl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Ls2hwge3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-_e4jAiDs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-MDiPagDx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-RmQTNmcI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-uTiIdO0F.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-TrYac60Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OWFxg9Im.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PfTXE4w9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html--tUsRM8W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ik3y9HJ8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2LBMckbl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-jSFk7HPD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-aX5SAJZk.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-avJpz5gY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-7kqkDjc1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-11KJ3gwb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-LQuERQvK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6iizFISA.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-7EXy9ft5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BYKqQoTu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OUm-Xb__.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Q77JHGwp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-qSCg3dme.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-3AOtZ1O7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-NUrjn_rx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ZkjR0Tnl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-4fJRFXlS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-0Zni0yS2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-x4TH_xzP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-yZYnH68c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-M3KBctL2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8WjFejoc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-KzgtbF_l.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-bUj5_ism.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-xtYkLxjR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-xfwIgr3s.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-AVn-_fFT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-V6IelPdJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-wvgAZYvE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Bp62bPd5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FTMRL3lu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Ob7dvR-M.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2oWEcuGm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Di6h8Ky1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-5GuLlprQ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dbwd_1YG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dQ2QFe76.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-DKIbv2Jr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-kmPKSOrX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PjKCTcgX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-WHhL-UfW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FHbtXQBu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-j0J10-eI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-j2GiZDuJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/intro.html-kvmRzgqY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AntDesign.html-2bvgt8I3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSS.html-rfeM_yvl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Expo.html-xudzMigH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Frontend.html-vERnRTPN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/HTML.html-xgHh1UsK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/JavaScript.html-ddpglDN7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Practice.html-BDuMyHfj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/React.html-arBJcHQW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/npm.html-QnfX-JMC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSAPP.html--uCuK0Qh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Netty.html-ETiOYTuf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/RPC.html-CzhRUHCW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/competition.html-D73iojLi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/操作系统.html-kpxLYpLS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/浏览器技能.html-sYaJoJ1u.js" as="script"><link rel="prefetch" href="/pinkpig/assets/网络.html-1Oh5evOk.js" as="script"><link rel="prefetch" href="/pinkpig/assets/计算机技能.html-gCYSJSqi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/commen_mistakes.html-Kxc5VgFq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/grammar.html-D9_-ufDh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english3.html-B0JSUlg5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english_detail.html-v_UBurm6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/pronunciation.html-6Cdk1z2w.js" as="script"><link rel="prefetch" href="/pinkpig/assets/sentence_pattern_and_expression.html-WKlmY2Qo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_llm_roadmap.html-aVOVkKpR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Git使用手册.html-EJfvl7pU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Markdown.html-5qcxA2dn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoshop.html-_-4ZMkKo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/interview_code.html-sAVucSFi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/quick_recovery.html-mydMUbVs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/solve_trick.html-nFbdYeKu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/多层迷宫.html-c3d-4mi-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/算法提升.html-j1iEB5I7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/经典题汇总（每个细分类限定10题以内）.html-lL1ro3yK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java8学习笔记.html-kFnkfB-h.js" as="script"><link rel="prefetch" href="/pinkpig/assets/基础.html-ksBFmG6c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/集合.html-GhStYV09.js" as="script"><link rel="prefetch" href="/pinkpig/assets/juc.html-ro0aTgdY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/jvm.html-pPb4mWUN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/spring.html-7pfgRIwQ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Keymap.html-NwOQQND_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Problem_and_plugin.html-VwXo30O3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Maven--java包管理工具.html-PXqWS-uj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/careers.html-99tXh8hl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/common.html-HN2GP_pT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/communication.html-JhqEzDdc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computers.html-YT-bWh1P.js" as="script"><link rel="prefetch" href="/pinkpig/assets/describing_something.html-rczf0FkK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/dreams.html--2uCpVGg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/graduating.html-Iui1fdi8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/greetings.html-FE929VX6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/hobbies.html-VIBn0RrT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/immigration.html-0PNSHfER.js" as="script"><link rel="prefetch" href="/pinkpig/assets/introducing_someone.html-nYe4N4yt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/phone.html-tTWjN5QO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/routine.html-HbBu3iUQ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/time_and_weather.html-ncKEliqb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/traits.html-VP1gJNGj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_llm_evolution.html-HfjsAbqQ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_emergent_abilities_and_scaling_law.html-YZXZVgAa.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络.html-qFWQKUj-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_rnn.html-vsTW7wIF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_attention.html-yFvn7rT9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_nlp.html-4o-hcUrJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_编码器与解码器.html-6-hjMLur.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_gpt.html-FM_cqYm5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_llama.html-_W7t-zkd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_qwen.html-r5r32MJt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_deepseek.html-LGrnVeZY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_LLM关键技术概览.html-Fn2myLjO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM构建过程.html-SL9ACfPz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_预训练.html-wnZVk9pt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_微调.html-bMQniZvT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_对齐.html-VXPAgckl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM数据工程.html-uQZoW4nP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_tokenizer.html-S_KM8jjM.js" as="script"><link rel="prefetch" href="/pinkpig/assets/08_word_embedding.html-GMlfdRLf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/10_ray.html-Odcn0DSH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_解码策略.html-lkdV90fE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM推理.html-zbe8i5VF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_推理框架.html-jwpyMgx0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_LLM评估.html-Z3TodLSl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_优化技术.html-ARDFd_W7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM压缩.html-hNpzOXrD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_resources.html-G8sfvlaq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/cursor.html-l33NmOtH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/frequent_use_command.html-dWwHiSdX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/google_colab.html-l1MbiYVH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/ipdb.html-e2AxZc6W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/llm显存占用计算以及GPU的选择.html-YHiNyq72.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt_experience.html-eN7kvD1d.js" as="script"><link rel="prefetch" href="/pinkpig/assets/不传之秘.html-G9Dy5Njq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/GraphQL.html-pYfoCoDV.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MicroService.html-doWYNNdy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MybatisPlus.html-9a1mpid2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rocketmq.html-y95tH0n1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/SQL.html-1cEZ6dM3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/mysql.html-ZZ7w3_Rt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/redis.html-rMm7M1kz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Docker.html-PqDRLHaR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/K8S.html-BdI-2aP1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/docker_from_xmind.html-DxfaN3wm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux.html-2VKYOtBi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux_command.html-EoDHT2sC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/wsl.html-AXsU3c9O.js" as="script"><link rel="prefetch" href="/pinkpig/assets/english_words.html-s2eLrZPW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/experience.html-IHhSJ2YS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/paper_find.html-WqdDV89y.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_python_environment.html-ENtf7Ped.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_python_data_type.html-I1J36tqz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_python_operator.html-VcoH557t.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_python_method.html-lGBsgf_n.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_python_builtin_module.html-ECJ4KoVw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_python_popular_package.html-tT8v-uO6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_python_web.html-uNLJoSCm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_deep_learning_frameworks.html--CSa8jV_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_ai_concept.html-8vMgxusd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_neural_net_train.html-ChfQMF8l.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_pytorch_operation.html-PGTglEge.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_pytorch_practice_nn.html-yDSPx-6j.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_linear_nn.html-QB0i415E.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_heterogeneous_graph.html-b4FXJnhI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_evolution.html-GK__OPu8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/0.时空复杂度.html-j3VqVq5c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.分治思想_递归实现.html-yzpirx6u.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.二进制_位运算.html-sz6WhSHD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.排序.html-ah_wl3tP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.二分查找.html-gxiSoOwN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.动态规划_贪心.html-HZr508cP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.字符串.html-efVUYYUE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.数学.html-ZnPblk7Y.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.算法技巧.html-0O71KSfe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.数组.html-bg0UBLp3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.链表.html-TjjRENRB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.栈.html-x0u0dOb2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.队列.html-j4nac7f8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.堆（优先队列）.html-2SrSh8u8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.树.html-6QdFBrMs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.图.html-XAK9O84N.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.哈希表（散列表）.html-GkWXDUwa.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java语言基础.html-ZDbai8Pf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/python算法刷题语法快速恢复.html-QwihiQ8Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent.html-HTx4IUog.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent_research.html-wF_96HXO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computer_use_same.html-H-bFfcKI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/langchain.html-_BBHU1Ur.js" as="script"><link rel="prefetch" href="/pinkpig/assets/memory.html-BA-7V65x.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt.html-lSvK1her.js" as="script"><link rel="prefetch" href="/pinkpig/assets/018_autorag.html-h8MGasNh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rag_opensource.html-yU9cBdH0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/404.html-TGpkFp4M.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-S0rrxUEt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dVW_aIee.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-o485_-Xz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-b1FAW59L.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6Xs7I65C.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-9WGhFj7R.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-_3-vC4gb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OTwvUEgR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-gg5-tIFC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-nDxo4suY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-9Jzeg1ta.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zi_V23Po.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-hDgxqljb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-twisI5vG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-EYnce3h4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-pR9-SSaW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-UMDa0G82.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-AmDUj5oV.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-iezoTas6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-soM1dU9W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FGusK20q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-5vJkd_FI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zYxg5pnw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PsKmNHhi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-YZvmRI-t.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-XJC5qFi6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6KW88402.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-JIzbaRPd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-NGvJ7aLn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-_lTpgZDy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-CWpG1MbN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-i6SwvpSu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-YLNYs3xP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8ywW55nv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BmnWJtmy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-3DORVxk0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-nRyV4nUc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-X_k4Nvgw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dMfrWd5K.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-mD5-aqXr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zm1Jlv5_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-sn13Na3M.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dLKskLtZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-fL7npYuO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-56rKIC7V.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-lek_6V6f.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-WL4lsfmh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-uYUEarR4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-f-SG-xlf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-pLmxeA0j.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-I1P4Bepn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-kNrd9jvf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-9XWVDPxD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-loOZu2JI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-wT1kI9v1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-43-4lwc5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-HGca5c9d.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-XQ0t5lIS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-L9t6xIqb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-a1AoqbmW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dc2jB5e0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-eDmVsQhP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-b4e705K6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-QuroFQFK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-KtGNwxSz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-isNtw3D1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-CGcKu3Se.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BoCyEgee.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-yj8Uz8m4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/pinkpig/"><img class="vp-nav-logo" src="/pinkpig/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Language" class="vp-link nav-link nav-link" href="/pinkpig/language/"><!---->Language<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="LLM" class="vp-link nav-link active nav-link active" href="/pinkpig/llm/"><!---->LLM<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Python" class="vp-link nav-link nav-link" href="/pinkpig/python/"><!---->Python<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Java" class="vp-link nav-link nav-link" href="/pinkpig/java/"><!---->Java<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Frontend" class="vp-link nav-link nav-link" href="/pinkpig/frontend/"><!---->Frontend<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Middleware" class="vp-link nav-link nav-link" href="/pinkpig/middleware/"><!---->Middleware<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="CS" class="vp-link nav-link nav-link" href="/pinkpig/cs/"><!---->CS<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Operations" class="vp-link nav-link nav-link" href="/pinkpig/operations/"><!---->Operations<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Tools" class="vp-link nav-link nav-link" href="/pinkpig/tools/"><!---->Tools<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">Llm</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">01 Llm Basic</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">02 Llm Architecture</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">03 Llm Training</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a aria-label="LLM 关键技术概览" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/01_LLM%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88.html"><!---->LLM 关键技术概览<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="LLM 数据工程" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/06_LLM%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>LLM 数据工程<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="LLM的构建过程" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/02_LLM%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>LLM的构建过程<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Ray 分布式计算框架" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/10_ray.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Ray 分布式计算框架<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Tokenization（词元化，分词）" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/07_tokenizer.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Tokenization（词元化，分词）<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Word Embedding（“词嵌入”，分布式词向量，稠密向量的非零表征，隐含语义的特征表示）" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/08_word_embedding.html"><!---->Word Embedding（“词嵌入”，分布式词向量，稠密向量的非零表征，隐含语义的特征表示）<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="分布式训练框架" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练框架<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="0. Pytorch三种数据并行方案" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_0-pytorch三种数据并行方案"><!---->0. Pytorch三种数据并行方案<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="DP和DDP的区别" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#dp和ddp的区别"><!---->DP和DDP的区别<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="DDP 和 FSDP的区别" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#ddp-和-fsdp的区别"><!---->DDP 和 FSDP的区别<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1. DeepSpeed" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_1-deepspeed"><!---->1. DeepSpeed<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="为什么需要Deepspeed" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#为什么需要deepspeed"><!---->为什么需要Deepspeed<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="DeepSpeed 优化点" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#deepspeed-优化点"><!---->DeepSpeed 优化点<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="DeepSpeed 通信策略" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#deepspeed-通信策略"><!---->DeepSpeed 通信策略<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="混合精度训练" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#混合精度训练"><!---->混合精度训练<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="DeepSpeed的核心技术：Zero（Zero Redundancy Optimizer，3D优化与卸载）" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载"><!---->DeepSpeed的核心技术：Zero（Zero Redundancy Optimizer，3D优化与卸载）<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="2. Megatron-LM" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_2-megatron-lm"><!---->2. Megatron-LM<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="分布式训练并行策略选择" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#分布式训练并行策略选择"><!---->分布式训练并行策略选择<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="8.1 单机单卡场景" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_8-1-单机单卡场景"><!---->8.1 单机单卡场景<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8.2 单机多卡场景" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_8-2-单机多卡场景"><!---->8.2 单机多卡场景<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8.3 多机多卡场景" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/03_llm_training/09_%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6.html#_8-3-多机多卡场景"><!---->8.3 多机多卡场景<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li></ul><!--]--></li><li><!--[--><a aria-label="对齐 / 偏好对齐" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/05_%E5%AF%B9%E9%BD%90.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>对齐 / 偏好对齐<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="微调" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/04_%E5%BE%AE%E8%B0%83.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>微调<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="预训练" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/03_llm_training/03_%E9%A2%84%E8%AE%AD%E7%BB%83.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>预训练<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">04 Llm Reasoning</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">05 Llm Engineering</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">06 Llm Experience</span><span class="vp-arrow end"></span></button><!----></section></li><li><!--[--><a aria-label="LLM Roadmap" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/00_llm_roadmap.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>LLM Roadmap<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练框架</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-04-23T13:53:11.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 19 min</span><meta property="timeRequired" content="PT19M"></span><!----><!----></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_0-pytorch三种数据并行方案">0. Pytorch三种数据并行方案</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#dp和ddp的区别">DP和DDP的区别</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#ddp-和-fsdp的区别">DDP 和 FSDP的区别</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-deepspeed">1. DeepSpeed</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#为什么需要deepspeed">为什么需要Deepspeed</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#deepspeed-优化点">DeepSpeed 优化点</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#deepspeed-通信策略">DeepSpeed 通信策略</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#混合精度训练">混合精度训练</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载">DeepSpeed的核心技术：Zero（Zero Redundancy Optimizer，3D优化与卸载）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-megatron-lm">2. Megatron-LM</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#分布式训练并行策略选择">分布式训练并行策略选择</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-1-单机单卡场景">8.1 单机单卡场景</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-2-单机多卡场景">8.2 单机多卡场景</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-3-多机多卡场景">8.3 多机多卡场景</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="分布式训练框架" tabindex="-1"><a class="header-anchor" href="#分布式训练框架" aria-hidden="true">#</a> 分布式训练框架</h1><p>训练框架对比</p><ul><li>小 (&lt;10B参数): torchrun/accelerate都行</li><li>中（10B-100B参数）: deepspeed</li><li>大（&gt;100参数）: 得上megatron</li></ul><h2 id="_0-pytorch三种数据并行方案" tabindex="-1"><a class="header-anchor" href="#_0-pytorch三种数据并行方案" aria-hidden="true">#</a> 0. Pytorch三种数据并行方案</h2><ul><li>DP（torch.nn.DataParallel） <ul><li>目前，基本上 DP 已经被弃用</li><li>DP只用于单机情况（单进程多线程模式），不支持多级多卡</li><li>使用普通的All-Reduce机制</li></ul></li><li>DDP（torch.nn.DistributedDataParallel） <ul><li>相较于DP，DDP传输的数据量更少，训练更高效</li><li>DDP适用于单机和多机情况，真正实现分布式训练</li><li>DDP数据传输过程： <ul><li>前向传播的输出和loss的计算都是在每个cuda独立计算的，梯度all-reduce到所有的CUDA(传输梯度)，这样初始参数相同，para.grad也相同，反向传播后参数就还是保持一致的，其他没有数据传输了。</li><li>DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致</li></ul></li><li>不足：要求整个模型加载到一个GPU上</li></ul></li><li>FSDP（torch.distributed.fsdp.FullyShardedDataParallel） <ul><li>PyTorch FSDP 受 DeepSpeed ZeRO 启发而获得灵感</li><li>是一种新型数据并行训练方法</li><li>将模型参数、梯度和优化器状态跨数据并行工作线程进行分片，并且可以选择将模型参数分片卸载到 CPU</li></ul></li></ul><h3 id="dp和ddp的区别" tabindex="-1"><a class="header-anchor" href="#dp和ddp的区别" aria-hidden="true">#</a> DP和DDP的区别</h3><p>DP 和 DDP 的主要差异有以下几点：</p><ul><li>DP 是基于单进程多线程的实现，只用于单机情况，而 DDP 是多进程实现的，每个 GPU 对应一个进程，适用于单机和多机情况，真正实现分布式训练，并且因为每个进程都是独立的 Python 解释器，DDP 避免了 GIL 带来的性能开销。</li><li>参数更新的方式不同。DDP在各进程梯度计算完成之后，各进程需要将梯度进行汇总平均，然后再由 rank=0 的进程，将其广播到所有进程后，各进程用该梯度来独立的更新参数（而 DP是梯度汇总到 GPU0，反向传播更新参数，再广播参数给其他剩余的 GPU）。由于DDP各进程中的模型，初始参数一致 (初始时刻进行一次广播)，而每次用于更新参数的梯度也一致；因此，各进程的模型参数始终保持一致（而在DP中，全程维护一个 optimizer，对各个GPU上梯度进行求平均，而在主卡进行参数更新，之后再将模型参数广播到其他GPU）。相较于DP，DDP传输的数据量更少，训练更高效，不存在 DP 中负载不均衡的问题。目前，基本上 DP 已经被弃用。</li><li>DDP 支持模型并行，而 DP 并不支持，这意味如果模型太大单卡显存不足时，只能使用DDP。</li></ul><h3 id="ddp-和-fsdp的区别" tabindex="-1"><a class="header-anchor" href="#ddp-和-fsdp的区别" aria-hidden="true">#</a> DDP 和 FSDP的区别</h3><figure><img src="/pinkpig/assets/image-40-CEX-_5gd.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>DDP <ul><li>每个GPU上都有一个模型副本，向前和向后传递的序列只在自己的数据分片上进行</li></ul></li><li>FSDP <ul><li><strong>Model shard</strong>：每个GPU上仅存在<strong>模型的分片</strong>。</li><li><strong>All-gather</strong>：每个GPU通过all-gather从其他GPU收集所有<strong>权重</strong>，以在本地计算前向传播。</li><li><strong>Forward（local）</strong>：在本地进行前向操作。前向计算和后向计算都是利用完整模型。</li><li><strong>All-gather</strong>：然后在后向传播之前再次执行此<strong>权重</strong>收集。</li><li><strong>Backward（local）</strong>：本地进行后向操作。前向计算和后向计算都是利用完整模型，此时每个GPU上也都是<strong>全部梯度</strong>。</li><li><strong>Reduce-Scatter</strong>：在向后传播之后，局部<strong>梯度</strong>被聚合并且通过 Reduce-Scatter 在各个GPU上分片，每个分片上的梯度是聚合之后本分片对应的那部分。</li><li><strong>Update Weight（local）</strong>：每个GPU更新其局部<strong>权重</strong>分片。</li></ul></li></ul><h2 id="_1-deepspeed" tabindex="-1"><a class="header-anchor" href="#_1-deepspeed" aria-hidden="true">#</a> 1. DeepSpeed</h2><p>DeepSpeed 是由 Microsoft 提供的分布式训练工具，旨在支持更大规模的模型和提供更多的优化策略和工具。</p><p><strong>DeepSpeed 提出了 ZeRO</strong></p><p>解锁ZeRO/FSDP的关键是我们可以把DDP之中的All-Reduce操作分解为独立的 Reduce-Scatter 和 All-Gather 操作。</p><h3 id="为什么需要deepspeed" tabindex="-1"><a class="header-anchor" href="#为什么需要deepspeed" aria-hidden="true">#</a> 为什么需要Deepspeed</h3><ul><li>分布式计算环境中，主节点负责协调其他节点和进程的工作</li><li>pytorch官方提供的分布式训练工具Accelerate只支持nvlink，而T4，3090这类显卡是PIX ，检测方式：nvidia-smi topo -m；deepspeed支持更大规模的模型训练</li><li>混合精度训练</li><li>ZeRO可以减少内存占用，优化大模型训练，将模型参数分成了三个部分：Optimizer States、Gradient 和 Model Parameter。在使用 ZeRO 进行分布式训练时，可以选择 ZeRO-Offload 和 ZeRO-Stage3 等不同的优化技术。</li></ul><h3 id="deepspeed-优化点" tabindex="-1"><a class="header-anchor" href="#deepspeed-优化点" aria-hidden="true">#</a> DeepSpeed 优化点</h3><p>与其他框架相比，DeepSpeed支持更大规模的模型和提供更多的优化策略和工具。其中，主要优势在于支持更大规模的模型、提供了更多的优化策略和工具（例如 ZeRO 和 Offload 等）</p><p>DeepSpeed 为分布式训练提供了各种优化技术支持，如内存优化（ZeRO 技术、梯度检查点）、数据并行、混合精度训练等，使得整个训练过程变得更加高效、稳定。为了更加适配大模型时代的用户需求</p><ul><li>DeepSpeed 还提供了 mpi、gloo 和 nccl 等通信策略，可以根据具体情况进行选择和配置。在使用 DeepSpeed 进行分布式训练时，可以根据具体情况选择合适的通信库，例如在 CPU 集群上进行分布式训练，可以选择 mpi 和 gloo；如果是在 GPU 上进行分布式训练，可以选择 nccl。</li><li><code>ZeRO</code>（Zero Redundancy Optimizer）是<strong>一种用于大规模训练优化的技术，主要是用来减少内存占用</strong>。ZeRO 将模型参数分成了三个部分：Optimizer States、Gradient 和 Model Parameter。在使用 ZeRO 进行分布式训练时，可以选择 ZeRO-Offload 和 ZeRO-Stage3 等不同的优化技术。</li><li><strong>混合精度训练</strong>是指在训练过程中同时使用FP16（半精度浮点数）和FP32（单精度浮点数）两种精度的技术。使用FP16可以大大减少内存占用，从而可以训练更大规模的模型。在使用混合精度训练时，需要使用一些技术来解决可能出现的梯度消失和模型不稳定的问题，例如动态精度缩放和混合精度优化器等。</li><li><strong>用 3D 并行化实现万亿参数模型训练</strong>**：**  DeepSpeed 实现了三种并行方法的灵活组合：ZeRO 支持的数据并行，流水线并行和张量切片模型并行。3D 并行性适应了不同工作负载的需求，以支持具有<strong>万亿</strong>参数的<strong>超大型模型</strong>，同时实现了近乎完美的显存扩展性和吞吐量扩展效率。此外，其提高的通信效率使用户可以在网络带宽有限的常规群集上以 2-7 倍的速度训练有数十亿参数的模型。</li><li><strong>ZeRO-Offload 使 GPU 单卡能够训练 10 倍大的模型</strong>**：**  为了同时利用 CPU 和 GPU 内存来训练大型模型，我们扩展了 ZeRO-2。我们的用户在使用带有<strong>单张英伟达 V100 GPU</strong> 的机器时，可以在不耗尽显存的情况下运行<strong>多达 130 亿个参数的模型</strong>，模型规模扩展至现有方法的10倍，并保持有竞争力的吞吐量。此功能使数十亿参数的模型训练更加大众化，，并为许多深度学习从业人员打开了一扇探索更大更好的模型的窗户。</li><li><strong>通过 DeepSpeed Sparse Attention 用6倍速度执行10倍长的序列</strong>**：**  DeepSpeed提供了稀疏 attention kernel ——一种工具性技术，可支持长序列的模型输入，包括文本输入，图像输入和语音输入。与经典的稠密 Transformer 相比，它支持的<strong>输入序列长一个数量级</strong>，并在保持相当的精度下获得最高 6 倍的执行速度提升。它还比最新的稀疏实现快 1.5–3 倍。此外，我们的稀疏 kernel 灵活支持稀疏格式，使用户能够通过自定义稀疏结构进行创新。</li><li><strong>1 比特 Adam 减少 5 倍通信量</strong>**：**  Adam 是一个在大规模深度学习模型训练场景下的有效的（也许是最广为应用的）优化器。然而，它与通信效率优化算法往往不兼容。因此，在跨设备进行分布式扩展时，通信开销可能成为瓶颈。我们推出了一种 1 比特 Adam 新算法，以及其高效实现。该算法<strong>最多可减少 5 倍通信量</strong>，同时实现了与Adam相似的收敛率。在通信受限的场景下，我们观察到分布式训练速度提升了 3.5 倍，这使得该算法可以扩展到不同类型的 GPU 群集和网络环境。</li></ul><h3 id="deepspeed-通信策略" tabindex="-1"><a class="header-anchor" href="#deepspeed-通信策略" aria-hidden="true">#</a> DeepSpeed 通信策略</h3><p>deepspeed 还提供了 mpi、gloo 和 nccl 等通信策略，可以根据具体情况进行选择和配置。</p><ul><li><code>mpi</code>是一种跨节点通信库，常用于 CPU 集群上的分布式训练；</li><li><code>gloo</code> 是一种高性能的分布式训练框架，支持 CPU 和 GPU 上的分布式训练；</li><li><code>nccl</code> 是 NVIDIA 提供的 GPU 专用通信库，被广泛应用于 GPU 上的分布式训练。</li></ul><p>在使用 DeepSpeed 进行分布式训练时，可以根据具体情况选择合适的通信库。通常情况下，如果是在 CPU 集群上进行分布式训练，可以选择 mpi 和 gloo；如果是在 GPU 上进行分布式训练，可以选择 nccl。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_LAUNCH_BLOCKING</span><span class="token operator">=</span><span class="token number">1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="混合精度训练" tabindex="-1"><a class="header-anchor" href="#混合精度训练" aria-hidden="true">#</a> 混合精度训练</h3><p>在 DeepSpeed 中，可以通过在配置文件中设置 <code>“bf16.enabled”: true</code> 来启用 BF16 混合精度训练，减少占用内存。混合精度训练是指在训练过程中同时使用FP16（半精度浮点数）和FP32（单精度浮点数）两种精度的技术。</p><p>在训练过程中，deepspeed会自动将一部分操作转换为FP16格式，并根据需要动态调整精度缩放因子，从而保证训练的稳定性和精度。</p><figure><img src="/pinkpig/assets/image-41-ceRjNs73.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/pinkpig/assets/image-42-1IWq1lVd.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/pinkpig/assets/image-43-Cp3XcGF9.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><strong>将权重转换为FP16</strong>：在这一步中，神经网络的权重（或参数）最初是FP32格式，被转换为低精度的FP16格式。这减少了内存的占用，并允许更快的计算，因为FP16操作需要更少的内存，并且可以被硬件更快地处理。 </li><li><strong>计算梯度</strong>：神经网络的前向和后向通道是使用较低精度的FP16权重进行的。这一步计算损失函数相对于网络权重的梯度（部分导数），在优化过程中用于更新权重。</li><li><strong>将梯度转换为FP32</strong>：在FP16中计算梯度后，它们被转换回高精度的FP32格式。这种转换对于保持数值稳定性和避免使用低精度算术时可能出现的梯度消失或爆炸等问题至关重要。 </li><li><strong>乘以学习率和更新权重</strong>：现在是FP32格式，梯度被乘以学习率（一个标量值，决定了优化过程中的步长）。乘积被用来更新原始FP32神经网络权重。学习率有助于控制优化过程的收敛性，对于实现良好的性能至关重要。</li></ul><p>NVIDIA Tesla V100 不支持BF16</p><h4 id="混合精度显存占用分析" tabindex="-1"><a class="header-anchor" href="#混合精度显存占用分析" aria-hidden="true">#</a> 混合精度显存占用分析</h4><h5 id="_1-模型状态-model-states" tabindex="-1"><a class="header-anchor" href="#_1-模型状态-model-states" aria-hidden="true">#</a> （1）<strong>模型状态</strong>（model states）</h5><p>假设模型的参数量是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Ψ</span></span></span></span> ，使用Adam为优化器进行混合精度训练。</p><ol><li>由于模型的参数和梯度使用float16，所以显存消耗分别为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span></span></span></span> 。</li><li>Adam会维护一个float32的模型备份副本，消耗 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span> 显存。Adam优化器本身会为模型的每个参数维护两个float32的辅助变量（fp32的momentum和fp32的variance），所以显存消耗占用为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ+4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span> 。</li></ol><p>总的来说，模型会消耗 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>2</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ+2Ψ=4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">2Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span> ，Adam优化器这消耗<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> </mtext><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>12</mn><mi mathvariant="normal">Ψ</mi><mtext> </mtext></mrow><annotation encoding="application/x-tex"> 4Ψ+4Ψ+4Ψ=12Ψ </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord"> 4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">12Ψ </span></span></span></span>。最终的总消耗为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>12</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>16</mn><mi mathvariant="normal">Ψ</mi><mtext> </mtext></mrow><annotation encoding="application/x-tex">4Ψ+12Ψ=16Ψ </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">12Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Ψ </span></span></span></span>。</p><figure><img src="/pinkpig/assets/image-44-Fkaf6O4b.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>**这里为了方便讨论，将优化器显存占用表示为 <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">KΨ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">Ψ</span></span></span></span></strong> (不同的优化器不同)，则混合精度训练的显存占用为 <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mi>K</mi><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ+KΨ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">Ψ</span></span></span></span></strong> 。 **</p><p>来看一个例子，<strong>GPT-2</strong>含有1.5B个参数，如果用fp16格式，只需要<code>1.5G*2Byte=3GB</code>显存</p><p>但是模型状态实际上需要耗费<code>1.5*16=24GB</code>, 相比之下，激活值可以用<a href="https://arxiv.org/pdf/1604.06174.pdf" title="activation checkpointing" target="_blank" rel="noopener noreferrer">activation checkpointing<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>来大大减少，所以模型状态就成了头号显存杀手，它也是ZeRO的重点优化对象。而其中Adam状态又是第一个要被优化的。</p><p>比如说有一个模型参数量是1M，在一般的深度学习框架中(比如说PyTorch)，一般是32位存储。32位存储的意思就是1个参数用32个bit来存储。那么这个拥有1M参数量的模型所需要的存储空间的大小即为：1M * 32 bit = 32Mb = 4MB。因为1 Byte = 8 bit。现在的quantization技术就是减少参数量所占的位数：比如我用16位存储，那么：所需要的存储空间的大小即为：1M * 16 bit = 16Mb = 2MB。</p><h5 id="_2-剩余状态-residual-states" tabindex="-1"><a class="header-anchor" href="#_2-剩余状态-residual-states" aria-hidden="true">#</a> <strong>（2）剩余状态</strong>（residual states）</h5><p> 除了模型状态之外的显存占用，包括<strong>激活值（activation）、各种临时缓冲区（buffer）以及无法使用的显存碎片（fragmentation）</strong>。</p><p>显然，激活在训练中也会消耗大量的显存。一个具体的例子，模型为1.5B的GPT-2，序列长度为1K，batch size为32，则消耗显存为60GB。Activation checkpointing(或者activation recomputation)则是一种常见的降低激活占用显存的方法。该方法以33%的重计算为代价，将激活的显存占用减少至总激活的均分更。即激活显存占用从60GB降低至8GB。</p><p>尽管激活的显存占用已经显著减少，但是对于更大的模型来说，激活所占用的显存也会非常大。例如，对于100B参数量的GPT模型且batch size为32，即使用来activation checkpointing，显存占用也需要60GB。</p><p><strong>临时缓存区(Temporary buffers)</strong>。对于大模型，用于存储中间结果的临时buffer也会消耗大量显存。例如在all-reduce时，需要一个平坦的buffer来融合所有的梯度，从而改善吞吐量。例如，跨设备的all-reduce操作会随着消息的增大而增加。虽然，梯度本文是fp16的张量，但是有些操作中可能需要融合的buffer为fp32。当模型尺寸很大时，临时的buffer也不小。例如，对于1.5B参数的模型，一个fp32的buffer需要6GB的显存。</p><p><strong>显存碎片</strong>。即使在有足够显存的情况下，也可能会导致Out of Memory，这是由于显存碎片导致的。在进程发出显存请求时，如果没有连续的显存来满足请求，即使总的显存仍然足够，该请求也会失败。当训练非常大的模型时，可以观察到明显的显存碎片。极端情况下，可能会导致30%的显存碎片。</p><h3 id="deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载" tabindex="-1"><a class="header-anchor" href="#deepspeed的核心技术-zero-zero-redundancy-optimizer-3d优化与卸载" aria-hidden="true">#</a> DeepSpeed的核心技术：<strong>Zero</strong>（Zero Redundancy Optimizer，3D优化与卸载）</h3><p>在deepspeed中通过<code>zero_optimization.stage=0/1/2/3</code> 设置，卸载通过<code>zero_optimization.offload_optimizer.device</code>设置</p><p><code>ZeRO-0</code>：禁用所有类型的分片，仅使用 DeepSpeed 作为 DDP (Distributed Data Parallel)</p><p><code>ZeRO-1</code>：分割Optimizer States，减少了4倍的内存，通信容量与数据并行性相同</p><p><code>ZeRO-2</code>：分割Optimizer States与Gradients，8x内存减少，通信容量与数据并行性相同</p><p><code>ZeRO-3</code>：分割Optimizer States、Gradients与Parameters，内存减少与数据并行度和复杂度成线性关系。</p><p><code>ZeRO-Infinity</code>是ZeRO-3的拓展。允许通过使用 NVMe 固态硬盘扩展 GPU 和 CPU 内存来训练大型模型。ZeRO-Infinity 需要启用 ZeRO-3。</p><p>ZeRO-Offload和ZeRO-Stage3是DeepSpeed中的不同的Zero-Redundancy Optimization技术，用于加速分布式训练，主要区别在资源占用和通信开销方面。</p><ul><li><code>ZeRO-Offload</code>将模型参数分片到不同的GPU上，通过交换节点间通信来降低显存占用，但需要进行额外的通信操作，因此可能会导致训练速度的下降。</li><li><code>ZeRO-Stage3</code>将模型参数分布在CPU和GPU上，通过CPU去计算一部分梯度，从而减少显存占用，但也会带来一定的计算开销。</li></ul><h2 id="_2-megatron-lm" tabindex="-1"><a class="header-anchor" href="#_2-megatron-lm" aria-hidden="true">#</a> 2. Megatron-LM</h2><p>Megatron-LM是由 NVIDIA 开发的一款专门为训练大语言模型而设计的深度学习代码库。这个代码库旨在解决大型模型训练过程中所遇到的一系列技术挑战，包括显存限制、计算效率以及不同的并行策略带来的通信问题。这些优化技术可以在很大程度上提高训练效率和速度，实现跨 GPU 的高效分布式训练。</p><p>引入了一系列分布式训练的优化技巧，支持多种并行化策略</p><p>数据并行，通过在每个工作节点复制模型，并将输入数据切分多份分配给多个节点，定期同步所有梯度来提升 GPU 的使用效率</p><p>模型并行，包括张量并行和流水线并行，通过在多个工作节点上分配模型和计算来克服单个 GPU 容量限制的问题</p><p>Megatron-LM 还支持混合精度训练和 FlashAttention 功能</p><h2 id="分布式训练并行策略选择" tabindex="-1"><a class="header-anchor" href="#分布式训练并行策略选择" aria-hidden="true">#</a> 分布式训练并行策略选择</h2><p>上面讲述了各种分布式并行策略，以下是进行分布式训练时针对不同的服务器资源类型（单机多卡、多机多卡），如何选择并行策略非常粗略的概述。</p><h3 id="_8-1-单机单卡场景" tabindex="-1"><a class="header-anchor" href="#_8-1-单机单卡场景" aria-hidden="true">#</a> 8.1 单机单卡场景</h3><p>当你的模型可以在单张 GPU 卡进行训练时，正常使用。</p><p>当你的模型不能在单张 GPU 卡进行训练时，</p><ul><li>ZeRO + Offload CPU 和 NVMe（可选的）。</li><li>启用以<strong>内存为中心的平铺</strong> 。</li></ul><p>如果最大层无法放置在单张GPU，则使用 ZeRO - 启用以<strong>内存为中心的平铺</strong> (MCT)。 它允许您通过自动分割层并按顺序执行来运行任意大的层。 MCT 减少了 GPU 上实时参数的数量，但不影响激活内存。</p><h3 id="_8-2-单机多卡场景" tabindex="-1"><a class="header-anchor" href="#_8-2-单机多卡场景" aria-hidden="true">#</a> 8.2 单机多卡场景</h3><p>当你的模型可以在单张 GPU 卡进行训练时，可以选择 DDP 或 ZeRO：</p><ul><li>DDP：分布式 DP。</li><li>ZeRO：可能会更快，也可能不会更快，具体取决于所使用的情况和配置。</li></ul><p>当你的模型不能在单张 GPU 卡进行训练时，可以选择 PP、ZeRO、TP：</p><ul><li>PP</li><li>ZeRO</li><li>TP</li></ul><p>如果使用 NVLINK 或 NVSwitch 进行节点内通信，这三者应该基本处于同等水平。</p><p>如果没有这些， PP 将比 TP 或 ZeRO 更快。 TP 的大小也可能产生影响，最好在您特定设置上进行试验以找到最优的方式。</p><p>注意： TP 几乎总是在单个节点内进行使用。 即：TP 大小 &lt;= 每个节点的 GPU 数。</p><h3 id="_8-3-多机多卡场景" tabindex="-1"><a class="header-anchor" href="#_8-3-多机多卡场景" aria-hidden="true">#</a> 8.3 多机多卡场景</h3><p>当服务器节点间网络通信速度较快时，可以选择 ZeRO、PP+TP+DP：</p><ul><li>ZeRO - 因为它几乎不需要对模型进行任何修改。</li><li>PP+TP+DP - 通信较少，但需要对模型进行大量更改。</li></ul><p>当您服务器节点间网络通信速度较慢，并且 GPU 内存仍然不足时，可以选择 DP+PP+TP+ZeRO-1。</p><p>这里采用 PP 与 ZeRO-1 进行混合并行，<strong>那么 PP 能与 DeepSpeed ZeRO 2/3一起训练吗</strong>？</p><p>答：PP + ZeRO 2/3 不推荐一起训练。 PP 需要累积梯度（accumulate gradients），但 ZeRO2 需要对梯度进行分块（chunk）。 即使能够实现，也没有真正的性能提升。</p><p>将两者结合使用来提高效率并不容易，PP + ZeRO 2 实际上比 ZeRO2（无 PP）更慢且内存效率低。如果用户内存不足，用户可以使用 ZeRO3 代替 ZeRO2 + PP。而正因为如此，在 DeepSpeed 中， PP + ZeRO 2/3 之间不兼容。但可以将 PP 与 ZeRO 1 进行组合使用。</p><p>这里多说一点：即使该方法效率不高，但是 ColossalAI 为了支持更多的并行训练方法。ColossalAI 还是提供了 ZeRO 3 + PP + TP 一起组合的方案。</p><h4 id="_8-4-假如有超多的8卡a100节点-dgx-a100-如何应用3d并行策略" tabindex="-1"><a class="header-anchor" href="#_8-4-假如有超多的8卡a100节点-dgx-a100-如何应用3d并行策略" aria-hidden="true">#</a> 8.4 假如有超多的8卡A100节点（DGX A100），如何应用3D并行策略？</h4><p>参考Megatron-Turing NLG 530B</p><ul><li>首先，张量并行。3种并行方式里，张量并行（TP）对于GPU之间的通信要求最高，而节点内有NVLINK通信速度可以达到600GB/s。</li><li>其次，流水线并行，每个节点负责一部分层，每35个节点组成一路完整的流水线，也就是一个完整的模型副本，这里一个模型副本需280卡。</li><li>最后，数据并行，官方也做了8路，10路，12路的并行实验，分别使用280个节点，350个节点和420个节点。</li></ul><p>集群规模越大，单个GPU利用率越低。</p><h4 id="_8-5-如果想构建这样一个大规模并行训练系统-训练框架如何选" tabindex="-1"><a class="header-anchor" href="#_8-5-如果想构建这样一个大规模并行训练系统-训练框架如何选" aria-hidden="true">#</a> 8.5 如果想构建这样一个大规模并行训练系统，训练框架如何选？</h4><p>可以参考Megatron-Turing NLG 530B，NVIDIA <a href="https://link.zhihu.com/?target=https://github.com/NVIDIA/Megatron-LM" title="Megatron-LM" target="_blank" rel="noopener noreferrer">Megatron-LM<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> + Microsoft <a href="https://link.zhihu.com/?target=https://github.com/microsoft/DeepSpeed" title="DeepSpeed" target="_blank" rel="noopener noreferrer">DeepSpeed<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>BLOOM则是PP+DP用DeepSpeed，TP用Megatron-LM</p><p>当然还有一些其他的训练框架，在超大规模下或许也能work。</p><p>参考：</p><ul><li><a href="https://github.com/microsoft/DeepSpeed/issues/1110" title="Details about pipeline parallelism implementation in DeepSpeed · Issue #1110 ·" target="_blank" rel="noopener noreferrer">Details about pipeline parallelism implementation in DeepSpeed · Issue #1110 ·<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://github.com/microsoft/DeepSpeed/blob/master/deepspeed/runtime/pipe/engine.py" title="DeepSpeed/deepspeed/runtime/pipe/engine.py " target="_blank" rel="noopener noreferrer">DeepSpeed/deepspeed/runtime/pipe/engine.py <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://github.com/hpcaitech/ColossalAI/issues/682" title="How PP and ZeRO stage 2+ work together? · Issue #682" target="_blank" rel="noopener noreferrer">How PP and ZeRO stage 2+ work together? · Issue #682<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://github.com/hpcaitech/ColossalAI/pull/477" title="[zero] ZeRO supports pipeline parallel by ver217 · Pull Request #477 " target="_blank" rel="noopener noreferrer">[zero] ZeRO supports pipeline parallel by ver217 · Pull Request #477 <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="Word Embedding（“词嵌入”，分布式词向量，稠密向量的非零表征，隐含语义的特征表示）" class="vp-link nav-link prev nav-link prev" href="/pinkpig/llm/03_llm_training/08_word_embedding.html"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->Word Embedding（“词嵌入”，分布式词向量，稠密向量的非零表征，隐含语义的特征表示）</div></a><a aria-label="对齐 / 偏好对齐" class="vp-link nav-link next nav-link next" href="/pinkpig/llm/03_llm_training/05_%E5%AF%B9%E9%BD%90.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">对齐 / 偏好对齐<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/pinkpig/assets/app-ieMuNFND.js" defer></script>
  </body>
</html>

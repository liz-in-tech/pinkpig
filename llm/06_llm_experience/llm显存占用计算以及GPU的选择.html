<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://liz-in-tech.github.io/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="GPU显存占用计算"><meta property="og:description" content="GPU显存占用计算 从第一性原则出发，要回答的第一个问题就是，为什么要计算大模型占用的显存资源？一句话概括：显存太小，模型无法运行；显存太大，浪费金钱。所以从成本的角度来看，很有必要分析计算大模型的资源占用 当你手头想要部署某个开源大模型，你的老板可能会问你，需要多大的资源？这时候需要你来确定使用哪种GPU来运行模型。 显存占用计算在线工具 https://rahulschand.github.io/gpu_poor/ https://huggingface.co/spaces/hf-accelerate/model-memory-usage https://vram.asmirnov.xyz/ https://huggingface.co/spaces/Vokturz/can-it-run-llm?ref=blog.runpod.io"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-04-23T13:53:11.000Z"><meta property="article:author" content="Liz"><meta property="article:modified_time" content="2025-04-23T13:53:11.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"GPU显存占用计算","image":[""],"dateModified":"2025-04-23T13:53:11.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/pinkpig/blogger.png"><title>GPU显存占用计算 | Liz</title><meta name="description" content="GPU显存占用计算 从第一性原则出发，要回答的第一个问题就是，为什么要计算大模型占用的显存资源？一句话概括：显存太小，模型无法运行；显存太大，浪费金钱。所以从成本的角度来看，很有必要分析计算大模型的资源占用 当你手头想要部署某个开源大模型，你的老板可能会问你，需要多大的资源？这时候需要你来确定使用哪种GPU来运行模型。 显存占用计算在线工具 https://rahulschand.github.io/gpu_poor/ https://huggingface.co/spaces/hf-accelerate/model-memory-usage https://vram.asmirnov.xyz/ https://huggingface.co/spaces/Vokturz/can-it-run-llm?ref=blog.runpod.io">
    <link rel="preload" href="/pinkpig/assets/style-B4ayxgRu.css" as="style"><link rel="stylesheet" href="/pinkpig/assets/style-B4ayxgRu.css">
    <link rel="modulepreload" href="/pinkpig/assets/app-D6wNGShW.js"><link rel="modulepreload" href="/pinkpig/assets/llm显存占用计算以及GPU的选择.html-LYt2wTaZ.js"><link rel="modulepreload" href="/pinkpig/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/pinkpig/assets/llm显存占用计算以及GPU的选择.html-tYtb1LPm.js">
    <link rel="prefetch" href="/pinkpig/assets/index.html-ibkdGA84.js" as="script"><link rel="prefetch" href="/pinkpig/assets/intro.html-VEF0ZusF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSAPP.html-DfrX1UAP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Netty.html-p8gk6fJ_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/RPC.html-7C88YC2N.js" as="script"><link rel="prefetch" href="/pinkpig/assets/competition.html-9FBFPDQz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/操作系统.html-1QgCNUH3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/浏览器技能.html-uFcrAJVS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/网络.html-36AG3eKy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/计算机技能.html-H-ZX4k04.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AntDesign.html-5NgDnkhT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSS.html-DWW8u9ge.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Expo.html-lJQuUz4Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Frontend.html-a7NJdFWI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/HTML.html-9wodgV5c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/JavaScript.html-lvtDI2LR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Practice.html-lui81Yar.js" as="script"><link rel="prefetch" href="/pinkpig/assets/React.html-b8iVrI2O.js" as="script"><link rel="prefetch" href="/pinkpig/assets/npm.html-cf-i0MG_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/commen_mistakes.html-mGgYvOuL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/grammar.html-H-3z-vXH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english3.html--aWr1mmm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english_detail.html-MQS8h2D6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/pronunciation.html-d7en6ro-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/sentence_pattern_and_expression.html-bv8MyCdJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_llm_roadmap.html-bnnJVWew.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Git使用手册.html-2FKeMxuw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Markdown.html-8ZdG81kj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoshop.html-1AQeTxWq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/python算法刷题语法快速恢复.html-7wyAQOib.js" as="script"><link rel="prefetch" href="/pinkpig/assets/做题经验总结.html-7JmlG7jg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/快速恢复30题.html-M04655mx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/快速恢复30题思路大纲.html-Sn9xRfZI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/算法提升.html-3eGbfge7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/经典题汇总（每个细分类限定10题以内）.html-7Y8Rh4OG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java8学习笔记.html-gBdmNduj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/基础.html-1_ocEQ4I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/集合.html-B3Wp3Upx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/juc.html-5GKFP4UE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/jvm.html-6rKN8Wso.js" as="script"><link rel="prefetch" href="/pinkpig/assets/spring.html-s5U1LwF9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Keymap.html--yTwT5Pe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Problem_and_plugin.html-fhQh8RqL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Maven--java包管理工具.html-scnAhanr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/careers.html-yiJQBxx-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/common.html-8eP_H2he.js" as="script"><link rel="prefetch" href="/pinkpig/assets/communication.html-Ws1GaxQj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computers.html-E9ZVn5M0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/describing_something.html-qB30C2Nz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/dreams.html-KfGof6S4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/graduating.html-P8cgR_ex.js" as="script"><link rel="prefetch" href="/pinkpig/assets/greetings.html-5eDIKNUU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/hobbies.html-j7YJS0Uj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/immigration.html-N3b_zhs7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/introducing_someone.html-8g3aWQlk.js" as="script"><link rel="prefetch" href="/pinkpig/assets/phone.html-83IoFm_-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/routine.html-HbuB0pac.js" as="script"><link rel="prefetch" href="/pinkpig/assets/time_and_weather.html-iKp7YvRN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/traits.html-2kgfa3hS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_llm_evolution.html-yia_gfta.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_emergent_abilities_and_scaling_law.html-DVn6qo4L.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络.html-2Oss4WeY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络1.html-CjsHq7_f.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_rnn.html-H_M06n55.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_attention.html-MApSKzbp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_nlp.html-K0tT5FAc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_编码器与解码器.html-sqKHqcqy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_gpt.html-Za3C2MCe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_llama.html-31qpWODi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_qwen.html-j6_AwMpp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_deepseek.html-B3W1djTi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_LLM关键技术概览.html-anKaf6G3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM构建过程.html-mPzu15NJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_预训练.html-DqQfxNWb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_微调.html-tnqPShz0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_对齐.html-nkDjN9A8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM数据工程.html-fOikUcO4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_tokenizer.html-ybjzGM0K.js" as="script"><link rel="prefetch" href="/pinkpig/assets/08_word_embedding.html-NkIVwupR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/09_分布式训练框架.html-f_4CE-ce.js" as="script"><link rel="prefetch" href="/pinkpig/assets/10_ray.html-snaCKVPs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_解码策略.html--PzsIBtw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM推理.html-UiLUY0jo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_推理框架.html-Qt3AIVVU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_LLM评估.html-lmUpBwjN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_优化技术.html-qepFvgp1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM压缩.html-u6JYyz3R.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_resources.html-ER0hIuhg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/cursor.html-SPLucZvd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/frequent_use_command.html-kuEEE1V7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/google_colab.html-NsrJLy3H.js" as="script"><link rel="prefetch" href="/pinkpig/assets/ipdb.html-lNneRT7f.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt_experience.html-RjAspTy1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/不传之秘.html-yim4NsOO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/GraphQL.html-zq9chJmn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MicroService.html-gqQ9Z22K.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MybatisPlus.html-sXrDLPET.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rocketmq.html-Hl75cf25.js" as="script"><link rel="prefetch" href="/pinkpig/assets/SQL.html-h6ZRnzFD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/mysql.html-w2oyLSBD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/redis.html-RgiRoRd9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Docker.html-v652K6De.js" as="script"><link rel="prefetch" href="/pinkpig/assets/K8S.html-hVxZM-yZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/docker_from_xmind.html-etYvtf7i.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux.html-GKFxuA1k.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux_command.html-iB7MbZV8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/wsl.html-oi6sho5k.js" as="script"><link rel="prefetch" href="/pinkpig/assets/english_words.html-QD9WjIVg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/experience.html-NGzTOw4o.js" as="script"><link rel="prefetch" href="/pinkpig/assets/paper_find.html--xIE94bO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_python_environment.html-Ogc-g3Pl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_python_data_type.html-SsgcwWnj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_python_operator.html-WW78TP0B.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_python_method.html-gy5ccBYv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_python_builtin_module.html-W4QAcEOF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_python_popular_package.html-4W72Pdg1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_python_web.html-2wx4z3ck.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_deep_learning_frameworks.html-6aphJD4D.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_ai_concept.html-FUCs1g0L.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_neural_net_train.html-YPETtbT8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_pytorch_operation.html-yukjJeR7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_pytorch_practice_nn.html-6bU2zAkC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_linear_nn.html-V-M3_Tfb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_heterogeneous_graph.html-eXFNwBOH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_evolution.html-dPUJTcbb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/0.时空复杂度.html-duqIgH8Z.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.分治思想_递归实现.html-ZR8C9fAr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.二进制_位运算.html-IPYNI70m.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.排序.html-SwglYgQW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.二分查找.html-6XjBZtvX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.动态规划_贪心.html-JlAVeSTu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.字符串.html-H_Kw0VHp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.数学.html-JB3Fd046.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.算法技巧.html-0zv2JKDG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.数组.html-2pX8ASkd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.链表.html-MDTUDdof.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.栈.html-VhlnLXDW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.队列.html-5RW94C74.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.堆（优先队列）.html-9UtOuX_z.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.树.html-eY_fw8EL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.图.html-C6zmof_l.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.哈希表（散列表）.html-rEshAQ6r.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java语言基础.html-zkZgse3g.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent.html-YzftFD9b.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent_research.html-pZN9c_1T.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computer_use_same.html-KOaRH6Ml.js" as="script"><link rel="prefetch" href="/pinkpig/assets/langchain.html-i58jGmH0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/memory.html-ly8uWP03.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt.html-lL6RQ9Ux.js" as="script"><link rel="prefetch" href="/pinkpig/assets/018_autorag.html-3i5c7At_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rag_opensource.html-G7UpFpJ-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/404.html-ELYBSFNe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ZtH9hb0Y.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ndBqxueE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FhfXXQqd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Y18Gk6ug.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PYFEr-gw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-n6sTAWGG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-SpiN3Ual.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-lySh48SJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-QLcoUYFo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OkAhqWR6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-WjAYn9Z-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2CIdeSnB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ayy3EF9I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zpwaHXIV.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-nGOSO6_S.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-iyn2Phdl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Ls2hwge3.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-_e4jAiDs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-MDiPagDx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-RmQTNmcI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-uTiIdO0F.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-TrYac60Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OWFxg9Im.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PfTXE4w9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html--tUsRM8W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ik3y9HJ8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2LBMckbl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-jSFk7HPD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-aX5SAJZk.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-avJpz5gY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-7kqkDjc1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-11KJ3gwb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-LQuERQvK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6iizFISA.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-7EXy9ft5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BYKqQoTu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OUm-Xb__.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Q77JHGwp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-qSCg3dme.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-3AOtZ1O7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-NUrjn_rx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ZkjR0Tnl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-4fJRFXlS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-0Zni0yS2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-x4TH_xzP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-yZYnH68c.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-M3KBctL2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8WjFejoc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-KzgtbF_l.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-bUj5_ism.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-xtYkLxjR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-xfwIgr3s.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-AVn-_fFT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-V6IelPdJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-wvgAZYvE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Bp62bPd5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FTMRL3lu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Ob7dvR-M.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-2oWEcuGm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Di6h8Ky1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-5GuLlprQ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dbwd_1YG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-dQ2QFe76.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-DKIbv2Jr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-kmPKSOrX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PjKCTcgX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-WHhL-UfW.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-FHbtXQBu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-j0J10-eI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-wZEowyhF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/intro.html-WQI-JNx7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSAPP.html-wqIZ7yxl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Netty.html-FDHjnee8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/RPC.html-t9MQ5XoD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/competition.html-k0dta5R7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/操作系统.html-m6yocnHy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/浏览器技能.html-RbC7KasS.js" as="script"><link rel="prefetch" href="/pinkpig/assets/网络.html-XmMwJRTf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/计算机技能.html-FeAxF12Z.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AntDesign.html-L97Pqs8P.js" as="script"><link rel="prefetch" href="/pinkpig/assets/CSS.html-vEiRMTph.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Expo.html-b70ZLlvN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Frontend.html-e9jQNGw_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/HTML.html-mnklU5pR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/JavaScript.html-Coe5qPNg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Practice.html-W2z7gljC.js" as="script"><link rel="prefetch" href="/pinkpig/assets/React.html-ociSuVDw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/npm.html-W--Bt4Lc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/commen_mistakes.html-X65bwLKu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/grammar.html-8jYLN2_t.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english3.html-UDXjBgNK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/new_concept_english_detail.html-Sd6PMT6Z.js" as="script"><link rel="prefetch" href="/pinkpig/assets/pronunciation.html-kY1g1ilR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/sentence_pattern_and_expression.html-ceJ-S_4O.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_llm_roadmap.html-xrG5RhVX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Git使用手册.html-PUSbWN2b.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Markdown.html-dmBbz-8s.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoshop.html-qICFFzxv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/python算法刷题语法快速恢复.html-blkJqVPX.js" as="script"><link rel="prefetch" href="/pinkpig/assets/做题经验总结.html-Yr554qH9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/快速恢复30题.html-XW7T27P9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/快速恢复30题思路大纲.html-qACUU4K8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/算法提升.html-j5D9GoJr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/经典题汇总（每个细分类限定10题以内）.html-EFQO_piv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java8学习笔记.html-YmpBODmr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/基础.html-cfYSXFsB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/集合.html-9PSgWyVL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/juc.html-FQhYVgcm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/jvm.html-pgJHTbF6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/spring.html-ERUsbQLr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Keymap.html-6csa3nOs.js" as="script"><link rel="prefetch" href="/pinkpig/assets/IDEA_Problem_and_plugin.html-SRx32EWD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Maven--java包管理工具.html-JYwNwlQm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/careers.html-51gV8i4o.js" as="script"><link rel="prefetch" href="/pinkpig/assets/common.html-GcBtyDk2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/communication.html-5KvLNp_i.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computers.html-goucRteD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/describing_something.html-iq9ylv5t.js" as="script"><link rel="prefetch" href="/pinkpig/assets/dreams.html-d9iQDbio.js" as="script"><link rel="prefetch" href="/pinkpig/assets/graduating.html-LS6pP7lN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/greetings.html-d951LIAT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/hobbies.html-09i6rp1w.js" as="script"><link rel="prefetch" href="/pinkpig/assets/immigration.html-EPnTP5NK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/introducing_someone.html-alIKA9ve.js" as="script"><link rel="prefetch" href="/pinkpig/assets/phone.html-6X8Kg3y1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/routine.html-5DPSviHJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/time_and_weather.html-iQQU0qih.js" as="script"><link rel="prefetch" href="/pinkpig/assets/traits.html-y2Ozfwh0.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_llm_evolution.html-bNJ3fC_W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_emergent_abilities_and_scaling_law.html-Ge0mzzqM.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络.html-53wdCiUd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_神经网络1.html-QDGLGbwF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_rnn.html-ogKss1xH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_attention.html-COV5U3Tc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_nlp.html-9q2JQJrg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_编码器与解码器.html-wpG6b__9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_gpt.html-PhsEshg6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_llama.html-9J_Rad_b.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_qwen.html-MPbTaRF7.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_deepseek.html-6319JNjN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_LLM关键技术概览.html-4dNUzWMV.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM构建过程.html-zDcKU1Ks.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_预训练.html-pMaz1SAO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_微调.html-P43WYObw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_对齐.html-eJZsKSFP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM数据工程.html-5JVEvC2_.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_tokenizer.html-hfxLNmvF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/08_word_embedding.html-2Q6uT5tY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/09_分布式训练框架.html-k35dT6fT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/10_ray.html-pk_7Pnd2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_解码策略.html-gkEdx4RI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_LLM推理.html-wYAC6olv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_推理框架.html-co9hqwnK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_LLM评估.html-0fARXfBb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_优化技术.html-N0nxcGbL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_LLM压缩.html-cdRAbCBE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_resources.html-DelYHHzJ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/cursor.html-liZ2PiVY.js" as="script"><link rel="prefetch" href="/pinkpig/assets/frequent_use_command.html-pPcWtFCe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/google_colab.html-n8Zi5enI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/ipdb.html-tkzSaZVT.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt_experience.html-lzBN_0rg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/不传之秘.html-KS_QfWuy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/GraphQL.html-2u0z_90G.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MicroService.html-44y53SkF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/MybatisPlus.html-IjYvp6c8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rocketmq.html-95QRDeO5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/SQL.html-xxUfuMwn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/mysql.html-PkhB28Df.js" as="script"><link rel="prefetch" href="/pinkpig/assets/redis.html-pu_qr4hI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Docker.html-z-gD9cLo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/K8S.html-h75NpAbv.js" as="script"><link rel="prefetch" href="/pinkpig/assets/docker_from_xmind.html-gowtlcie.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux.html-qrVtWxWi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/linux_command.html-PJgkiiMi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/wsl.html-Yf3kRssE.js" as="script"><link rel="prefetch" href="/pinkpig/assets/english_words.html-3ikj3wMB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/experience.html-pWxINY6n.js" as="script"><link rel="prefetch" href="/pinkpig/assets/paper_find.html-0m09BbXF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_python_environment.html-aS7jfUyh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_python_data_type.html-JQdXNgFp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_python_operator.html-F1Kl49_m.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_python_method.html-k2oqLMmF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_python_builtin_module.html-Np2OgLJy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_python_popular_package.html-DBR4vHd-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/07_python_web.html-Cg-PY9rI.js" as="script"><link rel="prefetch" href="/pinkpig/assets/00_deep_learning_frameworks.html-Rsg4oZ6w.js" as="script"><link rel="prefetch" href="/pinkpig/assets/01_ai_concept.html-QkEunHQF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/02_neural_net_train.html-Hx7cY5Ns.js" as="script"><link rel="prefetch" href="/pinkpig/assets/03_pytorch_operation.html-GoeYZAOl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/04_pytorch_practice_nn.html-ppLkTaen.js" as="script"><link rel="prefetch" href="/pinkpig/assets/05_linear_nn.html-8s67lDvM.js" as="script"><link rel="prefetch" href="/pinkpig/assets/06_heterogeneous_graph.html-_1FDtO-x.js" as="script"><link rel="prefetch" href="/pinkpig/assets/AI_evolution.html-gBCavySa.js" as="script"><link rel="prefetch" href="/pinkpig/assets/0.时空复杂度.html-aiVOMya4.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.分治思想_递归实现.html-ZYClRmvx.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.二进制_位运算.html-JcB3dR2D.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.排序.html-VcEzH5Yj.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.二分查找.html-y9eUPvQo.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.动态规划_贪心.html-JuKZnH7p.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.字符串.html-PFt-MgYf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.数学.html-dZ9zqU3D.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.算法技巧.html-2j4Xcd0p.js" as="script"><link rel="prefetch" href="/pinkpig/assets/1.数组.html-hNYDEIBz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/2.链表.html-3kgUkyPl.js" as="script"><link rel="prefetch" href="/pinkpig/assets/3.栈.html-Xb_1PsI5.js" as="script"><link rel="prefetch" href="/pinkpig/assets/4.队列.html-qKITRpFa.js" as="script"><link rel="prefetch" href="/pinkpig/assets/5.堆（优先队列）.html-saZa_tbL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/6.树.html-Z2GDAL7w.js" as="script"><link rel="prefetch" href="/pinkpig/assets/7.图.html-K3vD5tPG.js" as="script"><link rel="prefetch" href="/pinkpig/assets/8.哈希表（散列表）.html-1JSAtxLq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/Java语言基础.html-hGxHbfzm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent.html-RjG3cJnD.js" as="script"><link rel="prefetch" href="/pinkpig/assets/agent_research.html-GNaio_jd.js" as="script"><link rel="prefetch" href="/pinkpig/assets/computer_use_same.html-0MMRwwqb.js" as="script"><link rel="prefetch" href="/pinkpig/assets/langchain.html-Aalc8G0k.js" as="script"><link rel="prefetch" href="/pinkpig/assets/memory.html-_mdszx0n.js" as="script"><link rel="prefetch" href="/pinkpig/assets/prompt.html-dweaYxH6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/018_autorag.html-sIA9ayqN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/rag_opensource.html-IVX4l97t.js" as="script"><link rel="prefetch" href="/pinkpig/assets/404.html-0JAJWb9Q.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-KLjoYOzP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-iTDpzDMp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-7TnxM4nt.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8jBXoYoR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-DYSxpFgq.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-XQMeiO2B.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-0_ALjA2I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-c1f6EvrZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-IhPLdl1I.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Hfz2T6hi.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Gk61EMXc.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-pZpmUIZR.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-tcVy-a6N.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ZXKg8Sgh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6-ZIAR7-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-YT2qXWS1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-uInwiOeZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-E7W2sHuA.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-eyYLFi6F.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-EM4-Pnsr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ry_pPgz-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-RrOXpPWL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6oh_GCz8.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BKow0fy6.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-NqP26unP.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-VEm_ekV1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-SSCLzHt-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ymd734pz.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-1ahzU1z2.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Tts-IVCn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-OPWc5gye.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-6gIchGsO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-rAmT6gy-.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Vfq36Htu.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-s6B2Ku9s.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-34Vatc9W.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-x2L9lzgh.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-CmKyROvy.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BZxkpoZA.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-zZfHLpFn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8eM4hDnn.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-tuz4d1BH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-BGUKkdMO.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-x0xMnmrZ.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-jo60guVU.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-KS3L2TgK.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-eVlXwMiL.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-TTEg_dGg.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ByX5Cbg1.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-NfrnxkVm.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-HX-iUZth.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-9Dlpf43D.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-ukbEXHKr.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-hEKIsecB.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-8J3o-uBw.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html--Vr3kf0x.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-y3xHaDzf.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-fNolfeQF.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-_3qPJn-T.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-INC4xymN.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-q9ntNdwe.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Jz8syb-r.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-jxJZMdHp.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-PpgIgJ3x.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-voRaPes9.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-htaJh_ra.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-kHcsdC5i.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-fRkKM3LH.js" as="script"><link rel="prefetch" href="/pinkpig/assets/index.html-Tajg2m1n.js" as="script"><link rel="prefetch" href="/pinkpig/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/pinkpig/"><img class="vp-nav-logo" src="/pinkpig/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Language" class="vp-link nav-link nav-link" href="/pinkpig/language/"><!---->Language<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="LLM" class="vp-link nav-link active nav-link active" href="/pinkpig/llm/"><!---->LLM<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Python" class="vp-link nav-link nav-link" href="/pinkpig/python/"><!---->Python<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Java" class="vp-link nav-link nav-link" href="/pinkpig/java/"><!---->Java<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Frontend" class="vp-link nav-link nav-link" href="/pinkpig/frontend/"><!---->Frontend<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Middleware" class="vp-link nav-link nav-link" href="/pinkpig/middleware/"><!---->Middleware<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="CS" class="vp-link nav-link nav-link" href="/pinkpig/cs/"><!---->CS<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Operations" class="vp-link nav-link nav-link" href="/pinkpig/operations/"><!---->Operations<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Tools" class="vp-link nav-link nav-link" href="/pinkpig/tools/"><!---->Tools<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">Llm</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">01 Llm Basic</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">02 Llm Architecture</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">03 Llm Training</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">04 Llm Reasoning</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">05 Llm Engineering</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">06 Llm Experience</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a aria-label="AI 资源" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/AI_resources.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>AI 资源<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="AI使用经验积累" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/prompt_experience.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>AI使用经验积累<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="cursor" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/cursor.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>cursor<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Google Colab" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/google_colab.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Google Colab<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="GPU显存占用计算" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html"><!---->GPU显存占用计算<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="显存占用计算在线工具" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#显存占用计算在线工具"><!---->显存占用计算在线工具<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1. 大模型常见规格" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_1-大模型常见规格"><!---->1. 大模型常见规格<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="参数量估算 (n B)" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#参数量估算-n-b"><!---->参数量估算 (n B)<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="2. 模型文件有多大 (2n GB)" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_2-模型文件有多大-2n-gb"><!---->2. 模型文件有多大 (2n GB)<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="3. nB 模型推理需要多少显存 (2n GB)" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_3-nb-模型推理需要多少显存-2n-gb"><!---->3. nB 模型推理需要多少显存 (2n GB)<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4. nB 模型训练需要多少显存" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-nb-模型训练需要多少显存"><!---->4. nB 模型训练需要多少显存<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="4.1. gege version3" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-1-gege-version3"><!---->4.1. gege version3<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4.2. GPU 显存计算  version2" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-2-gpu-显存计算-version2"><!---->4.2. GPU 显存计算  version2<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4.3 version3" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-3-version3"><!---->4.3 version3<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4.4. 混合精度（详见blog和deepspeed处）" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-4-混合精度-详见blog和deepspeed处"><!---->4.4. 混合精度（详见blog和deepspeed处）<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4.5. 实践案例" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-5-实践案例"><!---->4.5. 实践案例<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="5. 能否用4 * v100 32G训练vicuna 65b？" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_5-能否用4-v100-32g训练vicuna-65b"><!---->5. 能否用4 * v100 32G训练vicuna 65b？<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="6. 全参数微调所需显存量的考虑因素" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_6-全参数微调所需显存量的考虑因素"><!---->6. 全参数微调所需显存量的考虑因素<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="7.样本量规模增大，训练出现OOM错解决方案" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_7-样本量规模增大-训练出现oom错解决方案"><!---->7.样本量规模增大，训练出现OOM错解决方案<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1. 哥哥现有GPU资源" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_1-哥哥现有gpu资源"><!---->1. 哥哥现有GPU资源<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="显存含义" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#显存含义"><!---->显存含义<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Cuda Cores和Tensor Cores" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#cuda-cores和tensor-cores"><!---->Cuda Cores和Tensor Cores<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="不同GPU对精度的支持力度" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#不同gpu对精度的支持力度"><!---->不同GPU对精度的支持力度<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="2. 选择 GPU 用于 AI 机器学习和 LLM 的关键因素" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_2-选择-gpu-用于-ai-机器学习和-llm-的关键因素"><!---->2. 选择 GPU 用于 AI 机器学习和 LLM 的关键因素<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="3. NVIDIA GPU 参数速查表" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_3-nvidia-gpu-参数速查表"><!---->3. NVIDIA GPU 参数速查表<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4. GPU介绍" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/pinkpig/llm/06_llm_experience/llm%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E4%BB%A5%E5%8F%8AGPU%E7%9A%84%E9%80%89%E6%8B%A9.html#_4-gpu介绍"><!---->4. GPU介绍<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li><li><!--[--><a aria-label="ipdb" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/ipdb.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>ipdb<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="不传之秘" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/%E4%B8%8D%E4%BC%A0%E4%B9%8B%E7%A7%98.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>不传之秘<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="常用命令" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/06_llm_experience/frequent_use_command.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>常用命令<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li><li><!--[--><a aria-label="LLM Roadmap" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/pinkpig/llm/00_llm_roadmap.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>LLM Roadmap<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->GPU显存占用计算</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-04-23T13:53:11.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 15 min</span><meta property="timeRequired" content="PT15M"></span><!----><!----></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#显存占用计算在线工具">显存占用计算在线工具</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-大模型常见规格">1. 大模型常见规格</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#参数量估算-n-b">参数量估算 (n B)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-模型文件有多大-2n-gb">2. 模型文件有多大 (2n GB)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-nb-模型推理需要多少显存-2n-gb">3. nB 模型推理需要多少显存 (2n GB)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-nb-模型训练需要多少显存">4. nB 模型训练需要多少显存</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-gege-version3">4.1. gege version3</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-gpu-显存计算-version2">4.2. GPU 显存计算  version2</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-3-version3">4.3 version3</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-4-混合精度-详见blog和deepspeed处">4.4. 混合精度（详见blog和deepspeed处）</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-5-实践案例">4.5. 实践案例</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-能否用4-v100-32g训练vicuna-65b">5. 能否用4 * v100 32G训练vicuna 65b？</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-全参数微调所需显存量的考虑因素">6. 全参数微调所需显存量的考虑因素</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-样本量规模增大-训练出现oom错解决方案">7.样本量规模增大，训练出现OOM错解决方案</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-哥哥现有gpu资源">1. 哥哥现有GPU资源</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#显存含义">显存含义</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#cuda-cores和tensor-cores">Cuda Cores和Tensor Cores</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#不同gpu对精度的支持力度">不同GPU对精度的支持力度</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-选择-gpu-用于-ai-机器学习和-llm-的关键因素">2. 选择 GPU 用于 AI 机器学习和 LLM 的关键因素</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-nvidia-gpu-参数速查表">3. NVIDIA GPU 参数速查表</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-gpu介绍">4. GPU介绍</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="gpu显存占用计算" tabindex="-1"><a class="header-anchor" href="#gpu显存占用计算" aria-hidden="true">#</a> GPU显存占用计算</h1><p>从第一性原则出发，要回答的第一个问题就是，为什么要计算大模型占用的显存资源？一句话概括：显存太小，模型无法运行；显存太大，浪费金钱。所以从成本的角度来看，很有必要分析计算大模型的资源占用</p><p>当你手头想要部署某个开源大模型，你的老板可能会问你，需要多大的资源？这时候需要你来确定使用哪种GPU来运行模型。</p><h2 id="显存占用计算在线工具" tabindex="-1"><a class="header-anchor" href="#显存占用计算在线工具" aria-hidden="true">#</a> 显存占用计算在线工具</h2><ul><li>https://rahulschand.github.io/gpu_poor/</li><li>https://huggingface.co/spaces/hf-accelerate/model-memory-usage</li><li>https://vram.asmirnov.xyz/</li><li>https://huggingface.co/spaces/Vokturz/can-it-run-llm?ref=blog.runpod.io</li></ul><h2 id="_1-大模型常见规格" tabindex="-1"><a class="header-anchor" href="#_1-大模型常见规格" aria-hidden="true">#</a> 1. 大模型常见规格</h2><p>一般模型的规格会体现在模型的名称上，例如 LLaMA2-13b，13b 就是其模型<strong>参数量</strong>的大小，意思是130亿的参数量。</p><p>如何查看</p><ul><li>huggingface上找到相应组织后，看模型的Collection</li></ul><p>各模型汇总</p><ul><li>Llama <ul><li>Llama 3.3：70B</li><li>Llama 3.2：1B，3B，11B（vision），90B（vision）</li><li>Llama 3.1：8B，70B，405B</li><li>Llama 3：8B，70B</li></ul></li><li>Qwen <ul><li>Qwen 2.5：0.5B、1.5B、3B、7B、14B、32B、72B</li><li>QwQ：32B</li></ul></li><li>Deepseek <ul><li>DeepSeek LLM：7B，67B</li><li>DeepSeek V3：671B</li><li>DeepSeek R1：671B，蒸馏版：（1.5B，7B，8B，14B，32B，70B）</li></ul></li><li>Gemini <ul><li>Gemma 3：1B，4B，12B，27B</li></ul></li></ul><p>规格总结：</p><ul><li>小型（&lt;10B）：0.5B，1B，1.5B，3B，4B，7B，8B</li><li>中型（10B-100B）：11B，12B，14B，27B，32B，67B，70B，72B，90B</li><li>大型（&gt;100B）：405B，671B</li></ul><h2 id="参数量估算-n-b" tabindex="-1"><a class="header-anchor" href="#参数量估算-n-b" aria-hidden="true">#</a> 参数量估算 (n B)</h2><ul><li>参数主要集中在注意力块和MLP块 <ul><li>注意力块 <ul><li>QKVO 四个线性层 <ul><li>形状 <ul><li>Q/O : [H * H]</li><li>K/V : [H * 1/4 H] (由于 repeat_kv=4)</li></ul></li><li>为了方便计算，也考虑到还有其他参数没有算进来，这里4个线性层都按[H * H]来算</li><li>共 4 H^2</li></ul></li></ul></li><li>MLP块 <ul><li>gate/up/down 三个线性层 <ul><li>形状 [H * 4H] = 4H^2</li><li>共 12 H^2</li></ul></li></ul></li></ul></li><li>影响参数量的两大变量： <ul><li>层数: L</li><li>隐状态维度(hidden_state): H</li></ul></li><li>参数量估算：<strong>16·L·H^2</strong><ul><li>Llama-8B，L=32，H=4096 <ul><li>按上述公式估算参数为 8,589,934,592</li><li>实际参数量为 8,030,261,248</li></ul></li></ul></li></ul><h2 id="_2-模型文件有多大-2n-gb" tabindex="-1"><a class="header-anchor" href="#_2-模型文件有多大-2n-gb" aria-hidden="true">#</a> 2. 模型文件有多大 (2n GB)</h2><p>大模型的文件大小与其参数量有关，通常大模型是以<strong>半精度</strong>存储的（一般放出来的模型文件都是fp16的）， nB 的模型文件大概是 2n GB多一些，例如 13B 的模型文件大小大约是 27GB 左右。</p><p>如果一个 8B（即 80 亿，或 8 × 10⁹）参数的 LLM（大语言模型），每个参数占用 2 个字节，那么整体模型大小就是：16 × 10⁹ bytes</p><p>换算成更常用的单位：</p><p>字节（Bytes）：16,000,000,000 字节</p><p>千字节（KB）：16,000,000,000 ÷ 1024 ≈ 15,625,000 KB</p><p>兆字节（MB）：15,625,000 ÷ 1024 ≈ 15,258 MB</p><p>吉字节（GB）：15,258 ÷ 1024 ≈ 14.9 GB</p><h2 id="_3-nb-模型推理需要多少显存-2n-gb" tabindex="-1"><a class="header-anchor" href="#_3-nb-模型推理需要多少显存-2n-gb" aria-hidden="true">#</a> 3. nB 模型推理需要多少显存 (2n GB)</h2><p>fp16加载到显存里做推理也是占 2n GB，和文件大小一致</p><p>一般来说推理模型需要的显存约等于模型文件大小</p><h2 id="_4-nb-模型训练需要多少显存" tabindex="-1"><a class="header-anchor" href="#_4-nb-模型训练需要多少显存" aria-hidden="true">#</a> 4. nB 模型训练需要多少显存</h2><h3 id="_4-1-gege-version3" tabindex="-1"><a class="header-anchor" href="#_4-1-gege-version3" aria-hidden="true">#</a> 4.1. gege version3</h3><p>推理x2,训练x8</p><p>bf16</p><p>每个参数占2个字节</p><p>推理只有模型参数</p><p>训练，参数1，梯度1,优化器2,激活值不计，4份参数大小 * 2 = 8</p><h3 id="_4-2-gpu-显存计算-version2" tabindex="-1"><a class="header-anchor" href="#_4-2-gpu-显存计算-version2" aria-hidden="true">#</a> 4.2. GPU 显存计算 version2</h3><p>nB LLM</p><ul><li>模型文件大小： 2n GB</li><li>全量微调： 10n GB</li><li>LoRA微调： 略比 2n GB 大，训练的参数都不到原参数量的1%</li></ul><p>全量微调 （需要 10n GB）</p><ul><li>模型本身 *1</li><li>Gradient *1</li><li>Optimizer States * 2</li><li>激活值 *1</li></ul><p>LoRA (略比2n GB大，训练的参数都不到原参数量的1%)</p><p>Trainable: 20971520 | total: 7262703616 | Percentage: 0.2888%</p><ul><li>模型本身 *1</li><li>Gradient *1 * 1%</li><li>Optimizer States * 2 * 1%</li></ul><h3 id="_4-3-version3" tabindex="-1"><a class="header-anchor" href="#_4-3-version3" aria-hidden="true">#</a> 4.3 version3</h3><p>推理显存占用 = 参数量 * 2字节 * 1.2</p><p>（也就是4.1推理显存占用基础上乘以1.2）</p><figure><img src="/pinkpig/assets/image-8-B6pIljIq.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/pinkpig/assets/image-9-vCymJveG.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>参考来源：https://blog.runpod.io/understanding-vram-and-how-much-your-llm-needs/</p><h3 id="_4-4-混合精度-详见blog和deepspeed处" tabindex="-1"><a class="header-anchor" href="#_4-4-混合精度-详见blog和deepspeed处" aria-hidden="true">#</a> 4.4. 混合精度（详见blog和deepspeed处）</h3><p>基础显存：模型参数2n+梯度2n+优化器12n = 16nG 显存</p><p>激活值占用显存，和max len、batch size有关</p><p>解释：优化器部分必须用fp32（似乎fp16会导致训练不稳定），所以应该是 2+2+12=16，参考 ZeRO 论文</p><p>举例：7B 的 vicuna 在 fsdp 下总共 160G 显存勉强可以训练 - 按照上面计算出 7 * 16 = 112G 是基础显存 - 全量训练准备 20nG 大概是最低要求，除非内存充足，显存不够 offload 内存补</p><figure><img src="/pinkpig/assets/image-4-qRDZ9yx2.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/pinkpig/assets/image-5-IY0goyC8.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_4-5-实践案例" tabindex="-1"><a class="header-anchor" href="#_4-5-实践案例" aria-hidden="true">#</a> 4.5. 实践案例</h3><ul><li>只有4.3节实际案例没看，其他都看了 https://www.baseten.co/blog/llm-transformer-inference-guide/</li><li>英文原版 https://blog.csdn.net/weixin_65514978/article/details/141728918</li></ul><h2 id="_5-能否用4-v100-32g训练vicuna-65b" tabindex="-1"><a class="header-anchor" href="#_5-能否用4-v100-32g训练vicuna-65b" aria-hidden="true">#</a> 5. 能否用4 * v100 32G训练vicuna 65b？</h2><p>不能。推理都有些吃力，更无法进行全参数训练。</p><p>首先，llama 65b 的权重需要5 * v100 32G 才能完整加载到GPU (推理约需要65x2=130GB，5张v100才够放)</p><p>其次，vicuna 使用 flash-attention 加速训练，暂不支持 v100，需要 turing 架构之后的显卡</p><p>一般来说推理模型需要的显存约等于模型文件大小，全参训练需要的显存约为推理所需显存的三倍到四倍，正常来说，在不量化的情况下4张 v100 显卡推理 65b 的模型都会有一些吃力，无法进行训练，需要通过 LoRA 或者 QLoRA 采用低秩分解的方式才可以训练。</p><h2 id="_6-全参数微调所需显存量的考虑因素" tabindex="-1"><a class="header-anchor" href="#_6-全参数微调所需显存量的考虑因素" aria-hidden="true">#</a> 6. 全参数微调所需显存量的考虑因素</h2><ul><li>模型大小</li><li>批次大小</li><li>输入序列长度</li><li>计算平台和优化 <ul><li>不同的计算平台和深度学习框架可能在显存使用方面存在差异。一些框架可能会提供显存优化的功能，例如梯度检查点（Gradient Checkpointing）或混合精度训练（Mixed Precision Training），以减少显存的使用。</li></ul></li></ul><h2 id="_7-样本量规模增大-训练出现oom错解决方案" tabindex="-1"><a class="header-anchor" href="#_7-样本量规模增大-训练出现oom错解决方案" aria-hidden="true">#</a> 7.样本量规模增大，训练出现OOM错解决方案</h2><ol><li><strong>减少批量大小（Batch Size）</strong>：将批量大小减小可以减少每个训练步骤中所需的内存量。较小的批量大小可能会导致训练过程中的梯度估计不稳定，但可以通过增加训练步骤的数量来弥补这一问题。</li><li><strong>分布式训练</strong>：使用多台机器或多个GPU进行分布式训练可以将训练负载分散到多个设备上，从而减少单个设备上的内存需求。通过分布式训练，可以将模型参数和梯度在多个设备之间进行同步和更新。</li><li><strong>内存优化技术</strong>：使用一些内存优化技术可以减少模型训练过程中的内存占用。例如，使用**混合精度训练（Mixed Precision Training）<strong>可以减少模型参数的内存占用；使用</strong>梯度累积（Gradient Accumulation）**可以减少每个训练步骤中的内存需求。</li><li><strong>减少模型规模</strong>：如果内存问题仍然存在，可以考虑减少模型的规模，例如减少模型的层数、隐藏单元的数量等。虽然这可能会导致模型性能的一定损失，但可以在一定程度上减少内存需求。</li><li><strong>增加硬件资源</strong>：如果条件允许，可以考虑增加硬件资源，例如增加内存容量或使用更高内存的设备。这样可以提供更多的内存空间来容纳更大规模的训练数据。</li><li><strong>数据处理和加载优化</strong>：优化数据处理和加载过程可以减少训练过程中的内存占用。例如，可以使用数据流水线技术来并行加载和处理数据，减少内存中同时存在的数据量。</li></ol><h1 id="gpu-如何选择" tabindex="-1"><a class="header-anchor" href="#gpu-如何选择" aria-hidden="true">#</a> GPU 如何选择</h1><h2 id="_1-哥哥现有gpu资源" tabindex="-1"><a class="header-anchor" href="#_1-哥哥现有gpu资源" aria-hidden="true">#</a> 1. 哥哥现有GPU资源</h2><ul><li>魔改版2080 Ti 共4张（家里）</li><li>哥哥主要有A800（公司）</li></ul><p>a800和h800都是80G显存</p><figure><img src="/pinkpig/assets/a800_h800-3uA0zT_n.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>算力差距好明显，他妈的我们组的48张h800都被一个人占得死死的，他能跑预训练</p><h2 id="显存含义" tabindex="-1"><a class="header-anchor" href="#显存含义" aria-hidden="true">#</a> 显存含义</h2><p>显存，也称为视频随机存取存储器（Video Random Access Memory，VRAM），是一种用于GPU的特殊内存类型。是用于存储图形处理器（GPU）处理数据的专用存储器。显存的主要作用是为GPU提供快速访问数据的能力，包括图像、纹理、帧缓存等。显存的大小和速度直接影响图形处理能力，特别是在3D渲染、高分辨率视频处理、深度学习和其他需要大量数据处理的任务中。GPU都会配备一定的VRAM，如下图所示。</p><figure><img src="/pinkpig/assets/image-evMfJU0T.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>与系统RAM不同，系统RAM与CPU和其他组件共享，而VRAM则专用于GPU。确保GPU可以不间断地访问内存，从而提高了性能的稳定性和可预测性。GPU通过允许应用程序中的重复计算并行运行来补充CPU架构，而主程序则继续在CPU上运行。CPU可以被认为是整个系统的任务管理者，负责协调各种通用计算任务，而GPU则执行范围更窄但更专业化的任务（通常是数学计算）。利用并行计算的强大能力，GPU可以在相同的时间内完成比CPU更多的工作。CPU和GPU各有优势，CPU擅长处理复杂的逻辑和串行任务，而GPU擅长处理并行计算任务。显存则是GPU发挥其计算能力的重要支撑，足够大的显存容量和带宽可以防止因为数据传输瓶颈而导致的性能下降</p><figure><img src="/pinkpig/assets/image-1-h30eL_XZ.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="cuda-cores和tensor-cores" tabindex="-1"><a class="header-anchor" href="#cuda-cores和tensor-cores" aria-hidden="true">#</a> Cuda Cores和Tensor Cores</h2><p>GPU携带了两种关键组成：Cuda Cores(CUDA 核心)和Tensor Cores(张量核心)，这个配置信息对于GPU的选择也是尤为重要</p><p>CUDA（Compute Unified Device Architecture）核心是 NVIDIA 于 2007 年开发的，是 GPU 的基本处理单元，能够处理广泛的并行计算任务。CUDA 核心在顺序处理方面表现出色，是传统图形渲染、物理仿真和通用 GPU 计算的主力。另一方面，Tensor Cores 是 NVIDIA 在 2017 年推出的 Volta 架构中引入的专用处理单元，并在后续几代产品中得到进一步改进。这些核心专门设计用于加速深度学习，特别是神经网络计算中常见的矩阵乘法和卷积操作。</p><figure><img src="/pinkpig/assets/image-2-i4YPNI1n.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>从对比项目来看，对于深度学习、大模型任务来说，Tensor Cores显得更为关键。Tensor Cores 支持混合精度计算（FP16、INT8、INT4 等），在不显著降低计算精度的情况下，减少计算所需的内存和带宽。这使得 Tensor Cores 在处理深度学习工作负载时，比只支持单一精度（如 FP32、FP64）的 CUDA Cores 更高效</p><p>Tensor Cores 与 CUDA Cores共享 VRAM（显存），在 NVIDIA GPU 架构中，显存（VRAM）是一个公共资源，供所有类型的计算单元（包括 CUDA Cores 和 Tensor Cores）使用。如下图所示：</p><figure><img src="/pinkpig/assets/image-3-RiGyzF1V.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="不同gpu对精度的支持力度" tabindex="-1"><a class="header-anchor" href="#不同gpu对精度的支持力度" aria-hidden="true">#</a> 不同GPU对精度的支持力度</h2><p>对于不同的精度，GPU架构和版本的不同，支持的力度存在差异。因此对于模型的训练、推理涉及的数值精度，需要按照实际情况选择GPU型号。</p><figure><img src="/pinkpig/assets/image-6-eX2Mwt0B.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/pinkpig/assets/image-6-eX2Mwt0B.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-选择-gpu-用于-ai-机器学习和-llm-的关键因素" tabindex="-1"><a class="header-anchor" href="#_2-选择-gpu-用于-ai-机器学习和-llm-的关键因素" aria-hidden="true">#</a> 2. 选择 GPU 用于 AI 机器学习和 LLM 的关键因素</h2><ol><li>计算性能</li></ol><ul><li><strong>FP16/TF32/FP8 Tensor Core 性能</strong>：深度学习训练和推理通常使用这些低精度计算格式，计算性能越高，训练速度越快。</li><li><strong>FP32 性能</strong>：用于部分模型计算需求。</li><li><strong>INT8 性能</strong>：用于推理优化，影响 LLM 部署效率。</li></ul><ol start="2"><li>显存 (VRAM)</li></ol><ul><li><strong>容量 (GB)</strong>：LLM 训练和推理需要大量显存。例如： <ul><li><strong>8GB–16GB</strong>：适用于小型模型推理 (如 LLaMA 7B 量化后)。</li><li><strong>24GB–48GB</strong>：适用于中等规模 LLM (13B–30B) 训练和推理。</li><li><strong>80GB+ (H100, A100, H800 等)</strong>：适用于大型 LLM 训练 (如 GPT-4 级别)。</li></ul></li><li><strong>显存带宽 (GB/s)</strong>：影响数据吞吐量，带宽越高，多 GPU 训练时效率更高。例如： <ul><li><strong>H100 (HBM3) ≈ 3.35TB/s</strong>，远高于 A100 (HBM2) 的 1.55TB/s。</li></ul></li></ul><ol start="3"><li>NVLink / GPU 互连带宽</li></ol><ul><li>训练大型 LLM 时通常需要多个 GPU 联合计算，因此 <strong>NVLink 互连带宽</strong> 至关重要： <ul><li><strong>H100 NVLink：900GB/s</strong></li><li><strong>H800 NVLink：400GB/s</strong></li><li><strong>A100 NVLink：600GB/s</strong></li><li><strong>A800 NVLink：400GB/s</strong></li></ul></li><li>互连带宽越高，多 GPU 并行计算时数据传输瓶颈越少，训练效率更高。</li></ul><ol start="4"><li>能效比 (TFLOPS/W)</li></ol><ul><li>训练 LLM 消耗大量电力，能效高的 GPU（如 H100）可以降低成本。</li></ul><ol start="5"><li>软件生态</li></ol><ul><li><strong>CUDA + cuDNN</strong>：加速深度学习计算。</li><li><strong>TensorRT</strong>：优化推理性能。</li><li><strong>PyTorch/XLA, DeepSpeed, Megatron-LM</strong>：优化 LLM 训练。</li><li><strong>Multi-GPU 框架 (NCCL, FSDP, ZeRO, Triton)</strong>：优化数据并行计算。</li></ul><p>结论</p><p>如果预算充足，建议使用 <strong>H100 (或 H800)</strong> 进行大规模 LLM 训练，因其高显存、NVLink 带宽和计算效率。如果预算有限，可以选择 <strong>A100/A800 或 RTX 4090</strong>（单机推理）。</p><h2 id="_3-nvidia-gpu-参数速查表" tabindex="-1"><a class="header-anchor" href="#_3-nvidia-gpu-参数速查表" aria-hidden="true">#</a> 3. NVIDIA GPU 参数速查表</h2><figure><img src="/pinkpig/assets/nvidia-bgLIc1b8.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_4-gpu介绍" tabindex="-1"><a class="header-anchor" href="#_4-gpu介绍" aria-hidden="true">#</a> 4. GPU介绍</h2><p>GPU，即图形处理器（Graphics Processing Unit），是一种专门设计用于图形渲染和图像处理的处理器。与传统的中央处理器（CPU）相比，GPU具有更强大的并行处理能力。</p><p>NVIDIA 作为全球领先的 GPU 生产商，其显卡被广泛应用于游戏、深度学习、科学计算和图形处理等领域。随着 GPU 技术的不断升级，NVIDIA 推出了多个系列的显卡，涵盖了消费级、专业级和企业级市场。本文将对当前市面上流行的 NVIDIA GPU 型号进行排名，并探讨它们在不同应用场景中的表现。</p><p>NVIDIA 显卡系列</p><ul><li>GeForce系列：GeForce是NVIDIA的主要消费级图形处理器系列，用于电脑、游戏主机和笔记本电脑等设备。GeForce系列的显卡提供出色的图形性能和游戏体验，支持高分辨率、高帧率和实时光线追踪等先进技术。</li><li>Quadro系列：Quadro是NVIDIA的专业级图形处理器系列，用于工作站和专业可视化应用。Quadro显卡具有高度精准的图形处理能力和对专业应用软件的优化支持，广泛应用于计算机辅助设计、医学成像、影视制作等领域。</li><li>Tesla系列：Tesla是NVIDIA的高性能计算加速器系列，用于超级计算机和数据中心。Tesla采用GPU加速计算技术，可在科学计算、人工智能和深度学习等领域中提供强大的计算能力和数据处理能力。</li></ul><p>1.消费级显卡 消费级显卡主要面向个人用户和游戏玩家，通常用于日常计算、3D 游戏以及家庭娱乐等场景。NVIDIA 的 GeForce 系列是这一领域的主打产品，提供高性能与价格的平衡。</p><table><thead><tr><th>排名</th><th>GPU型号</th><th>架构</th><th>CUDA核心数</th><th>显存</th><th>主要用途</th></tr></thead><tbody><tr><td>1</td><td>RTX 4090</td><td>Ada Lovelace</td><td>16384</td><td>24GB GDDR6X</td><td>4K游戏、3D渲染、VR</td></tr><tr><td>2</td><td>RTX 4080</td><td>Ada Lovelace</td><td>9728</td><td>16GB GDDR6X</td><td>高性能游戏、AI加速</td></tr><tr><td>3</td><td>RTX 4070 Ti</td><td>Ada Lovelace</td><td>7680</td><td>12GB GDDR6X</td><td>1440p游戏、创意工作</td></tr><tr><td>4</td><td>RTX 3070</td><td>Ampere</td><td>5888</td><td>8GB GDDR6</td><td>主流游戏、高帧率电竞</td></tr><tr><td>5</td><td>RTX 3060 Ti</td><td>Ampere</td><td>4864</td><td>8GB GDDR6</td><td>中高端游戏、图形设计</td></tr></tbody></table><p>在消费级市场，RTX 4090 是目前性能最强的显卡，搭载了 16384 个 CUDA 核心和 24GB 的 GDDR6X 显存，非常适合 4K 游戏、虚拟现实（VR）应用以及重度 3D 渲染任务。RTX 4080 和 RTX 4070 Ti 则提供了更高性价比的选择，适合不需要极致性能但仍要求流畅游戏体验的用户。</p><p>2.专业级显卡 专业级显卡主要应用于内容创作者、3D 建模、科学计算等领域，NVIDIA 的 Quadro 和 RTX A 系列显卡在这些市场中备受欢迎。它们通常具有更强的计算能力、更大的显存以及针对专业软件的优化。</p><table><thead><tr><th>排名</th><th>GPU型号</th><th>架构</th><th>CUDA核心数</th><th>显存</th><th>主要用途</th></tr></thead><tbody><tr><td>1</td><td>RTX A6000</td><td>Ampere</td><td>10752</td><td>48GB GDDR6</td><td>3D渲染、AI计算、工程设计</td></tr><tr><td>2</td><td>RTX A5000</td><td>Ampere</td><td>8192</td><td>24GB GDDR6</td><td>大数据处理、机器学习</td></tr><tr><td>3</td><td>Quadro RTX 8000</td><td>Turing</td><td>4608</td><td>48GB GDDR6</td><td>高级CAD、科学计算</td></tr><tr><td>4</td><td>Quadro RTX 6000</td><td>Turing</td><td>4608</td><td>24GB GDDR6</td><td>图像和视频编辑、3D建模</td></tr><tr><td>5</td><td>RTX A4000</td><td>Ampere</td><td>6144</td><td>16GB GDDR6</td><td>中端设计、动画制作</td></tr></tbody></table><p>在专业领域，RTX A6000 是最顶尖的 GPU，凭借 48GB 显存和超过 10000 个 CUDA 核心，非常适合大规模 AI 训练、3D 渲染和视频编辑。相比之下，RTX A5000 和 Quadro RTX 8000 在性价比方面表现出色，广泛应用于工程设计和大数据分析领域。</p><p>3.面向 AI 和机器学习的显卡 AI 和机器学习（ML）领域对 GPU 的需求非常高，尤其是在训练大型神经网络和深度学习模型时，GPU 的并行处理能力至关重要。NVIDIA 的 Tesla 系列和 A100 等产品在 AI 领域表现出色。</p><table><thead><tr><th>排名</th><th>GPU型号</th><th>架构</th><th>CUDA核心数</th><th>显存</th><th>主要用途</th></tr></thead><tbody><tr><td>1</td><td>NVIDIA H100</td><td>Hopper</td><td>16896</td><td>80GB HBM3</td><td>大规模AI训练</td></tr><tr><td>2</td><td>NVIDIA A100</td><td>Ampere</td><td>6912</td><td>40GB HBM2</td><td>AI推理、机器学习</td></tr><tr><td>3</td><td>NVIDIA V100</td><td>Volta</td><td>5120</td><td>32GB HBM2</td><td>神经网络训练、科学计算</td></tr><tr><td>4</td><td>Tesla T4</td><td>Turing</td><td>2560</td><td>16GB GDDR6</td><td>轻量AI推理、云推理</td></tr><tr><td>5</td><td>Tesla P100</td><td>Pascal</td><td>3584</td><td>16GB HBM2</td><td>数据中心加速、机器学习推理</td></tr></tbody></table><p>在 AI 领域，NVIDIA H100 是最新且最强的产品，专为大规模深度学习和 AI 模型训练设计。A100 依然是数据中心的主力 GPU，广泛应用于 AI 推理和机器学习任务中。</p><p>4.A800 与 H800 A800 和 H800 是 NVIDIA 专为中国市场推出的数据中心 GPU，它们是 A100 和 H100 的改进版本，主要区别在于受限的互连带宽，以符合出口管制要求。</p><p>A100 的 NVLink 互连带宽为 600GB/s，H100 的 NVLink 互连带宽高达 900GB/s</p><p>A800 与 H800 的 NVLink 互连带宽限制为 400GB/s，计算性能仍然强大，但 NVLink 互连速度有所降低，影响多 GPU 互联时的通信效率。对于单卡或较小规模的 GPU 计算任务，影响相对较小，而对于大规模分布式 AI 训练，可能会导致一定的性能下降。</p></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="Google Colab" class="vp-link nav-link prev nav-link prev" href="/pinkpig/llm/06_llm_experience/google_colab.html"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Google Colab</div></a><a aria-label="ipdb" class="vp-link nav-link next nav-link next" href="/pinkpig/llm/06_llm_experience/ipdb.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">ipdb<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/pinkpig/assets/app-D6wNGShW.js" defer></script>
  </body>
</html>
